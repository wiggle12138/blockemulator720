"""
å®Œæ•´çš„å››æ­¥éª¤æµæ°´çº¿æ¼”ç¤º - æ”¯æŒåˆ†å±‚åé¦ˆçš„å¢å¼ºç‰ˆæœ¬
"""
"""
æ•´åˆç¬¬ä¸‰æ­¥ EvolveGCN åŠ¨æ€åˆ†ç‰‡çš„å®Œæ•´æµæ°´çº¿
"""
import os
import sys
import torch
import torch.nn as nn
import numpy as np
import pickle
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥å„æ­¥éª¤ç»„ä»¶
from partition.feature.MainPipeline import Pipeline
from partition.feature.nodeInitialize import Node, load_nodes_from_csv
from feedback.feedback import FeedbackController
from feedback.feature_evolution import DynamicFeatureEvolution

# å¯¼å…¥ç¬¬äºŒæ­¥å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ç»„ä»¶
from muti_scale.All_Final import (
    MSCIA, TemporalMSCIA, GNNEncoder,
    subgraph_contrastive_loss, graph_contrastive_loss, node_contrastive_loss
)

# å¯¼å…¥ç¬¬ä¸‰æ­¥ EvolveGCN ç»„ä»¶
from evolve_GCN.models import EvolveGCNWrapper, DynamicShardingModule
from evolve_GCN.data import BlockchainDataset
from evolve_GCN.losses import multi_objective_sharding_loss, temporal_consistency_loss
from evolve_GCN.config import TrainingConfig
from evolve_GCN.utils import get_device, HyperparameterUpdater


class IntegratedEvolveGCNDynamicSharder:
    """æ•´åˆçš„ç¬¬ä¸‰æ­¥ EvolveGCN åŠ¨æ€åˆ†ç‰‡æ¨¡å—"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.device = get_device()

        # ç¬¬ä¸‰æ­¥ä¸“ç”¨é…ç½®
        self.config = TrainingConfig()
        if config:
            for key, value in config.items():
                if hasattr(self.config, key):
                    setattr(self.config, key, value)

        # æ¨¡å‹ç»„ä»¶
        self.model = None
        self.sharding_module = None
        self.param_updater = HyperparameterUpdater()

        # è®­ç»ƒçŠ¶æ€
        self.history_states = []
        self.prev_shard_assignment = None
        self.prev_shard_count = self.config.base_shards
        self.cross_increase_count = 0
        self.prev_cross_rate = 0.0

        # åˆå§‹åŒ–çŠ¶æ€
        self.initialized = False
        self.training_history = []

    def initialize_models(self, input_dim: int):
        """åˆå§‹åŒ– EvolveGCN æ¨¡å‹"""
        print(f"[SPEED] åˆå§‹åŒ– EvolveGCN åŠ¨æ€åˆ†ç‰‡æ¨¡å‹...")

        # 1. EvolveGCN åŒ…è£…å™¨
        self.model = EvolveGCNWrapper(input_dim, self.config.hidden_dim).to(self.device)

        # 2. åŠ¨æ€åˆ†ç‰‡æ¨¡å—
        self.sharding_module = DynamicShardingModule(
            self.config.hidden_dim,
            self.config.base_shards,
            self.config.max_shards
        ).to(self.device)

        # 3. ä¼˜åŒ–å™¨
        self.model_optimizer = torch.optim.Adam(
            self.model.parameters(),
            lr=self.config.lr,
            weight_decay=self.config.weight_decay
        )
        self.shard_optimizer = torch.optim.Adam(
            self.sharding_module.parameters(),
            lr=self.config.shard_lr
        )

        self.initialized = True
        print(f"[SUCCESS] EvolveGCN æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (è¾“å…¥ç»´åº¦: {input_dim}, éšè—ç»´åº¦: {self.config.hidden_dim})")

    def process_step2_output(self, step2_output: Dict[str, torch.Tensor],
                             edge_index: torch.Tensor,
                             epoch: int = 0,
                             feedback_signal: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç¬¬äºŒæ­¥çš„è¾“å‡ºï¼Œæ‰§è¡ŒåŠ¨æ€åˆ†ç‰‡

        Args:
            step2_output: ç¬¬äºŒæ­¥çš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ç»“æœ
            edge_index: ç½‘ç»œæ‹“æ‰‘è¾¹ç´¢å¼• [2, E]
            epoch: å½“å‰è½®æ¬¡
            feedback_signal: æ¥è‡ªç¬¬å››æ­¥çš„åé¦ˆä¿¡å·

        Returns:
            {
                'shard_assignments': torch.Tensor,     # [N, num_shards] è½¯åˆ†é…
                'hard_assignments': torch.Tensor,      # [N] ç¡¬åˆ†é…
                'predicted_num_shards': int,           # é¢„æµ‹åˆ†ç‰‡æ•°
                'shard_loss': float,                   # åˆ†ç‰‡æŸå¤±
                'enhanced_embeddings': torch.Tensor,   # å¢å¼ºåµŒå…¥
                'training_info': Dict                  # è®­ç»ƒä¿¡æ¯
            }
        """
        if not self.initialized:
            input_dim = step2_output['embeddings'].size(1)
            self.initialize_models(input_dim)

        print(f"\n[SPEED] æ‰§è¡Œç¬¬ä¸‰æ­¥: EvolveGCN åŠ¨æ€åˆ†ç‰‡ (Epoch {epoch})")

        # 1. å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = self._prepare_sharding_input(step2_output, edge_index, epoch, feedback_signal)

        # 2. æ‰§è¡Œ EvolveGCN æ—¶åºå¤„ç†
        evolved_embeddings = self._evolve_gcn_forward(input_data, epoch)

        # 3. åŠ¨æ€åˆ†ç‰‡å†³ç­–
        shard_results = self._dynamic_sharding_forward(evolved_embeddings, input_data, epoch)

        # 4. è®¡ç®—åˆ†ç‰‡æŸå¤±
        loss_results = self._compute_sharding_loss(shard_results, input_data, epoch)

        # 5. æ›´æ–°å†å²çŠ¶æ€
        self._update_sharding_history(loss_results, shard_results, epoch)

        # 6. æ„å»ºè¾“å‡º
        output = {
            'shard_assignments': shard_results['shard_assignments'],
            'hard_assignments': torch.argmax(shard_results['shard_assignments'], dim=1),
            'predicted_num_shards': shard_results['predicted_num_shards'],
            'shard_loss': loss_results['total_loss'],
            'loss_components': loss_results['components'],
            'enhanced_embeddings': shard_results['enhanced_embeddings'],
            'attention_weights': shard_results['attention_weights'],
            'training_info': {
                'epoch': epoch,
                'feedback_used': feedback_signal is not None,
                'history_length': len(self.history_states),
                'convergence_info': self._get_convergence_info()
            },
            # æ€§èƒ½æŒ‡æ ‡
            'performance_metrics': self._compute_performance_metrics(shard_results, input_data)
        }

        # 7. è®°å½•è®­ç»ƒå†å²
        self.training_history.append({
            'epoch': epoch,
            'shard_loss': loss_results['total_loss'],
            'num_shards': shard_results['predicted_num_shards'],
            'performance_metrics': output['performance_metrics']
        })

        print(f"[SUCCESS] ç¬¬ä¸‰æ­¥å®Œæˆ:")
        print(f"  - é¢„æµ‹åˆ†ç‰‡æ•°: {shard_results['predicted_num_shards']}")
        print(f"  - åˆ†ç‰‡æŸå¤±: {loss_results['total_loss']:.4f}")
        print(f"  - è´Ÿè½½å‡è¡¡: {output['performance_metrics']['balance_score']:.3f}")
        print(f"  - è·¨ç‰‡æ¯”ä¾‹: {output['performance_metrics']['cross_shard_ratio']:.3f}")

        return output

    def _prepare_sharding_input(self, step2_output: Dict[str, torch.Tensor],
                                edge_index: torch.Tensor,
                                epoch: int,
                                feedback_signal: Optional[torch.Tensor]) -> Dict[str, Any]:
        """å‡†å¤‡åˆ†ç‰‡è¾“å…¥æ•°æ®"""

        embeddings = step2_output['embeddings'].to(self.device)
        edge_index = edge_index.to(self.device)

        # æ„å»ºæ—¶åºæ•°æ®ï¼ˆæ¨¡æ‹Ÿæ—¶é—´æ­¥ï¼‰
        num_nodes = embeddings.size(0)
        timestep_data = []

        # ä¸º EvolveGCN åˆ›å»ºæ—¶åºè¾“å…¥
        for t in range(self.config.num_timesteps):
            # æ·»åŠ å™ªå£°æ¨¡æ‹Ÿæ—¶åºå˜åŒ–
            noise = torch.randn_like(embeddings) * self.config.noise_level
            timestep_embeddings = embeddings + noise
            timestep_data.append((timestep_embeddings, edge_index, t))

        # å‡†å¤‡æ€§èƒ½åé¦ˆ
        if feedback_signal is not None:
            performance_feedback = feedback_signal.to(self.device)
        else:
            # ä½¿ç”¨å†å²çŠ¶æ€è®¡ç®—åé¦ˆ
            performance_feedback = self._get_performance_feedback()

        return {
            'timestep_data': timestep_data,
            'original_embeddings': embeddings,
            'edge_index': edge_index,
            'performance_feedback': performance_feedback,
            'num_nodes': num_nodes,
            'epoch': epoch
        }

    def _evolve_gcn_forward(self, input_data: Dict[str, Any], epoch: int) -> torch.Tensor:
        """EvolveGCN å‰å‘ä¼ æ’­"""

        # é‡ç½®æ¨¡å‹çŠ¶æ€
        self.model.reset_state()

        all_embeddings = []
        performance_feedback = input_data['performance_feedback']

        # æ—¶åºå¤„ç†
        for t, (node_features, edge_index, timestep) in enumerate(input_data['timestep_data']):
            # EvolveGCN å‰å‘ä¼ æ’­
            embeddings, delta_signal = self.model(node_features, edge_index, performance_feedback)
            all_embeddings.append(embeddings)

            # è®¡ç®— GCN æŸå¤±ï¼ˆç”¨äºæ¨¡å‹æ›´æ–°ï¼‰
            if epoch % 5 == 0:  # å‘¨æœŸæ€§è®­ç»ƒ
                gcn_loss = self._compute_gcn_loss(embeddings, all_embeddings, t)

                # åå‘ä¼ æ’­æ›´æ–° EvolveGCN
                self.model_optimizer.zero_grad()
                gcn_loss.backward(retain_graph=True)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.model_optimizer.step()

        # è¿”å›æœ€ç»ˆåµŒå…¥
        final_embeddings = all_embeddings[-1]
        return final_embeddings

    def _dynamic_sharding_forward(self, evolved_embeddings: torch.Tensor,
                                  input_data: Dict[str, Any], epoch: int) -> Dict[str, Any]:
        """åŠ¨æ€åˆ†ç‰‡å‰å‘ä¼ æ’­"""

        # ä½¿ç”¨ DynamicShardingModule è¿›è¡Œåˆ†ç‰‡
        shard_assignments, enhanced_embeddings, attention_weights, predicted_num_shards = self.sharding_module(
            evolved_embeddings,
            self.history_states,
            feedback_signal=input_data['performance_feedback']
        )

        return {
            'shard_assignments': shard_assignments,
            'enhanced_embeddings': enhanced_embeddings,
            'attention_weights': attention_weights,
            'predicted_num_shards': predicted_num_shards,
            'original_embeddings': evolved_embeddings
        }

    def _compute_sharding_loss(self, shard_results: Dict[str, Any],
                               input_data: Dict[str, Any], epoch: int) -> Dict[str, Any]:
        """è®¡ç®—åˆ†ç‰‡æŸå¤±"""

        shard_assignments = shard_results['shard_assignments']
        enhanced_embeddings = shard_results['enhanced_embeddings']
        edge_index = input_data['edge_index']

        # ç”Ÿæˆå®‰å…¨è¯„åˆ†ï¼ˆç®€åŒ–ï¼‰
        num_nodes = shard_assignments.size(0)
        security_scores = torch.rand(num_nodes, dtype=torch.float32, device=self.device) * 0.5

        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å†å²åˆ†é…
        use_prev_assignment = (self.prev_shard_assignment is not None and
                               self.prev_shard_assignment.size(1) == shard_assignments.size(1))

        # è®¡ç®—å¤šç›®æ ‡åˆ†ç‰‡æŸå¤±
        shard_loss, loss_components = multi_objective_sharding_loss(
            shard_assignments, enhanced_embeddings, edge_index,
            prev_assignment=self.prev_shard_assignment if use_prev_assignment else None,
            security_scores=security_scores,
            a=self.param_updater.params.get('balance_weight', 1.0),
            b=self.param_updater.params.get('cross_weight', 1.0),
            c=self.param_updater.params.get('security_weight', 1.5),
            d=self.param_updater.params.get('migrate_weight', 0.5) if use_prev_assignment else 0.0
        )

        # ä¿å­˜å½“å‰åˆ†é…
        self.prev_shard_assignment = shard_assignments.detach().clone()

        # ä¼˜åŒ–åˆ†ç‰‡æ¨¡å—
        if epoch % 3 == 0:  # å‘¨æœŸæ€§ä¼˜åŒ–
            self.shard_optimizer.zero_grad()
            shard_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.sharding_module.parameters(), max_norm=1.0)
            self.shard_optimizer.step()

        return {
            'total_loss': shard_loss.item(),
            'components': loss_components,
            'use_prev_assignment': use_prev_assignment
        }

    def _compute_gcn_loss(self, embeddings: torch.Tensor,
                          all_embeddings: List[torch.Tensor], t: int) -> torch.Tensor:
        """è®¡ç®— GCN æŸå¤±"""
        gcn_loss = torch.tensor(0.0, dtype=torch.float32, device=self.device)

        # æ—¶åºä¸€è‡´æ€§æŸå¤±
        if t > 0:
            consistency_loss = temporal_consistency_loss(
                embeddings, all_embeddings[t - 1].detach(),
                lambda_contrast=self.param_updater.params['lambda']
            )
            gcn_loss += consistency_loss

        # æ­£åˆ™åŒ–æŸå¤±
        reg_loss = 0.01 * torch.mean(torch.norm(embeddings, p=2, dim=1))
        gcn_loss += reg_loss

        return gcn_loss

    def _update_sharding_history(self, loss_results: Dict[str, Any],
                                 shard_results: Dict[str, Any], epoch: int):
        """æ›´æ–°åˆ†ç‰‡å†å²çŠ¶æ€"""

        with torch.no_grad():
            shard_assignments = shard_results['shard_assignments']
            predicted_num_shards = shard_results['predicted_num_shards']

            hard_assignment = torch.argmax(shard_assignments, dim=1)
            shard_sizes = [(hard_assignment == s).sum().item() for s in range(predicted_num_shards)]

            # æ€§èƒ½æŒ‡æ ‡è®¡ç®—
            balance_score = 1.0 - (np.std(shard_sizes) / (np.mean(shard_sizes) + 1e-8))
            cross_rate = loss_results['components']['cross']
            security_score = 1.0 - loss_results['components']['security']

            # è·¨ç‰‡äº¤æ˜“ç‡è¶‹åŠ¿æ£€æµ‹
            if cross_rate > self.prev_cross_rate:
                self.cross_increase_count += 1
            else:
                self.cross_increase_count = 0
            self.prev_cross_rate = cross_rate

            # æ›´æ–°å†å²çŠ¶æ€
            current_state = torch.tensor([balance_score, cross_rate, security_score],
                                         dtype=torch.float32, device=self.device)
            self.history_states.append(current_state)
            if len(self.history_states) > self.config.history_length:
                self.history_states.pop(0)

            # æ›´æ–°çŠ¶æ€è·Ÿè¸ª
            self.prev_shard_count = predicted_num_shards

            # åŠ¨æ€è°ƒèŠ‚å‚æ•°
            performance_metrics = {
                'balance_score': balance_score,
                'cross_tx_rate': cross_rate,
                'cross_increase_count': self.cross_increase_count
            }
            self.param_updater.update_hyperparams(performance_metrics)

    def _compute_performance_metrics(self, shard_results: Dict[str, Any],
                                     input_data: Dict[str, Any]) -> Dict[str, float]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""

        shard_assignments = shard_results['shard_assignments']
        predicted_num_shards = shard_results['predicted_num_shards']
        edge_index = input_data['edge_index']

        hard_assignment = torch.argmax(shard_assignments, dim=1)
        shard_sizes = [(hard_assignment == s).sum().item() for s in range(predicted_num_shards)]

        # è´Ÿè½½å‡è¡¡æŒ‡æ ‡
        balance_score = 1.0 - (np.std(shard_sizes) / (np.mean(shard_sizes) + 1e-8))

        # è·¨ç‰‡äº¤æ˜“æ¯”ä¾‹
        cross_shard_edges = 0
        total_edges = edge_index.size(1)
        if total_edges > 0:
            u, v = edge_index[0], edge_index[1]
            valid_mask = (u < len(hard_assignment)) & (v < len(hard_assignment))
            if valid_mask.sum() > 0:
                valid_u, valid_v = u[valid_mask], v[valid_mask]
                cross_shard_edges = (hard_assignment[valid_u] != hard_assignment[valid_v]).sum().item()

        cross_shard_ratio = cross_shard_edges / max(total_edges, 1)

        return {
            'balance_score': balance_score,
            'cross_shard_ratio': cross_shard_ratio,
            'shard_sizes': shard_sizes,
            'num_shards': predicted_num_shards,
            'size_variance': np.var(shard_sizes)
        }

    def _get_performance_feedback(self) -> torch.Tensor:
        """è·å–æ€§èƒ½åé¦ˆä¿¡å·"""
        if self.history_states:
            recent_states = torch.stack(self.history_states[-3:]) if len(self.history_states) >= 3 else torch.stack(
                self.history_states)
            performance_feedback = torch.mean(recent_states, dim=0).float()
        else:
            performance_feedback = torch.tensor([0.5, 0.1, 0.8], dtype=torch.float32, device=self.device)
        return performance_feedback

    def _get_convergence_info(self) -> Dict[str, Any]:
        """è·å–æ”¶æ•›ä¿¡æ¯"""
        if len(self.training_history) < 5:
            return {'converged': False, 'trend': 'unknown'}

        recent_losses = [h['shard_loss'] for h in self.training_history[-5:]]
        loss_trend = np.mean(np.diff(recent_losses))

        return {
            'converged': abs(loss_trend) < 0.001,
            'trend': 'decreasing' if loss_trend < 0 else 'increasing',
            'recent_avg_loss': np.mean(recent_losses),
            'loss_variance': np.var(recent_losses)
        }

    def get_model_state(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€"""
        return {
            'initialized': self.initialized,
            'config': self.config.to_dict(),
            'device': str(self.device),
            'history_length': len(self.history_states),
            'training_history_length': len(self.training_history),
            'model_parameters': sum(p.numel() for p in self.model.parameters()) if self.model else 0,
            'sharding_parameters': sum(p.numel() for p in self.sharding_module.parameters()) if self.sharding_module else 0,
            'hyperparams': self.param_updater.get_params()
        }

    def save_sharding_results(self, output: Dict[str, Any], filepath: str):
        """ä¿å­˜åˆ†ç‰‡ç»“æœ"""

        hard_assignments = output['hard_assignments'].cpu().numpy()
        num_shards = output['predicted_num_shards']

        sharding_results = {}
        for s in range(num_shards):
            shard_nodes = (hard_assignments == s).nonzero()[0].tolist()
            sharding_results[f'shard_{s}'] = shard_nodes

        with open(filepath, 'wb') as f:
            pickle.dump(sharding_results, f)

        print(f"ğŸ“ åˆ†ç‰‡ç»“æœå·²ä¿å­˜: {filepath}")

        # æ‰“å°åˆ†ç‰‡ç»Ÿè®¡
        for key, value in sharding_results.items():
            print(f"  - {key}: {len(value)} èŠ‚ç‚¹")

        return sharding_results


# æ›´æ–°å®Œæ•´æµæ°´çº¿æ¼”ç¤ºç±»ï¼Œæ•´åˆçœŸå®çš„ç¬¬ä¸‰æ­¥
class FullIntegratedPipelineDemo:
    """å®Œæ•´æ•´åˆçš„å››æ­¥éª¤æµæ°´çº¿æ¼”ç¤º - çœŸå®çš„ç¬¬äºŒæ­¥å’Œç¬¬ä¸‰æ­¥"""

    def __init__(self):
        self.device = get_device()
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

        # é…ç½®å‚æ•°
        self.config = {
            'num_epochs': 15,
            'feedback_start_epoch': 2,
            'save_results': True,
            'results_dir': './results',
            'sample_data_path': './large_samples.csv',

            # ç¬¬äºŒæ­¥ä¸“ç”¨é…ç½®
            'step2_config': {
                'input_dim': 128,
                'hidden_dim': 64,
                'time_dim': 16,
                'k_ratio': 0.9,
                'alpha': 0.3,
                'beta': 0.4,
                'gamma': 0.3,
                'tau': 0.09,
                'augment_type': 'edge',      # æ·»åŠ è¿™ä¸ªå‚æ•°
                'num_node_types': 5,         # æ·»åŠ è¿™ä¸ªå‚æ•°
                'num_edge_types': 3,         # æ·»åŠ è¿™ä¸ªå‚æ•°
                'learning_rate': 0.02,
                'weight_decay': 9e-6,
                'max_epochs': 20,
                'target_loss': 0.25
            },

            # ç¬¬ä¸‰æ­¥ä¸“ç”¨é…ç½®
            'step3_config': {
                'lr': 0.001,
                'epochs': 10,
                'num_timesteps': 5,
                'base_shards': 3,
                'hidden_dim': 64,
                'max_shards': 8,
                'noise_level': 0.01,
                'weight_decay': 1e-5,
                'shard_lr': 0.001,
                'balance_weight': 0.5,
                'cross_weight': 1.5,
                'security_weight': 0.5,
                'migrate_weight': 0.5,
                'max_grad_norm': 1.0,
                'history_length': 10,
                'print_freq': 5
            }
        }

        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(self.config['results_dir'], exist_ok=True)

        # æµæ°´çº¿å†å²è®°å½•
        self.pipeline_history = {
            'step1_features': [],
            'step2_embeddings': [],
            'step3_sharding': [],
            'step4_feedback': [],
            'performance_metrics': []
        }

        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()

    def _initialize_components(self):
        """åˆå§‹åŒ–å„æ­¥éª¤ç»„ä»¶"""
        print("åˆå§‹åŒ–å„æ­¥éª¤ç»„ä»¶...")

        # ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–æµæ°´çº¿
        print("- åˆå§‹åŒ–ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–æµæ°´çº¿")
        base_pipeline = Pipeline(use_fusion=True, save_adjacency=True)
        self.step1_pipeline = LayeredFeedbackFeatureExtractor(base_pipeline)

        # ç¬¬äºŒæ­¥: æ•´åˆçš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
        print("- åˆå§‹åŒ–ç¬¬äºŒæ­¥: å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ")
        self.step2_mscia = IntegratedMultiScaleContrastiveLearning(self.config['step2_config'])

        # ç¬¬ä¸‰æ­¥: æ•´åˆçš„ EvolveGCN åŠ¨æ€åˆ†ç‰‡
        print("- åˆå§‹åŒ–ç¬¬ä¸‰æ­¥: EvolveGCN åŠ¨æ€åˆ†ç‰‡")
        self.step3_evolve_gcn = IntegratedEvolveGCNDynamicSharder(self.config['step3_config'])

        # ç¬¬å››æ­¥: å¢å¼ºåé¦ˆæ§åˆ¶å™¨
        print("- åˆå§‹åŒ–ç¬¬å››æ­¥: å¢å¼ºåé¦ˆæ§åˆ¶å™¨")
        self.feedback_controller = EnhancedFeedbackController()

        print("[SUCCESS] æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def run_step3_evolve_gcn_sharding(self, step2_output: Dict[str, torch.Tensor],
                                      edge_index: torch.Tensor,
                                      epoch: int,
                                      feedback_signal: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """ç¬¬ä¸‰æ­¥: çœŸå®çš„ EvolveGCN åŠ¨æ€åˆ†ç‰‡"""
        print(f"\n[SPEED] æ‰§è¡Œç¬¬ä¸‰æ­¥: EvolveGCN åŠ¨æ€åˆ†ç‰‡ (Epoch {epoch})...")

        # ä½¿ç”¨æ•´åˆçš„ EvolveGCN åŠ¨æ€åˆ†ç‰‡å™¨
        step3_output = self.step3_evolve_gcn.process_step2_output(
            step2_output, edge_index, epoch, feedback_signal
        )

        # è®°å½•åˆ†ç‰‡å†å²
        sharding_record = {
            'epoch': epoch,
            'shard_loss': step3_output['shard_loss'],
            'num_shards': step3_output['predicted_num_shards'],
            'shard_sizes': step3_output['performance_metrics']['shard_sizes'],
            'balance_score': step3_output['performance_metrics']['balance_score'],
            'cross_shard_ratio': step3_output['performance_metrics']['cross_shard_ratio'],
            'feedback_used': step3_output['training_info']['feedback_used'],
            'convergence_info': step3_output['training_info']['convergence_info'],
            'embeddings_source': step2_output['training_info']['mode']
        }

        self.pipeline_history['step3_sharding'].append(sharding_record)

        # å‘¨æœŸæ€§ä¿å­˜åˆ†ç‰‡ç»“æœ
        if epoch % 5 == 0:
            sharding_path = os.path.join(self.config['results_dir'], f'sharding_results_epoch_{epoch}.pkl')
            self.step3_evolve_gcn.save_sharding_results(step3_output, sharding_path)

        print(f"[SUCCESS] ç¬¬ä¸‰æ­¥å®Œæˆ:")
        print(f"  - é¢„æµ‹åˆ†ç‰‡æ•°: {step3_output['predicted_num_shards']}")
        print(f"  - åˆ†ç‰‡æŸå¤±: {step3_output['shard_loss']:.4f}")
        print(f"  - è´Ÿè½½å‡è¡¡: {step3_output['performance_metrics']['balance_score']:.3f}")
        print(f"  - è·¨ç‰‡æ¯”ä¾‹: {step3_output['performance_metrics']['cross_shard_ratio']:.3f}")
        print(f"  - æ”¶æ•›çŠ¶æ€: {step3_output['training_info']['convergence_info']['trend']}")

        return step3_output

    def run_complete_pipeline(self, save_results: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å››æ­¥éª¤æµæ°´çº¿ - çœŸå®çš„ç¬¬äºŒæ­¥å’Œç¬¬ä¸‰æ­¥"""
        print("=" * 80)
        print("[START] å¼€å§‹å®Œæ•´çš„å››æ­¥éª¤åŒºå—é“¾åˆ†ç‰‡æµæ°´çº¿ (æ•´åˆçœŸå®ç¬¬äºŒæ­¥å’Œç¬¬ä¸‰æ­¥)")
        print("=" * 80)

        start_time = datetime.now()

        try:
            # ç”Ÿæˆç¤ºä¾‹æ•°æ®
            nodes = self.generate_sample_nodes()
            edge_index = self.generate_sample_network_topology(len(nodes))

            # å½“å‰åé¦ˆæŒ‡å¯¼çŠ¶æ€
            current_step1_guidance = None

            # ä¸»è®­ç»ƒå¾ªç¯
            for epoch in range(self.config['num_epochs']):
                print(f"\n{'='*30} EPOCH {epoch+1}/{self.config['num_epochs']} {'='*30}")

                # ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–
                step1_output = self.run_step1_feature_extraction(
                    nodes, current_step1_guidance, epoch
                )

                # ç¬¬äºŒæ­¥: çœŸå®çš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
                step2_output = self.run_step2_contrastive_learning(
                    step1_output, edge_index, epoch
                )

                # ç¬¬ä¸‰æ­¥: çœŸå®çš„ EvolveGCN åŠ¨æ€åˆ†ç‰‡
                feedback_signal = None
                if epoch > 0 and hasattr(self, 'last_feedback_signal'):
                    feedback_signal = self.last_feedback_signal

                step3_output = self.run_step3_evolve_gcn_sharding(
                    step2_output, edge_index, epoch, feedback_signal
                )

                # ç¬¬å››æ­¥: åˆ†å±‚åé¦ˆä¼˜åŒ–
                feedback_signal, next_step1_guidance = self.run_step4_feedback_optimization(
                    step1_output, step3_output, edge_index, epoch
                )

                # ä¿å­˜åé¦ˆä¿¡å·å’ŒæŒ‡å¯¼ä¾›ä¸‹ä¸€è½®ä½¿ç”¨
                self.last_feedback_signal = feedback_signal
                current_step1_guidance = next_step1_guidance

                # è®°å½•æ•´ä½“æ€§èƒ½
                epoch_performance = {
                    'epoch': epoch,
                    'step1_mode': step1_output.get('feedback_mode', 'unknown'),
                    'step2_loss': step2_output['contrastive_loss'],
                    'step2_mode': step2_output['training_info']['mode'],
                    'step3_loss': step3_output['shard_loss'],
                    'step3_converged': step3_output['training_info']['convergence_info']['converged'],
                    'num_shards': step3_output['predicted_num_shards'],
                    'balance_score': feedback_signal[0].item(),
                    'cross_tx_rate': feedback_signal[1].item(),
                    'security_score': feedback_signal[2].item(),
                    'feedback_active': bool(current_step1_guidance),
                    'integration_metrics': {
                        'step1_layers': len(step1_output.get('layered_breakdown', {})),
                        'step2_converged': step2_output['training_info'].get('converged', False),
                        'step3_balance_score': step3_output['performance_metrics']['balance_score'],
                        'step3_cross_ratio': step3_output['performance_metrics']['cross_shard_ratio'],
                        'step3_trend': step3_output['training_info']['convergence_info']['trend']
                    }
                }

                self.pipeline_history['performance_metrics'].append(epoch_performance)

                # æ¯3è½®è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                if (epoch + 1) % 3 == 0:
                    self._print_full_integrated_epoch_summary(epoch_performance)

        except Exception as e:
            print(f"[ERROR] æµæ°´çº¿æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # æ±‡æ€»ç»“æœ
        final_results = self._compile_full_integrated_final_results(duration)

        # ä¿å­˜ç»“æœ
        if save_results and self.config['save_results']:
            self._save_full_integrated_results(final_results)

        self._visualize_full_integrated_results()

        print("\n" + "=" * 80)
        print("[SUCCESS] å®Œæ•´å››æ­¥éª¤æµæ°´çº¿æ‰§è¡Œå®Œæˆ (çœŸå®ç¬¬äºŒæ­¥ + çœŸå®ç¬¬ä¸‰æ­¥)!")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f}ç§’")
        print(f"ğŸ§  ç¬¬äºŒæ­¥æ¨¡å‹çŠ¶æ€: {self.step2_mscia.get_model_state()}")
        print(f"[SPEED] ç¬¬ä¸‰æ­¥æ¨¡å‹çŠ¶æ€: {self.step3_evolve_gcn.get_model_state()}")
        adaptation_report = self.step1_pipeline.get_adaptation_report()
        print(f"ğŸ”„ åé¦ˆæ¨¡å¼: {adaptation_report.get('current_mode', 'unknown')}")
        print("=" * 80)

        return final_results

    # å¤ç”¨ä¹‹å‰çš„æ–¹æ³•å®ç°...
    def generate_sample_nodes(self, num_nodes: int = 100) -> List[Node]:
        """ç”Ÿæˆç¤ºä¾‹èŠ‚ç‚¹æ•°æ® - ä¿®å¤ç‰ˆæœ¬"""
        # é¦–å…ˆå°è¯•ä»CSVæ–‡ä»¶åŠ è½½
        if os.path.exists(self.config['sample_data_path']):
            print(f"ä» {self.config['sample_data_path']} åŠ è½½èŠ‚ç‚¹æ•°æ®...")
            try:
                return load_nodes_from_csv(self.config['sample_data_path'])
            except Exception as e:
                print(f"[WARNING] ä»CSVåŠ è½½å¤±è´¥: {e}")
                print("å°†ç”Ÿæˆæ¨¡æ‹ŸèŠ‚ç‚¹æ•°æ®...")
        
        print(f"ç”Ÿæˆ {num_nodes} ä¸ªç¤ºä¾‹èŠ‚ç‚¹...")
        
        # ä½¿ç”¨ä¸generate_samples.pyç›¸åŒçš„èŠ‚ç‚¹ç”Ÿæˆé€»è¾‘
        try:
            # ä½¿ç”¨ä¸“é—¨çš„æ ·æœ¬ç”Ÿæˆå™¨
            from partition.feature.generate_samples import BlockchainNodeSampleGenerator
            
            generator = BlockchainNodeSampleGenerator(seed=42)
            raw_samples = generator.generate_samples(
                num_samples=num_nodes, 
                output_file='temp_generated_samples.csv'
            )
            
            # å°†åŸå§‹æ ·æœ¬è½¬æ¢ä¸ºNodeå¯¹è±¡
            nodes = []
            for i, sample_dict in enumerate(raw_samples):
                try:
                    # ä½¿ç”¨æ­£ç¡®çš„Nodeæ„é€ æ–¹å¼ï¼ˆä¼ å…¥å­—å…¸æ•°æ®ï¼‰
                    node = Node(sample_dict)  # Nodeç±»æ¥å—å­—å…¸å½¢å¼çš„æ•°æ®
                    nodes.append(node)
                except Exception as e:
                    print(f"[WARNING] åˆ›å»ºèŠ‚ç‚¹ {i} å¤±è´¥: {e}")
                    continue
            
            print(f"[SUCCESS] æˆåŠŸç”Ÿæˆ {len(nodes)} ä¸ªèŠ‚ç‚¹")
            return nodes
            
        except Exception as e:
            print(f"[WARNING] ä½¿ç”¨æ ·æœ¬ç”Ÿæˆå™¨å¤±è´¥: {e}")
            print("ä½¿ç”¨ç®€åŒ–çš„èŠ‚ç‚¹ç”Ÿæˆæ–¹æ³•...")
            
            # å›é€€åˆ°ç®€åŒ–çš„èŠ‚ç‚¹ç”Ÿæˆ
            return self._generate_simplified_nodes(num_nodes)

    def generate_sample_network_topology(self, num_nodes: int) -> torch.Tensor:
        """ç”Ÿæˆç¤ºä¾‹ç½‘ç»œæ‹“æ‰‘"""
        num_edges = min(num_nodes * 3, num_nodes * (num_nodes - 1) // 2)
        edges = []
        for _ in range(num_edges):
            u = np.random.randint(0, num_nodes)
            v = np.random.randint(0, num_nodes)
            if u != v:
                edges.append([u, v])

        if edges:
            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        else:
            edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long).t().contiguous()

        return edge_index.to(self.device)

    def run_step1_feature_extraction(self, nodes: List[Node],
                                     step4_guidance: Optional[Dict[str, Any]] = None,
                                     epoch: int = 0) -> Dict[str, torch.Tensor]:
        """ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–"""
        print(f"\n[CONFIG] æ‰§è¡Œç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå– (Epoch {epoch})")

        results = self.step1_pipeline.extract_features_with_feedback(
            nodes, step4_guidance, epoch
        )

        extraction_record = {
            'epoch': epoch,
            'f_classic_shape': results['f_classic'].shape,
            'f_graph_shape': results['f_graph'].shape,
            'feedback_applied': results.get('feedback_applied', False),
            'feedback_mode': results.get('feedback_mode', 'cold_start'),
            'layer_count': len(results.get('layered_breakdown', {}))
        }

        if 'f_fused' in results:
            extraction_record['f_fused_shape'] = results['f_fused'].shape

        self.pipeline_history['step1_features'].append(extraction_record)

        print(f"[SUCCESS] ç¬¬ä¸€æ­¥å®Œæˆ (æ¨¡å¼: {results.get('feedback_mode', 'unknown')}):")
        print(f"  - F_classic: {results['f_classic'].shape}")
        print(f"  - F_graph: {results['f_graph'].shape}")
        print(f"  - åˆ†å±‚ç‰¹å¾: {len(results.get('layered_breakdown', {}))} å±‚")
        if 'f_fused' in results:
            print(f"  - F_fused: {results['f_fused'].shape}")

        return results

    def run_step2_contrastive_learning(self, step1_output: Dict[str, torch.Tensor],
                                       edge_index: torch.Tensor,
                                       epoch: int) -> Dict[str, torch.Tensor]:
        """ç¬¬äºŒæ­¥: çœŸå®çš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ """
        print(f"\nğŸ§  æ‰§è¡Œç¬¬äºŒæ­¥: å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹  (Epoch {epoch})...")

        step2_output = self.step2_mscia.process_step1_output(
            step1_output, edge_index, epoch
        )

        embedding_record = {
            'epoch': epoch,
            'input_features_shape': step1_output['f_classic'].shape,
            'embeddings_shape': step2_output['embeddings'].shape,
            'contrastive_loss': step2_output['contrastive_loss'],
            'training_mode': step2_output['training_info']['mode'],
            'converged': step2_output['training_info'].get('converged', False),
            'embedding_stats': {
                'mean': float(torch.mean(step2_output['embeddings'])),
                'std': float(torch.std(step2_output['embeddings'])),
                'min': float(torch.min(step2_output['embeddings'])),
                'max': float(torch.max(step2_output['embeddings']))
            }
        }

        self.pipeline_history['step2_embeddings'].append(embedding_record)

        if epoch % 5 == 0:
            embeddings_path = os.path.join(self.config['results_dir'], f'temporal_embeddings_epoch_{epoch}.pkl')
            self.step2_mscia.save_embeddings(step2_output['temporal_embeddings'], embeddings_path)

        print(f"[SUCCESS] ç¬¬äºŒæ­¥å®Œæˆ:")
        print(f"  - åµŒå…¥ç»´åº¦: {step2_output['embeddings'].shape}")
        print(f"  - å¯¹æ¯”æŸå¤±: {step2_output['contrastive_loss']:.4f}")
        print(f"  - è®­ç»ƒæ¨¡å¼: {step2_output['training_info']['mode']}")
        if 'converged' in step2_output['training_info']:
            print(f"  - æ”¶æ•›çŠ¶æ€: {'æ˜¯' if step2_output['training_info']['converged'] else 'å¦'}")

        return step2_output

    def run_step4_feedback_optimization(self, step1_output: Dict[str, torch.Tensor],
                                        step3_output: Dict[str, Any],
                                        edge_index: torch.Tensor,
                                        epoch: int) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """ç¬¬å››æ­¥: åˆ†å±‚åé¦ˆä¼˜åŒ–"""
        print(f"\nğŸ”„ æ‰§è¡Œç¬¬å››æ­¥: åˆ†å±‚åé¦ˆä¼˜åŒ– (Epoch {epoch})...")

        if epoch < self.config['feedback_start_epoch']:
            print("- è·³è¿‡åé¦ˆä¼˜åŒ– (æœªåˆ°å¯åŠ¨è½®æ¬¡)")
            default_feedback = torch.tensor([0.5, 0.1, 0.8], device=self.device)
            return default_feedback, {}

        try:
            # ä½¿ç”¨çœŸå®çš„åˆ†ç‰‡åˆ†é…ç»“æœ
            feedback_signal, step1_guidance = self.feedback_controller.process_layered_feedback(
                step1_output,
                step3_output['shard_assignments'],
                edge_index,
                self.step3_evolve_gcn.model if self.step3_evolve_gcn.model else None,
                epoch
            )

        except Exception as e:
            print(f"åé¦ˆå¤„ç†å‡ºé”™ï¼Œä½¿ç”¨åŸºäºç¬¬ä¸‰æ­¥æ€§èƒ½çš„åé¦ˆ: {e}")

            # åŸºäºç¬¬ä¸‰æ­¥çš„å®é™…æ€§èƒ½æŒ‡æ ‡
            balance_score = step3_output['performance_metrics']['balance_score']
            cross_shard_ratio = step3_output['performance_metrics']['cross_shard_ratio']

            # åŸºäºæŸå¤±è¶‹åŠ¿ä¼°ç®—å®‰å…¨åˆ†æ•°
            convergence_info = step3_output['training_info']['convergence_info']
            security_score = 0.8 if convergence_info['converged'] else 0.6

            feedback_signal = torch.tensor([balance_score, cross_shard_ratio, security_score], device=self.device)

            step1_guidance = {
                'epoch': epoch,
                'guidance_type': 'step3_based',
                'layer_weight_adjustments': {
                    'hardware': 1.0 + (balance_score - 0.5) * 0.3,
                    'onchain_behavior': 1.0 + (security_score - 0.7) * 0.4,
                    'network_topology': 1.0 + (cross_shard_ratio - 0.2) * -0.4,
                    'sequence': 1.0 + (security_score - 0.7) * 0.2,
                },
                'layer_enhancement_factors': {
                    'hardware': 1.1 if balance_score < 0.6 else 1.0,
                    'onchain_behavior': 1.1 if security_score < 0.7 else 1.0,
                    'network_topology': 0.9 if cross_shard_ratio > 0.25 else 1.0
                }
            }

        feedback_record = {
            'epoch': epoch,
            'balance_score': feedback_signal[0].item(),
            'cross_tx_rate': feedback_signal[1].item(),
            'security_score': feedback_signal[2].item(),
            'has_guidance': bool(step1_guidance),
            'guidance_layers': len(step1_guidance.get('layer_weight_adjustments', {})),
            'step3_metrics': step3_output['performance_metrics']
        }

        self.pipeline_history['step4_feedback'].append(feedback_record)

        print(f"[SUCCESS] ç¬¬å››æ­¥å®Œæˆ: åé¦ˆä¿¡å· [{feedback_signal[0]:.3f}, {feedback_signal[1]:.3f}, {feedback_signal[2]:.3f}]")

        if step1_guidance:
            print(f"   ç”Ÿæˆåˆ†å±‚æŒ‡å¯¼: {len(step1_guidance.get('layer_weight_adjustments', {}))} å±‚æƒé‡è°ƒæ•´")

        return feedback_signal, step1_guidance

    def _print_full_integrated_epoch_summary(self, epoch_performance: Dict[str, Any]):
        """æ‰“å°å®Œå…¨æ•´åˆçš„è½®æ¬¡æ‘˜è¦"""
        print(f"\n[DATA] Epoch {epoch_performance['epoch']} å®Œå…¨æ•´åˆæ€§èƒ½æ‘˜è¦:")
        print(f"   â€¢ ç¬¬ä¸€æ­¥æ¨¡å¼: {epoch_performance['step1_mode']}")
        print(f"   â€¢ ç¬¬äºŒæ­¥æŸå¤±: {epoch_performance['step2_loss']:.4f} (æ¨¡å¼: {epoch_performance['step2_mode']})")
        print(f"   â€¢ ç¬¬ä¸‰æ­¥æŸå¤±: {epoch_performance['step3_loss']:.4f} (æ”¶æ•›: {'æ˜¯' if epoch_performance['step3_converged'] else 'å¦'})")
        print(f"   â€¢ åˆ†ç‰‡æ•°é‡: {epoch_performance['num_shards']}")
        print(f"   â€¢ è´Ÿè½½å‡è¡¡: {epoch_performance['balance_score']:.3f}")
        print(f"   â€¢ è·¨ç‰‡äº¤æ˜“ç‡: {epoch_performance['cross_tx_rate']:.3f}")
        print(f"   â€¢ å®‰å…¨åˆ†æ•°: {epoch_performance['security_score']:.3f}")
        print(f"   â€¢ æ•´åˆæŒ‡æ ‡:")
        for metric, value in epoch_performance['integration_metrics'].items():
            if isinstance(value, (int, float)):
                print(f"     - {metric}: {value:.3f}" if isinstance(value, float) else f"     - {metric}: {value}")
            else:
                print(f"     - {metric}: {value}")

    def _compile_full_integrated_final_results(self, duration: float) -> Dict[str, Any]:
        """ç¼–è¯‘å®Œå…¨æ•´åˆçš„æœ€ç»ˆç»“æœ"""
        return {
            'execution_info': {
                'duration_seconds': duration,
                'total_epochs': self.config['num_epochs'],
                'feedback_start_epoch': self.config['feedback_start_epoch'],
                'device': str(self.device),
                'integration_type': 'real_step2_step3_full'
            },
            'pipeline_history': self.pipeline_history,
            'step2_model_state': self.step2_mscia.get_model_state(),
            'step3_model_state': self.step3_evolve_gcn.get_model_state(),
            'adaptation_report': self.step1_pipeline.get_adaptation_report(),
            'final_metrics': {
                'avg_balance_score': np.mean([m['balance_score'] for m in self.pipeline_history['performance_metrics']]),
                'avg_cross_tx_rate': np.mean([m['cross_tx_rate'] for m in self.pipeline_history['performance_metrics']]),
                'avg_security_score': np.mean([m['security_score'] for m in self.pipeline_history['performance_metrics']]),
                'avg_step2_loss': np.mean([m['step2_loss'] for m in self.pipeline_history['performance_metrics']]),
                'avg_step3_loss': np.mean([m['step3_loss'] for m in self.pipeline_history['performance_metrics']]),
                'step2_convergence_rate': sum(1 for m in self.pipeline_history['performance_metrics']
                                              if m.get('integration_metrics', {}).get('step2_converged', False)) / len(self.pipeline_history['performance_metrics']),
                'step3_convergence_rate': sum(1 for m in self.pipeline_history['performance_metrics']
                                              if m.get('step3_converged', False)) / len(self.pipeline_history['performance_metrics']),
                'total_feedback_activations': sum(1 for m in self.pipeline_history['performance_metrics'] if m['feedback_active'])
            }
        }

    def _save_full_integrated_results(self, results: Dict[str, Any]):
        """ä¿å­˜å®Œå…¨æ•´åˆçš„ç»“æœ"""
        results_path = os.path.join(self.config['results_dir'], 'full_integrated_pipeline_results.json')
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        print(f"ğŸ“ å®Œå…¨æ•´åˆç»“æœå·²ä¿å­˜: {results_path}")

    def _visualize_full_integrated_results(self):
        """å¯è§†åŒ–å®Œå…¨æ•´åˆçš„ç»“æœ"""
        try:
            import matplotlib.pyplot as plt

            epochs = [m['epoch'] for m in self.pipeline_history['performance_metrics']]
            balance_scores = [m['balance_score'] for m in self.pipeline_history['performance_metrics']]
            step2_losses = [m['step2_loss'] for m in self.pipeline_history['performance_metrics']]
            step3_losses = [m['step3_loss'] for m in self.pipeline_history['performance_metrics']]

            plt.figure(figsize=(18, 12))

            plt.subplot(2, 4, 1)
            plt.plot(epochs, balance_scores, 'b-', label='Balance Score', linewidth=2)
            plt.title('è´Ÿè½½å‡è¡¡åˆ†æ•°', fontsize=12)
            plt.xlabel('Epoch')
            plt.ylabel('Score')
            plt.grid(True, alpha=0.3)

            plt.subplot(2, 4, 2)
            plt.plot(epochs, step2_losses, 'r-', label='Step2 Loss', linewidth=2)
            plt.title('ç¬¬äºŒæ­¥å¯¹æ¯”å­¦ä¹ æŸå¤±', fontsize=12)
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True, alpha=0.3)

            plt.subplot(2, 4, 3)
            plt.plot(epochs, step3_losses, 'g-', label='Step3 Loss', linewidth=2)
            plt.title('ç¬¬ä¸‰æ­¥ EvolveGCN æŸå¤±', fontsize=12)
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True, alpha=0.3)

            # å…¶ä»–å¯è§†åŒ–
            if len(self.pipeline_history['step2_embeddings']) > 0:
                embedding_means = [e['embedding_stats']['mean'] for e in self.pipeline_history['step2_embeddings']]
                plt.subplot(2, 4, 4)
                plt.plot(epochs, embedding_means, 'm-', label='Embedding Mean', linewidth=2)
                plt.title('åµŒå…¥ç‰¹å¾å‡å€¼', fontsize=12)
                plt.xlabel('Epoch')
                plt.ylabel('Mean Value')
                plt.grid(True, alpha=0.3)

            # ç¬¬ä¸‰æ­¥ç›¸å…³æŒ‡æ ‡
            if len(self.pipeline_history['step3_sharding']) > 0:
                balance_scores_step3 = [s['balance_score'] for s in self.pipeline_history['step3_sharding']]
                cross_ratios = [s['cross_shard_ratio'] for s in self.pipeline_history['step3_sharding']]

                plt.subplot(2, 4, 5)
                plt.plot(epochs, balance_scores_step3, 'c-', label='Step3 Balance', linewidth=2)
                plt.title('ç¬¬ä¸‰æ­¥è´Ÿè½½å‡è¡¡', fontsize=12)
                plt.xlabel('Epoch')
                plt.ylabel('Balance Score')
                plt.grid(True, alpha=0.3)

                plt.subplot(2, 4, 6)
                plt.plot(epochs, cross_ratios, 'orange', label='Cross Shard Ratio', linewidth=2)
                plt.title('è·¨ç‰‡äº¤æ˜“æ¯”ä¾‹', fontsize=12)
                plt.xlabel('Epoch')
                plt.ylabel('Cross Ratio')
                plt.grid(True, alpha=0.3)

            plt.tight_layout()

            plot_path = os.path.join(self.config['results_dir'], 'full_integrated_performance_visualization.png')
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ å®Œå…¨æ•´åˆæ€§èƒ½å¯è§†åŒ–å·²ä¿å­˜: {plot_path}")

            plt.show()

        except ImportError:
            print("[WARNING] matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        except Exception as e:
            print(f"[WARNING] å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")





class LayeredFeedbackFeatureExtractor:
    """
    åˆ†å±‚åé¦ˆç‰¹å¾æå–å™¨ - å¯¹åº”ç¬¬ä¸€æ­¥çš„å®é™…ç»“æ„
    æ”¯æŒ 99ç»´åŸå§‹ç‰¹å¾çš„6å±‚åˆ†è§£ + 32ç»´æ—¶åºç‰¹å¾ + 10ç»´å›¾ç»“æ„ç‰¹å¾
    """

    def __init__(self, base_pipeline: Pipeline):
        self.base_pipeline = base_pipeline
        self.feedback_enabled = False
        self.feedback_mode = 'cold_start'  # cold_start, warm_feedback, stable_feedback
        self.adaptation_history = []

        # ç¬¬ä¸€æ­¥ç‰¹å¾ç»“æ„æ˜ å°„
        self.feature_structure = {
            # 99ç»´åŸå§‹ç‰¹å¾çš„6å±‚åˆ†è§£
            'original_layers': {
                'hardware': {'start': 0, 'end': 17, 'dim': 17},           # ç¡¬ä»¶è§„æ ¼ç‰¹å¾
                'onchain_behavior': {'start': 17, 'end': 34, 'dim': 17},  # é“¾ä¸Šè¡Œä¸ºç‰¹å¾
                'network_topology': {'start': 34, 'end': 54, 'dim': 20},  # ç½‘ç»œæ‹“æ‰‘ç‰¹å¾
                'dynamic_attributes': {'start': 54, 'end': 67, 'dim': 13}, # åŠ¨æ€å±æ€§ç‰¹å¾
                'heterogeneous_type': {'start': 67, 'end': 84, 'dim': 17}, # å¼‚æ„ç±»å‹ç‰¹å¾
                'categorical': {'start': 84, 'end': 99, 'dim': 15}         # åˆ†ç±»ç‰¹å¾
            },
            # é™„åŠ ç‰¹å¾
            'sequence_features': {'start': 99, 'end': 131, 'dim': 32},    # æ—¶åºç‰¹å¾
            'graph_structure': {'start': 131, 'end': 141, 'dim': 10},     # å›¾ç»“æ„ç‰¹å¾
            # æœ€ç»ˆæŠ•å½±
            'final_projection': {'input_dim': 141, 'output_dim': 128}
        }

        # è‡ªé€‚åº”æƒé‡ç®¡ç†å™¨
        self.layer_weights = {
            'hardware': 1.0,
            'onchain_behavior': 1.0,
            'network_topology': 1.0,
            'dynamic_attributes': 1.0,
            'heterogeneous_type': 1.0,
            'categorical': 1.0,
            'sequence': 1.0,
            'graph_structure': 1.0
        }

    def extract_features_with_feedback(self, nodes: List[Node],
                                       step4_guidance: Optional[Dict[str, Any]] = None,
                                       epoch: int = 0) -> Dict[str, torch.Tensor]:
        """å¸¦åˆ†å±‚åé¦ˆçš„ç‰¹å¾æå–"""

        self._update_feedback_mode(step4_guidance, epoch)

        print(f"[CONFIG] æ‰§è¡Œåˆ†å±‚åé¦ˆç‰¹å¾æå– (Epoch {epoch}, Mode: {self.feedback_mode})")

        # 1. ä½¿ç”¨åŸºç¡€Pipelineæå–åŸå§‹ç‰¹å¾
        base_results = self.base_pipeline.extract_features(nodes)
        f_classic = base_results['f_classic']  # [N, 128] - å·²æŠ•å½±çš„ç‰¹å¾
        f_graph = base_results['f_graph']      # [N, 96]

        # 2. é‡æ–°æå–141ç»´çš„åŸå§‹æ‹¼æ¥ç‰¹å¾ï¼ˆæ¨¡æ‹Ÿç¬¬ä¸€æ­¥çš„å®é™…æµç¨‹ï¼‰
        raw_features_141 = self._extract_raw_141_features(nodes)  # [N, 141]

        # 3. åˆ†è§£ä¸ºåˆ†å±‚ç»“æ„
        layered_breakdown = self._decompose_to_layers(raw_features_141)

        # 4. åº”ç”¨åé¦ˆè°ƒæ•´
        if step4_guidance and self.feedback_mode != 'cold_start':
            adjusted_layered = self._apply_layered_feedback(layered_breakdown, step4_guidance)
        else:
            adjusted_layered = layered_breakdown

        # 5. é‡æ„ä¸º141ç»´ç‰¹å¾
        adjusted_raw_141 = self._reconstruct_from_layers(adjusted_layered)

        # 6. é‡æ–°æŠ•å½±åˆ°128ç»´
        adjusted_f_classic = self._adaptive_projection(adjusted_raw_141, step4_guidance)

        # 7. æ„å»ºå®Œæ•´ç»“æœ
        results = {
            'f_classic': adjusted_f_classic,      # [N, 128] - è°ƒæ•´åçš„æœ€ç»ˆç‰¹å¾
            'f_graph': f_graph,                   # [N, 96] - å›¾ç‰¹å¾ä¿æŒä¸å˜
            'nodes': nodes,

            # åˆ†å±‚ç‰¹å¾è¯¦ç»†ä¿¡æ¯
            'layered_breakdown': adjusted_layered,
            'raw_141_features': adjusted_raw_141,
            'original_raw_141': raw_features_141,

            # åé¦ˆçŠ¶æ€
            'feedback_applied': step4_guidance is not None,
            'feedback_mode': self.feedback_mode,
            'adaptation_info': {
                'epoch': epoch,
                'layer_weights': self.layer_weights.copy(),
                'guidance_keys': list(step4_guidance.keys()) if step4_guidance else []
            }
        }

        # 8. ç‰¹å¾èåˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.base_pipeline.use_fusion:
            f_fused, contrastive_loss = self.base_pipeline.fusion_pipeline(
                adjusted_f_classic, f_graph
            )
            results['f_fused'] = f_fused
            results['contrastive_loss'] = contrastive_loss

        # 9. è®°å½•é€‚åº”å†å²
        self._record_adaptation(step4_guidance, results, epoch)

        return results

    def _extract_raw_141_features(self, nodes: List[Node]) -> torch.Tensor:
        """æå–141ç»´åŸå§‹æ‹¼æ¥ç‰¹å¾ï¼ˆæ¨¡æ‹ŸUnifiedFeatureExtractorçš„å†…éƒ¨æµç¨‹ï¼‰"""

        # 1. æå–99ç»´ç»¼åˆç‰¹å¾
        comprehensive_features = self.base_pipeline.feature_extractor.comprehensive_extractor.extract_features(nodes)  # [N, 99]

        # 2. æå–32ç»´æ—¶åºç‰¹å¾
        sequence_features = self.base_pipeline.feature_extractor.sequence_encoder(nodes)  # [N, 32]

        # 3. æå–10ç»´å›¾ç»“æ„ç‰¹å¾
        graph_structure_features = self.base_pipeline.feature_extractor.graph_encoder(nodes)  # [N, 10]

        # 4. æ‹¼æ¥ä¸º141ç»´
        raw_141 = torch.cat([
            comprehensive_features,    # [N, 99]
            sequence_features,         # [N, 32]
            graph_structure_features   # [N, 10]
        ], dim=1)  # [N, 141]

        return raw_141

    def _decompose_to_layers(self, raw_141: torch.Tensor) -> Dict[str, torch.Tensor]:
        """å°†141ç»´ç‰¹å¾åˆ†è§£ä¸ºåˆ†å±‚ç»“æ„"""
        layered = {}

        # åˆ†è§£99ç»´åŸå§‹ç‰¹å¾ä¸º6å±‚
        for layer_name, info in self.feature_structure['original_layers'].items():
            start, end = info['start'], info['end']
            layered[layer_name] = raw_141[:, start:end]

        # æå–æ—¶åºç‰¹å¾
        seq_info = self.feature_structure['sequence_features']
        layered['sequence'] = raw_141[:, seq_info['start']:seq_info['end']]

        # æå–å›¾ç»“æ„ç‰¹å¾
        graph_info = self.feature_structure['graph_structure']
        layered['graph_structure'] = raw_141[:, graph_info['start']:graph_info['end']]

        return layered

    def _apply_layered_feedback(self, layered_features: Dict[str, torch.Tensor],
                                step4_guidance: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """åº”ç”¨åˆ†å±‚åé¦ˆè°ƒæ•´"""
        adjusted = {}

        # è·å–åé¦ˆæŒ‡å¯¼
        layer_weight_adjustments = step4_guidance.get('layer_weight_adjustments', {})
        layer_enhancement_factors = step4_guidance.get('layer_enhancement_factors', {})

        for layer_name, layer_features in layered_features.items():

            # 1. æƒé‡è°ƒæ•´
            weight_adjustment = layer_weight_adjustments.get(layer_name, 1.0)
            self.layer_weights[layer_name] = 0.7 * self.layer_weights[layer_name] + 0.3 * weight_adjustment

            # 2. å¢å¼ºå› å­
            enhancement_factor = layer_enhancement_factors.get(layer_name, 1.0)

            # 3. åº”ç”¨è°ƒæ•´
            adjusted_features = layer_features * self.layer_weights[layer_name] * enhancement_factor

            # 4. ç»´åº¦é€‰æ‹©ï¼ˆå¦‚æœæœ‰æŒ‡å¯¼ï¼‰
            dimension_selection = step4_guidance.get('layer_dimension_selection', {}).get(layer_name, {})
            if 'selection_ratio' in dimension_selection and dimension_selection['selection_ratio'] < 1.0:
                # ç®€åŒ–å®ç°ï¼šä¿ç•™é«˜æ–¹å·®ç»´åº¦
                feature_vars = torch.var(adjusted_features, dim=0)
                num_keep = max(1, int(adjusted_features.size(1) * dimension_selection['selection_ratio']))
                _, top_indices = torch.topk(feature_vars, num_keep)

                # åˆ›å»ºé›¶å¡«å……çš„å®Œæ•´ç»´åº¦ç‰¹å¾
                full_features = torch.zeros_like(adjusted_features)
                full_features[:, top_indices] = adjusted_features[:, top_indices]
                adjusted_features = full_features

            adjusted[layer_name] = adjusted_features

            print(f"  è°ƒæ•´ {layer_name}: æƒé‡={self.layer_weights[layer_name]:.3f}, å¢å¼º={enhancement_factor:.3f}")

        return adjusted

    def _reconstruct_from_layers(self, layered_features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """ä»åˆ†å±‚ç‰¹å¾é‡æ„ä¸º141ç»´ç‰¹å¾"""
        feature_parts = []

        # é‡æ„99ç»´åŸå§‹ç‰¹å¾éƒ¨åˆ†
        for layer_name in ['hardware', 'onchain_behavior', 'network_topology',
                           'dynamic_attributes', 'heterogeneous_type', 'categorical']:
            if layer_name in layered_features:
                feature_parts.append(layered_features[layer_name])

        # æ·»åŠ æ—¶åºç‰¹å¾
        if 'sequence' in layered_features:
            feature_parts.append(layered_features['sequence'])

        # æ·»åŠ å›¾ç»“æ„ç‰¹å¾
        if 'graph_structure' in layered_features:
            feature_parts.append(layered_features['graph_structure'])

        reconstructed = torch.cat(feature_parts, dim=1)  # [N, 141]
        return reconstructed

    def _adaptive_projection(self, raw_141: torch.Tensor,
                             step4_guidance: Optional[Dict[str, Any]]) -> torch.Tensor:
        """è‡ªé€‚åº”æŠ•å½±åˆ°128ç»´"""

        # ä½¿ç”¨åŸºç¡€Pipelineçš„æŠ•å½±å™¨
        projected = self.base_pipeline.feature_extractor.feature_projector(raw_141)  # [N, 128]

        # å¦‚æœæœ‰æŠ•å½±è°ƒæ•´æŒ‡å¯¼ï¼Œåº”ç”¨é¢å¤–çš„å˜æ¢
        if step4_guidance and 'projection_adjustment' in step4_guidance:
            proj_guidance = step4_guidance['projection_adjustment']
            if 'enhancement_factor' in proj_guidance:
                projected = projected * proj_guidance['enhancement_factor']

        return projected

    def _update_feedback_mode(self, step4_guidance: Optional[Dict[str, Any]], epoch: int):
        """æ›´æ–°åé¦ˆæ¨¡å¼"""
        if epoch == 0:
            self.feedback_mode = 'cold_start'
            self.feedback_enabled = False
        elif epoch < 5 and step4_guidance is not None:
            self.feedback_mode = 'warm_feedback'
            if not self.feedback_enabled:
                self.feedback_enabled = True
                print(f"ğŸ”„ å¯ç”¨åˆ†å±‚åé¦ˆæ¨¡å¼ (Epoch {epoch})")
        elif epoch >= 5 and step4_guidance is not None:
            self.feedback_mode = 'stable_feedback'

    def _record_adaptation(self, step4_guidance: Optional[Dict[str, Any]],
                           results: Dict[str, torch.Tensor], epoch: int):
        """è®°å½•é€‚åº”å†å²"""
        record = {
            'epoch': epoch,
            'feedback_mode': self.feedback_mode,
            'guidance_applied': step4_guidance is not None,
            'layer_weights': self.layer_weights.copy(),
            'feature_stats': {
                'f_classic_mean': float(torch.mean(results['f_classic'])),
                'f_classic_std': float(torch.std(results['f_classic'])),
                'raw_141_mean': float(torch.mean(results['raw_141_features'])),
            }
        }

        if step4_guidance:
            record['guidance_summary'] = {
                'layer_adjustments': len(step4_guidance.get('layer_weight_adjustments', {})),
                'enhancement_factors': len(step4_guidance.get('layer_enhancement_factors', {})),
                'dimension_selections': len(step4_guidance.get('layer_dimension_selection', {}))
            }

        self.adaptation_history.append(record)

    def get_adaptation_report(self) -> Dict[str, Any]:
        """è·å–é€‚åº”æŠ¥å‘Š"""
        return {
            'feedback_enabled': self.feedback_enabled,
            'current_mode': self.feedback_mode,
            'total_adaptations': len(self.adaptation_history),
            'current_layer_weights': self.layer_weights.copy(),
            'feature_structure': self.feature_structure
        }


class EnhancedFeedbackController(FeedbackController):
    """å¢å¼ºçš„åé¦ˆæ§åˆ¶å™¨ - æ”¯æŒåˆ†å±‚ç‰¹å¾åé¦ˆ"""

    def __init__(self):
        # åˆå§‹åŒ–ç‰¹å¾ç»´åº¦ï¼ˆå¯¹åº”ç¬¬ä¸€æ­¥çš„6å±‚ç»“æ„ï¼‰
        feature_dims = {
            'hardware': 17,
            'onchain_behavior': 17,
            'network_topology': 20,
            'dynamic_attributes': 13,
            'heterogeneous_type': 17,
            'categorical': 15,
            'sequence': 32,
            'graph_structure': 10
        }
        super().__init__(feature_dims)

        # ä¸“é—¨çš„åˆ†å±‚ç‰¹å¾æ¼”åŒ–å™¨
        self.layered_evolution = None

    def process_layered_feedback(self, step1_results: Dict[str, torch.Tensor],
                                 step3_shard_assignments: torch.Tensor,
                                 edge_index: torch.Tensor,
                                 evolve_gcn_model: nn.Module,
                                 epoch: int = 0) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """
        å¤„ç†åˆ†å±‚ç‰¹å¾åé¦ˆ

        Args:
            step1_results: ç¬¬ä¸€æ­¥çš„åˆ†å±‚ç‰¹å¾æå–ç»“æœ
            step3_shard_assignments: ç¬¬ä¸‰æ­¥åˆ†ç‰‡åˆ†é…ç»“æœ
            edge_index: ç½‘ç»œæ‹“æ‰‘
            evolve_gcn_model: EvolveGCNæ¨¡å‹
            epoch: å½“å‰è½®æ¬¡

        Returns:
            feedback_signal: åé¦ˆä¿¡å·
            step1_guidance: ç»™ç¬¬ä¸€æ­¥çš„åˆ†å±‚æŒ‡å¯¼
        """
        print(f"\nğŸ”„ å¤„ç†åˆ†å±‚ç‰¹å¾åé¦ˆ (Epoch {epoch})")

        # 1. ä»step1ç»“æœä¸­æå–åˆ†å±‚ç‰¹å¾
        layered_features = step1_results.get('layered_breakdown', {})
        final_features = step1_results.get('f_classic')  # [N, 128]

        if not layered_features:
            print("[WARNING] æœªæ‰¾åˆ°åˆ†å±‚ç‰¹å¾ï¼Œä½¿ç”¨æœ€ç»ˆç‰¹å¾è¿›è¡Œè¯„ä¼°")
            # åˆ›å»ºä¸´æ—¶åˆ†å±‚ç»“æ„ç”¨äºè¯„ä¼°
            layered_features = {'combined': final_features}

        # 2. æ€§èƒ½è¯„ä¼°ï¼ˆåŸºäºåˆ†å±‚ç‰¹å¾ï¼‰
        performance_metrics = self._evaluate_layered_performance(
            layered_features, step3_shard_assignments, edge_index
        )

        # 3. åˆ†å±‚é‡è¦æ€§åˆ†æ
        importance_matrix = self._analyze_layered_importance(
            layered_features, performance_metrics, evolve_gcn_model
        )

        # 4. åˆå§‹åŒ–åˆ†å±‚æ¼”åŒ–å™¨
        if self.layered_evolution is None:
            self.layered_evolution = DynamicFeatureEvolution(layered_features)

        # 5. ç”Ÿæˆåˆ†å±‚æŒ‡å¯¼
        step1_guidance = self._generate_layered_guidance(
            layered_features, importance_matrix, performance_metrics, epoch
        )

        # 6. è®¡ç®—åé¦ˆä¿¡å·
        feedback_signal = self._compute_layered_feedback_signal(performance_metrics)

        print(f"[SUCCESS] åˆ†å±‚åé¦ˆå¤„ç†å®Œæˆ")
        print(f"   åé¦ˆä¿¡å·: {[f'{x:.3f}' for x in feedback_signal.tolist()]}")
        print(f"   åˆ†å±‚æŒ‡å¯¼: {len(step1_guidance)} ä¸ªè°ƒæ•´é¡¹")

        return feedback_signal, step1_guidance

    def _evaluate_layered_performance(self, layered_features: Dict[str, torch.Tensor],
                                      shard_assignments: torch.Tensor,
                                      edge_index: torch.Tensor) -> Dict[str, torch.Tensor]:
        """è¯„ä¼°åˆ†å±‚ç‰¹å¾çš„æ€§èƒ½è´¡çŒ®"""

        # ä½¿ç”¨åŸæœ‰çš„æ€§èƒ½è¯„ä¼°å™¨ï¼Œä½†é€‚é…åˆ†å±‚è¾“å…¥
        if len(layered_features) == 1 and 'combined' in layered_features:
            # å•ä¸€ç‰¹å¾çš„æƒ…å†µ
            combined_features = layered_features['combined']
            eval_features = {
                'hardware': combined_features[:, :17] if combined_features.size(1) >= 17 else combined_features,
                'topology': combined_features[:, 17:37] if combined_features.size(1) >= 37 else combined_features[:, :min(20, combined_features.size(1))],
                'consensus': combined_features[:, 37:45] if combined_features.size(1) >= 45 else combined_features[:, :min(8, combined_features.size(1))],
                'semantic': combined_features[:, 45:] if combined_features.size(1) > 45 else combined_features[:, :min(15, combined_features.size(1))]
            }
        else:
            # çœŸå®çš„åˆ†å±‚ç‰¹å¾
            eval_features = {
                'hardware': layered_features.get('hardware', torch.zeros(shard_assignments.size(0), 17)),
                'topology': layered_features.get('network_topology', torch.zeros(shard_assignments.size(0), 20)),
                'consensus': layered_features.get('onchain_behavior', torch.zeros(shard_assignments.size(0), 17))[:, :8],  # å–å‰8ç»´ä½œä¸ºå…±è¯†ç‰¹å¾
                'semantic': layered_features.get('categorical', torch.zeros(shard_assignments.size(0), 15))
            }

        # ä½¿ç”¨åŸºç±»çš„æ€§èƒ½è¯„ä¼°å™¨
        return self.performance_evaluator(eval_features, shard_assignments, edge_index)

    def _analyze_layered_importance(self, layered_features: Dict[str, torch.Tensor],
                                    performance_metrics: Dict[str, torch.Tensor],
                                    evolve_gcn_model: nn.Module) -> Dict[str, Dict[str, float]]:
        """åˆ†æåˆ†å±‚ç‰¹å¾çš„é‡è¦æ€§"""
        return self.importance_analyzer.analyze_importance(
            layered_features, performance_metrics, evolve_gcn_model
        )

    def _generate_layered_guidance(self, layered_features: Dict[str, torch.Tensor],
                                   importance_matrix: Dict[str, Dict[str, float]],
                                   performance_metrics: Dict[str, torch.Tensor],
                                   epoch: int) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†å±‚æŒ‡å¯¼"""
        guidance = {
            'epoch': epoch,
            'guidance_type': 'layered_feedback',

            # å±‚çº§æƒé‡è°ƒæ•´
            'layer_weight_adjustments': {},

            # å±‚çº§å¢å¼ºå› å­
            'layer_enhancement_factors': {},

            # ç»´åº¦é€‰æ‹©æŒ‡å¯¼
            'layer_dimension_selection': {},

            # æŠ•å½±è°ƒæ•´
            'projection_adjustment': {},

            # ç‰¹å¾ç»“æ„ä¿¡æ¯
            'feature_structure_info': {
                'total_layers': len(layered_features),
                'layer_names': list(layered_features.keys())
            }
        }

        # ä¸ºæ¯ä¸€å±‚ç”Ÿæˆå…·ä½“æŒ‡å¯¼
        for layer_name, layer_features in layered_features.items():
            if layer_name in importance_matrix:
                importance = importance_matrix[layer_name].get('combined', 0.5)

                # æƒé‡è°ƒæ•´ï¼šåŸºäºé‡è¦æ€§å’Œæ€§èƒ½
                base_weight = 1.0
                performance_factor = self._compute_layer_performance_factor(
                    layer_name, performance_metrics
                )
                adjusted_weight = base_weight * importance * (1 + performance_factor)
                guidance['layer_weight_adjustments'][layer_name] = adjusted_weight

                # å¢å¼ºå› å­ï¼šé‡è¦å±‚å¢å¼ºï¼Œä¸é‡è¦å±‚æŠ‘åˆ¶
                if importance > 0.7:
                    enhancement_factor = 1.1
                elif importance < 0.3:
                    enhancement_factor = 0.9
                else:
                    enhancement_factor = 1.0
                guidance['layer_enhancement_factors'][layer_name] = enhancement_factor

                # ç»´åº¦é€‰æ‹©ï¼šä½é‡è¦æ€§å±‚è¿›è¡Œç»´åº¦å‹ç¼©
                selection_ratio = max(0.5, importance)  # è‡³å°‘ä¿ç•™50%
                guidance['layer_dimension_selection'][layer_name] = {
                    'selection_ratio': selection_ratio,
                    'importance_score': importance
                }

        # æŠ•å½±è°ƒæ•´
        avg_performance = sum(v.item() for v in performance_metrics.values()) / len(performance_metrics)
        if avg_performance < 0.6:
            guidance['projection_adjustment'] = {
                'enhancement_factor': 1.05,  # è½»å¾®å¢å¼º
                'reason': 'low_performance'
            }
        elif avg_performance > 0.8:
            guidance['projection_adjustment'] = {
                'enhancement_factor': 0.98,  # è½»å¾®æŠ‘åˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ
                'reason': 'high_performance'
            }

        return guidance

    def _compute_layer_performance_factor(self, layer_name: str,
                                          performance_metrics: Dict[str, torch.Tensor]) -> float:
        """è®¡ç®—å±‚çº§æ€§èƒ½å› å­"""
        factor = 0.0

        # æ ¹æ®å±‚æ¬¡ç±»å‹å’Œæ€§èƒ½æŒ‡æ ‡çš„å…³ç³»è®¡ç®—å› å­
        if layer_name in ['hardware', 'dynamic_attributes']:
            # ç¡¬ä»¶å’ŒåŠ¨æ€å±æ€§ä¸»è¦å½±å“è´Ÿè½½å‡è¡¡
            if 'balance_score' in performance_metrics:
                balance_score = performance_metrics['balance_score'].item()
                factor += (balance_score - 0.5) * 0.2

        elif layer_name in ['onchain_behavior', 'sequence']:
            # é“¾ä¸Šè¡Œä¸ºå’Œæ—¶åºç‰¹å¾ä¸»è¦å½±å“å®‰å…¨æ€§
            if 'security_score' in performance_metrics:
                security_score = performance_metrics['security_score'].item()
                factor += (security_score - 0.7) * 0.3

        elif layer_name in ['network_topology', 'graph_structure']:
            # ç½‘ç»œç›¸å…³ç‰¹å¾ä¸»è¦å½±å“è·¨ç‰‡äº¤æ˜“
            if 'cross_tx_rate' in performance_metrics:
                cross_tx_rate = performance_metrics['cross_tx_rate'].item()
                factor -= cross_tx_rate * 0.2  # è·¨ç‰‡äº¤æ˜“ç‡é«˜æ—¶é™ä½æƒé‡

        return np.clip(factor, -0.2, 0.2)  # é™åˆ¶å› å­èŒƒå›´

    def _compute_layered_feedback_signal(self, performance_metrics: Dict[str, torch.Tensor]) -> torch.Tensor:
        """è®¡ç®—åˆ†å±‚åé¦ˆä¿¡å·"""
        return torch.tensor([
            performance_metrics.get('balance_score', torch.tensor(0.5)).item(),
            performance_metrics.get('cross_tx_rate', torch.tensor(0.2)).item(),
            performance_metrics.get('security_score', torch.tensor(0.8)).item()
        ])







class IntegratedMultiScaleContrastiveLearning:
    """æ•´åˆçš„ç¬¬äºŒæ­¥å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ æ¨¡å— - ä¿®å¤ç‰ˆ"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # é»˜è®¤é…ç½®ï¼ˆåŸºäºmuti_scaleç›®å½•ä¸­çš„æœ€ä¼˜å‚æ•°ï¼‰
        self.config = config or {
            'input_dim': 128,            # ç¬¬ä¸€æ­¥è¾“å‡ºçš„ç‰¹å¾ç»´åº¦
            'hidden_dim': 64,            # éšè—å±‚ç»´åº¦
            'time_dim': 16,              # æ—¶åºåµŒå…¥ç»´åº¦
            'k_ratio': 0.9,              # é‡‡æ ·æ¯”ä¾‹
            'alpha': 0.3,                # å›¾çº§æŸå¤±æƒé‡
            'beta': 0.4,                 # èŠ‚ç‚¹çº§æŸå¤±æƒé‡
            'gamma': 0.3,                # å­å›¾çº§æŸå¤±æƒé‡
            'tau': 0.09,                 # æ¸©åº¦å‚æ•°
            'augment_type': 'edge',      # å¢å¼ºç±»å‹
            'num_node_types': 5,         # èŠ‚ç‚¹ç±»å‹æ•°
            'num_edge_types': 3,         # è¾¹ç±»å‹æ•°
            'learning_rate': 0.02,       # å­¦ä¹ ç‡
            'weight_decay': 9e-6,        # æƒé‡è¡°å‡
            'max_epochs': 50,            # æ¯æ¬¡è°ƒç”¨çš„æœ€å¤§è®­ç»ƒè½®æ¬¡
            'early_stopping_patience': 10,  # æ—©åœè€å¿ƒå€¼
            'target_loss': 0.25,          # ç›®æ ‡æŸå¤±
        }

        # åˆå§‹åŒ–æ¨¡å‹å’ŒæŠ•å½±å±‚
        self.model = None
        self.feature_projection = None  # å¤ç”¨çš„æŠ•å½±å±‚
        self.initialized = False
        self.training_history = []

    def initialize_model(self):
        """åˆå§‹åŒ–MSCIAæ¨¡å‹"""
        print(f"ğŸ§  åˆå§‹åŒ–å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ æ¨¡å‹...")

        # åˆ›å»ºæ—¶åºMSCIAæ¨¡å‹å¹¶ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        self.model = TemporalMSCIA(
            input_dim=self.config['input_dim'],
            hidden_dim=self.config['hidden_dim'],
            time_dim=self.config['time_dim'],
            k_ratio=self.config['k_ratio'],
            alpha=self.config['alpha'],
            beta=self.config['beta'],
            gamma=self.config['gamma'],
            tau=self.config['tau'],
            num_node_types=self.config['num_node_types'],
            num_edge_types=self.config['num_edge_types']
        ).to(self.device)

        self.initialized = True
        print(f"[SUCCESS] æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (è®¾å¤‡: {self.device})")

    def process_step1_output(self, step1_results: Dict[str, torch.Tensor],
                             edge_index: torch.Tensor,
                             epoch: int = 0) -> Dict[str, torch.Tensor]:
        """
        å¤„ç†ç¬¬ä¸€æ­¥çš„è¾“å‡ºï¼Œç”Ÿæˆç¬¬äºŒæ­¥çš„åµŒå…¥ - ä¿®å¤ç‰ˆ

        Args:
            step1_results: ç¬¬ä¸€æ­¥çš„ç‰¹å¾æå–ç»“æœ
            edge_index: ç½‘ç»œæ‹“æ‰‘è¾¹ç´¢å¼• [2, E]
            epoch: å½“å‰è½®æ¬¡

        Returns:
            {
                'embeddings': torch.Tensor,           # [N, hidden_dim] èŠ‚ç‚¹åµŒå…¥
                'temporal_embeddings': Dict,          # æ—¶åºåµŒå…¥å­—å…¸
                'contrastive_loss': float,            # å¯¹æ¯”å­¦ä¹ æŸå¤±
                'training_info': Dict                 # è®­ç»ƒä¿¡æ¯
            }
        """
        if not self.initialized:
            self.initialize_model()

        print(f"\nğŸ§  æ‰§è¡Œç¬¬äºŒæ­¥: å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹  (Epoch {epoch})")

        # 1. å‡†å¤‡è¾“å…¥æ•°æ® - ä¿®å¤æ ¼å¼åŒ¹é…
        input_data = self._prepare_input_data_fixed(step1_results, edge_index, epoch)

        # 2. è®­ç»ƒ/æ¨ç†æ¨¡å¼é€‰æ‹©
        if epoch == 0 or epoch % 5 == 0:  # å‘¨æœŸæ€§é‡è®­ç»ƒ
            embeddings, training_info = self._train_mode_fixed(input_data, epoch)
        else:
            embeddings, training_info = self._inference_mode_fixed(input_data, epoch)

        # 3. ç”Ÿæˆæ—¶åºåµŒå…¥
        temporal_embeddings = self._generate_temporal_embeddings(
            embeddings, input_data, epoch
        )

        # 4. æ„å»ºè¾“å‡º
        output = {
            'embeddings': embeddings,                    # [N, hidden_dim]
            'temporal_embeddings': temporal_embeddings,  # æ—¶åºåµŒå…¥å­—å…¸
            'contrastive_loss': training_info.get('loss', 0.0),
            'training_info': training_info,
            'model_state': {
                'epoch': epoch,
                'config': self.config,
                'initialized': self.initialized
            }
        }

        print(f"[SUCCESS] ç¬¬äºŒæ­¥å®Œæˆ: åµŒå…¥ç»´åº¦ {embeddings.shape}, æŸå¤± {output['contrastive_loss']:.4f}")

        return output

    def _prepare_input_data_fixed(self, step1_results: Dict[str, torch.Tensor],
                                  edge_index: torch.Tensor, epoch: int) -> Dict[str, Any]:
        """å‡†å¤‡MSCIAæ¨¡å‹çš„è¾“å…¥æ•°æ® - ä¿®å¤è®¾å¤‡å’Œæ ¼å¼é—®é¢˜"""

        # ä¼˜å…ˆä½¿ç”¨èåˆç‰¹å¾ï¼Œå…¶æ¬¡ç»å…¸ç‰¹å¾
        if 'f_fused' in step1_results and step1_results['f_fused'] is not None:
            node_features = step1_results['f_fused']  # [N, fused_dim]
        else:
            node_features = step1_results['f_classic']  # [N, 128]
        
        # ç¡®ä¿è¾“å…¥åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        node_features = node_features.to(self.device)
        edge_index = edge_index.to(self.device)
        
        # å¦‚æœç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼Œè¿›è¡ŒæŠ•å½±
        if node_features.size(1) != self.config['input_dim']:
            # åˆ›å»ºæˆ–å¤ç”¨æŠ•å½±å±‚ï¼Œç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            if (not hasattr(self, 'feature_projection') or 
                self.feature_projection is None or 
                self.feature_projection.in_features != node_features.size(1)):
                
                self.feature_projection = nn.Linear(
                    node_features.size(1), 
                    self.config['input_dim']
                ).to(self.device)
            
            node_features = self.feature_projection(node_features)

        # æ„å»ºç¬¦åˆmuti_scaleæœŸæœ›çš„è¾“å…¥æ ¼å¼
        num_nodes = node_features.size(0)
        
        # 1. æ„å»ºé‚»æ¥çŸ©é˜µ [N, N]ï¼ˆä¸æ˜¯batchå½¢å¼ï¼‰
        adjacency_matrix = self._build_adjacency_matrix_fixed(edge_index, num_nodes)
        
        # 2. ç”Ÿæˆæ—¶é—´æˆ³ [N]ï¼ˆä¸æ˜¯batchå½¢å¼ï¼‰
        timestamps = torch.arange(num_nodes, device=self.device, dtype=torch.float32)
        
        # 3. ç”Ÿæˆä¸­å¿ƒèŠ‚ç‚¹ç´¢å¼•ï¼ˆç”¨äºå­å›¾é‡‡æ ·ï¼‰
        num_centers = min(32, num_nodes)  # é™åˆ¶ä¸­å¿ƒèŠ‚ç‚¹æ•°é‡
        center_indices = torch.randperm(num_nodes, device=self.device)[:num_centers]
        
        # 4. èŠ‚ç‚¹ç±»å‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        node_types = self._extract_node_types(step1_results, num_nodes)

        return {
            # ç¬¦åˆTemporalMSCIAæœŸæœ›çš„æ ¼å¼
            'A_batch': adjacency_matrix.unsqueeze(0),      # [1, N, N] - æ·»åŠ batchç»´åº¦
            'X_batch': node_features.unsqueeze(0),         # [1, N, input_dim] - æ·»åŠ batchç»´åº¦
            'center_indices': center_indices,              # [num_centers]
            'timestamps': timestamps.unsqueeze(0),         # [1, N] - æ·»åŠ batchç»´åº¦
            'node_types': node_types,                      # [N] or None
            'edge_index': edge_index,                      # [2, E] - ä¿ç•™åŸæ ¼å¼ä¾›å…¶ä»–ç”¨é€”
            'num_nodes': num_nodes,
            'epoch': epoch
        }

    def _build_adjacency_matrix_fixed(self, edge_index: torch.Tensor, num_nodes: int) -> torch.Tensor:
        """æ„å»ºé‚»æ¥çŸ©é˜µ - ä¿®å¤ç‰ˆ"""
        adjacency = torch.zeros(num_nodes, num_nodes, device=self.device, dtype=torch.float32)

        if edge_index.size(1) > 0:  # ç¡®ä¿æœ‰è¾¹
            row, col = edge_index[0], edge_index[1]
            # å¤„ç†è¾¹ç´¢å¼•è¶…å‡ºèŒƒå›´çš„æƒ…å†µ
            valid_mask = (row < num_nodes) & (col < num_nodes) & (row >= 0) & (col >= 0)
            
            if valid_mask.sum() > 0:
                row, col = row[valid_mask], col[valid_mask]
                adjacency[row, col] = 1.0
                # å¦‚æœæ˜¯æ— å‘å›¾ï¼Œæ·»åŠ åå‘è¾¹
                adjacency[col, row] = 1.0

        # æ·»åŠ è‡ªç¯ï¼ˆé‡è¦ï¼šè®¸å¤šGNNæ¨¡å‹éœ€è¦è‡ªç¯ï¼‰
        adjacency.fill_diagonal_(1.0)

        return adjacency

    def _extract_node_types(self, step1_results: Dict[str, torch.Tensor], num_nodes: int) -> Optional[torch.Tensor]:
        """æå–èŠ‚ç‚¹ç±»å‹"""
        if 'nodes' in step1_results:
            try:
                nodes = step1_results['nodes']
                node_types = torch.zeros(num_nodes, dtype=torch.long, device=self.device)
                
                for i, node in enumerate(nodes[:num_nodes]):  # ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
                    if hasattr(node, 'node_type'):
                        # èŠ‚ç‚¹ç±»å‹æ˜ å°„
                        type_map = {
                            'validator': 0, 'full_node': 1, 'light_node': 2, 
                            'miner': 3, 'storage': 4, 'relay': 4
                        }
                        node_type_str = getattr(node, 'node_type', 'validator')
                        node_types[i] = type_map.get(node_type_str, 0)
                
                return node_types
            except Exception as e:
                print(f"    [WARNING] æå–èŠ‚ç‚¹ç±»å‹å¤±è´¥: {e}")
                return None
        
        return None

    def _train_mode_fixed(self, input_data: Dict[str, Any], epoch: int) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """è®­ç»ƒæ¨¡å¼ - ä¿®å¤ç‰ˆ"""
        print(f"  ğŸ”„ è®­ç»ƒæ¨¡å¼ (Epoch {epoch})")

        self.model.train()

        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            self.model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay']
        )

        # è®­ç»ƒå¾ªç¯
        best_loss = float('inf')
        patience_counter = 0
        epoch_losses = []

        max_train_epochs = min(self.config['max_epochs'], 15)  # é™åˆ¶è®­ç»ƒè½®æ¬¡é¿å…è¿‡é•¿

        for train_epoch in range(max_train_epochs):
            optimizer.zero_grad()

            try:
                # è°ƒç”¨TemporalMSCIAçš„forwardæ–¹æ³•
                # ä¼ å…¥ç¬¦åˆå…¶æœŸæœ›çš„å‚æ•°
                output = self.model(
                    A_batch=input_data['A_batch'],         # [1, N, N]
                    X_batch=input_data['X_batch'],         # [1, N, input_dim]
                    center_indices=input_data['center_indices'],  # [num_centers]
                    timestamps=input_data['timestamps'],   # [1, N]
                    node_types=input_data['node_types']    # [N] or None
                )
                
                # æ ¹æ®TemporalMSCIAçš„è¿”å›æ ¼å¼è§£æ
                if isinstance(output, tuple):
                    loss, embeddings = output
                elif isinstance(output, dict):
                    loss = output.get('loss', output.get('total_loss', torch.tensor(0.0)))
                    embeddings = output.get('embeddings', output.get('node_embeddings'))
                else:
                    # å¦‚æœè¿”å›å•ä¸€tensorï¼Œå‡è®¾æ˜¯æŸå¤±
                    loss = output
                    embeddings = self.model.get_embeddings() if hasattr(self.model, 'get_embeddings') else None

                # æ£€æŸ¥æŸå¤±å’ŒåµŒå…¥çš„æœ‰æ•ˆæ€§
                if embeddings is None:
                    print(f"    [WARNING] è®­ç»ƒè½®æ¬¡ {train_epoch}: æ— æ³•è·å–åµŒå…¥")
                    continue
                    
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"    [WARNING] è®­ç»ƒè½®æ¬¡ {train_epoch}: æ— æ•ˆæŸå¤± {loss}")
                    continue

                # åå‘ä¼ æ’­
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                optimizer.step()

                current_loss = loss.item()
                epoch_losses.append(current_loss)

                # æ—©åœæ£€æŸ¥
                if current_loss < best_loss:
                    best_loss = current_loss
                    patience_counter = 0
                else:
                    patience_counter += 1

                # è¾¾åˆ°ç›®æ ‡æŸå¤±æˆ–æ—©åœ
                if current_loss < self.config['target_loss'] or patience_counter >= self.config['early_stopping_patience']:
                    print(f"    [SUCCESS] è®­ç»ƒå®Œæˆ: æŸå¤± {current_loss:.4f} (è½®æ¬¡ {train_epoch+1})")
                    break

                if (train_epoch + 1) % 5 == 0:
                    print(f"    è®­ç»ƒè½®æ¬¡ {train_epoch+1}: æŸå¤± {current_loss:.4f}")

            except Exception as e:
                print(f"    [ERROR] è®­ç»ƒè½®æ¬¡ {train_epoch} å¤±è´¥: {e}")
                continue

        # è·å–æœ€ç»ˆåµŒå…¥
        self.model.eval()
        with torch.no_grad():
            try:
                final_output = self.model(
                    A_batch=input_data['A_batch'],
                    X_batch=input_data['X_batch'],
                    center_indices=input_data['center_indices'],
                    timestamps=input_data['timestamps'],
                    node_types=input_data['node_types']
                )
                
                if isinstance(final_output, tuple):
                    final_loss, final_embeddings = final_output
                    final_loss_value = final_loss.item()
                elif isinstance(final_output, dict):
                    final_loss_value = final_output.get('loss', final_output.get('total_loss', torch.tensor(0.0))).item()
                    final_embeddings = final_output.get('embeddings', final_output.get('node_embeddings'))
                else:
                    final_loss_value = final_output.item() if torch.is_tensor(final_output) else float(final_output)
                    final_embeddings = self.model.get_embeddings() if hasattr(self.model, 'get_embeddings') else None

                # å¦‚æœåµŒå…¥ä»ç„¶æœ‰é—®é¢˜ï¼Œä½¿ç”¨X_batchä½œä¸ºfallback
                if final_embeddings is None:
                    print(f"    [WARNING] æ— æ³•è·å–æœ€ç»ˆåµŒå…¥ï¼Œä½¿ç”¨è¾“å…¥ç‰¹å¾ä½œä¸ºfallback")
                    final_embeddings = input_data['X_batch'].squeeze(0)  # [N, input_dim]
                    
                # ç¡®ä¿åµŒå…¥ç»´åº¦æ­£ç¡®
                if final_embeddings.dim() == 3:  # [1, N, hidden_dim]
                    final_embeddings = final_embeddings.squeeze(0)  # [N, hidden_dim]
                    
            except Exception as e:
                print(f"    [ERROR] è·å–æœ€ç»ˆåµŒå…¥å¤±è´¥: {e}")
                # ç”Ÿæˆé»˜è®¤åµŒå…¥
                num_nodes = input_data['num_nodes']
                final_embeddings = torch.randn(num_nodes, self.config['hidden_dim'], device=self.device)
                final_loss_value = float('inf')

        training_info = {
            'mode': 'train',
            'loss': final_loss_value,
            'best_loss': best_loss,
            'epochs_trained': len(epoch_losses),
            'epoch_losses': epoch_losses,
            'converged': best_loss < self.config['target_loss']
        }

        # è®°å½•è®­ç»ƒå†å²
        self.training_history.append({
            'global_epoch': epoch,
            'training_info': training_info
        })

        return final_embeddings, training_info

    def _inference_mode_fixed(self, input_data: Dict[str, Any], epoch: int) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """æ¨ç†æ¨¡å¼ - ä¿®å¤ç‰ˆ"""
        print(f"  [SPEED] æ¨ç†æ¨¡å¼ (Epoch {epoch})")

        self.model.eval()

        with torch.no_grad():
            try:
                output = self.model(
                    A_batch=input_data['A_batch'],
                    X_batch=input_data['X_batch'],
                    center_indices=input_data['center_indices'],
                    timestamps=input_data['timestamps'],
                    node_types=input_data['node_types']
                )
                
                if isinstance(output, tuple):
                    loss, embeddings = output
                    loss_value = loss.item()
                elif isinstance(output, dict):
                    loss_value = output.get('loss', output.get('total_loss', torch.tensor(0.0))).item()
                    embeddings = output.get('embeddings', output.get('node_embeddings'))
                else:
                    loss_value = output.item() if torch.is_tensor(output) else float(output)
                    embeddings = self.model.get_embeddings() if hasattr(self.model, 'get_embeddings') else None

                if embeddings is None:
                    print(f"    [WARNING] æ¨ç†æ¨¡å¼æ— æ³•è·å–åµŒå…¥ï¼Œä½¿ç”¨è¾“å…¥ç‰¹å¾")
                    embeddings = input_data['X_batch'].squeeze(0)  # [N, input_dim]
                    
                if embeddings.dim() == 3:  # [1, N, hidden_dim]
                    embeddings = embeddings.squeeze(0)  # [N, hidden_dim]
                    
            except Exception as e:
                print(f"    [ERROR] æ¨ç†å¤±è´¥: {e}")
                num_nodes = input_data['num_nodes']
                embeddings = torch.randn(num_nodes, self.config['hidden_dim'], device=self.device)
                loss_value = float('inf')

        training_info = {
            'mode': 'inference',
            'loss': loss_value,
            'inference_successful': loss_value != float('inf')
        }

        return embeddings, training_info

    # ä¿æŒå…¶ä»–æ–¹æ³•ä¸å˜
    def _generate_temporal_embeddings(self, embeddings: torch.Tensor,
                                      input_data: Dict[str, Any],
                                      epoch: int) -> Dict[str, Any]:
        """ç”Ÿæˆæ—¶åºåµŒå…¥å­—å…¸"""
        temporal_embeddings = {}

        timestamps = input_data['timestamps'].squeeze(0) if input_data['timestamps'].dim() > 1 else input_data['timestamps']
        num_nodes = input_data['num_nodes']

        for i in range(num_nodes):
            node_id = f"node_{i}"
            timestamp = timestamps[i].item() if torch.is_tensor(timestamps[i]) else timestamps[i]

            if node_id not in temporal_embeddings:
                temporal_embeddings[node_id] = {}

            # ä½¿ç”¨epochä½œä¸ºæ—¶é—´ç»´åº¦çš„ä¸€éƒ¨åˆ†
            time_key = f"t_{epoch}_{timestamp}"
            temporal_embeddings[node_id][time_key] = embeddings[i].detach().cpu().numpy()

        return {
            'embeddings_dict': temporal_embeddings,
            'metadata': {
                'epoch': epoch,
                'num_nodes': num_nodes,
                'embedding_dim': embeddings.size(1),
                'timestamp_range': [timestamps.min().item(), timestamps.max().item()]
            }
        }

    def save_embeddings(self, temporal_embeddings: Dict, filepath: str):
        """ä¿å­˜æ—¶åºåµŒå…¥åˆ°æ–‡ä»¶"""
        with open(filepath, 'wb') as f:
            pickle.dump(temporal_embeddings, f)
        print(f"ğŸ“ æ—¶åºåµŒå…¥å·²ä¿å­˜: {filepath}")

    def load_embeddings(self, filepath: str) -> Dict:
        """ä»æ–‡ä»¶åŠ è½½æ—¶åºåµŒå…¥"""
        with open(filepath, 'rb') as f:
            temporal_embeddings = pickle.load(f)
        print(f"ğŸ“‚ æ—¶åºåµŒå…¥å·²åŠ è½½: {filepath}")
        return temporal_embeddings

    def get_model_state(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€"""
        return {
            'initialized': self.initialized,
            'config': self.config,
            'device': str(self.device),
            'training_history_length': len(self.training_history),
            'model_parameters': sum(p.numel() for p in self.model.parameters()) if self.model else 0
        }


# ä¿®æ”¹å®Œæ•´æµæ°´çº¿æ¼”ç¤ºç±»
class IntegratedFullPipelineDemo:
    """æ•´åˆçœŸå®ç¬¬äºŒæ­¥çš„å®Œæ•´å››æ­¥éª¤æµæ°´çº¿æ¼”ç¤º"""

    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

        # é…ç½®å‚æ•°
        self.config = {
            'num_epochs': 20,
            'feedback_start_epoch': 2,
            'save_results': True,
            'results_dir': './results',
            'sample_data_path': './large_samples.csv',
            # ç¬¬äºŒæ­¥ä¸“ç”¨é…ç½®
            'step2_config': {
                'input_dim': 128,
                'hidden_dim': 64,
                'time_dim': 16,
                'k_ratio': 0.9,
                'alpha': 0.3,
                'beta': 0.4,
                'gamma': 0.3,
                'tau': 0.09,
                'learning_rate': 0.02,
                'weight_decay': 9e-6,
                'max_epochs': 30,
                'target_loss': 0.25
            }
        }

        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(self.config['results_dir'], exist_ok=True)

        # æµæ°´çº¿å†å²è®°å½•
        self.pipeline_history = {
            'step1_features': [],
            'step2_embeddings': [],
            'step3_sharding': [],
            'step4_feedback': [],
            'performance_metrics': []
        }

        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()

    def _initialize_components(self):
        """åˆå§‹åŒ–å„æ­¥éª¤ç»„ä»¶"""
        print("åˆå§‹åŒ–å„æ­¥éª¤ç»„ä»¶...")

        # ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–æµæ°´çº¿
        print("- åˆå§‹åŒ–ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–æµæ°´çº¿")
        base_pipeline = Pipeline(use_fusion=True, save_adjacency=True)  # å¯ç”¨é‚»æ¥çŸ©é˜µä¿å­˜
        self.step1_pipeline = LayeredFeedbackFeatureExtractor(base_pipeline)

        # ç¬¬äºŒæ­¥: æ•´åˆçš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
        print("- åˆå§‹åŒ–ç¬¬äºŒæ­¥: å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ")
        self.step2_mscia = IntegratedMultiScaleContrastiveLearning(self.config['step2_config'])

        # ç¬¬ä¸‰æ­¥: åŠ¨æ€åˆ†ç‰‡ï¼ˆä½¿ç”¨çœŸå®å®ç°æˆ–æ¨¡æ‹Ÿï¼‰
        print("- åˆå§‹åŒ–ç¬¬ä¸‰æ­¥: åŠ¨æ€åˆ†ç‰‡")
        self.dynamic_sharder = self._create_enhanced_dynamic_sharder()

        # ç¬¬å››æ­¥: å¢å¼ºåé¦ˆæ§åˆ¶å™¨
        print("- åˆå§‹åŒ–ç¬¬å››æ­¥: å¢å¼ºåé¦ˆæ§åˆ¶å™¨")
        self.feedback_controller = EnhancedFeedbackController()

        print("[SUCCESS] æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def _create_enhanced_dynamic_sharder(self):
        """åˆ›å»ºå¢å¼ºçš„åŠ¨æ€åˆ†ç‰‡å™¨ï¼ˆå¯ä»¥æ›¿æ¢ä¸ºçœŸå®å®ç°ï¼‰"""
        class EnhancedDynamicSharder(nn.Module):
            def __init__(self, embedding_dim=64, max_shards=8):
                super().__init__()
                self.embedding_dim = embedding_dim
                self.max_shards = max_shards

                # åˆ†ç‰‡æ•°é¢„æµ‹ç½‘ç»œ
                self.shard_num_predictor = nn.Sequential(
                    nn.Linear(embedding_dim, 32),
                    nn.ReLU(),
                    nn.Linear(32, 16),
                    nn.ReLU(),
                    nn.Linear(16, 1),
                    nn.Sigmoid()
                )

                # åˆ†ç‰‡åˆ†é…ç½‘ç»œ
                self.shard_classifier = nn.Sequential(
                    nn.Linear(embedding_dim, 128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(128, max_shards)
                )

            def forward(self, embeddings, feedback_signal=None):
                # é¢„æµ‹åˆ†ç‰‡æ•°é‡
                shard_num_raw = self.shard_num_predictor(embeddings.mean(dim=0, keepdim=True))
                predicted_num_shards = max(2, int(shard_num_raw.item() * self.max_shards) + 1)

                # åˆ†ç‰‡åˆ†é…
                logits = self.shard_classifier(embeddings)[:, :predicted_num_shards]

                # å¦‚æœæœ‰åé¦ˆä¿¡å·ï¼Œè°ƒæ•´logits
                if feedback_signal is not None:
                    balance_factor = feedback_signal[0].item()  # è´Ÿè½½å‡è¡¡å› å­
                    if balance_factor < 0.5:  # è´Ÿè½½ä¸å‡è¡¡æ—¶ï¼Œå¢åŠ éšæœºæ€§
                        noise = torch.randn_like(logits) * 0.1
                        logits = logits + noise

                shard_assignments = torch.softmax(logits, dim=1)

                # è®¡ç®—æŸå¤±
                entropy_loss = -torch.mean(torch.sum(shard_assignments * torch.log(shard_assignments + 1e-8), dim=1))
                balance_loss = torch.std(torch.sum(shard_assignments, dim=0))
                total_loss = entropy_loss + 0.1 * balance_loss

                return shard_assignments, total_loss

        return EnhancedDynamicSharder().to(self.device)

    def run_step2_contrastive_learning(self, step1_output: Dict[str, torch.Tensor],
                                       edge_index: torch.Tensor,
                                       epoch: int) -> Dict[str, torch.Tensor]:
        """ç¬¬äºŒæ­¥: çœŸå®çš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ """
        print(f"\nğŸ§  æ‰§è¡Œç¬¬äºŒæ­¥: å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹  (Epoch {epoch})...")

        # ä½¿ç”¨æ•´åˆçš„MSCIAæ¨¡å‹
        step2_output = self.step2_mscia.process_step1_output(
            step1_output, edge_index, epoch
        )

        # è®°å½•åµŒå…¥å†å²
        embedding_record = {
            'epoch': epoch,
            'input_features_shape': step1_output['f_classic'].shape,
            'embeddings_shape': step2_output['embeddings'].shape,
            'contrastive_loss': step2_output['contrastive_loss'],
            'training_mode': step2_output['training_info']['mode'],
            'converged': step2_output['training_info'].get('converged', False),
            'embedding_stats': {
                'mean': float(torch.mean(step2_output['embeddings'])),
                'std': float(torch.std(step2_output['embeddings'])),
                'min': float(torch.min(step2_output['embeddings'])),
                'max': float(torch.max(step2_output['embeddings']))
            }
        }

        self.pipeline_history['step2_embeddings'].append(embedding_record)

        # ä¿å­˜æ—¶åºåµŒå…¥ï¼ˆå‘¨æœŸæ€§ä¿å­˜ï¼‰
        if epoch % 5 == 0:
            embeddings_path = os.path.join(self.config['results_dir'], f'temporal_embeddings_epoch_{epoch}.pkl')
            self.step2_mscia.save_embeddings(step2_output['temporal_embeddings'], embeddings_path)

        print(f"[SUCCESS] ç¬¬äºŒæ­¥å®Œæˆ:")
        print(f"  - åµŒå…¥ç»´åº¦: {step2_output['embeddings'].shape}")
        print(f"  - å¯¹æ¯”æŸå¤±: {step2_output['contrastive_loss']:.4f}")
        print(f"  - è®­ç»ƒæ¨¡å¼: {step2_output['training_info']['mode']}")
        if 'converged' in step2_output['training_info']:
            print(f"  - æ”¶æ•›çŠ¶æ€: {'æ˜¯' if step2_output['training_info']['converged'] else 'å¦'}")

        return step2_output

    def run_step3_dynamic_sharding(self, step2_output: Dict[str, torch.Tensor],
                                   edge_index: torch.Tensor,
                                   epoch: int,
                                   feedback_signal: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """ç¬¬ä¸‰æ­¥: å¢å¼ºçš„åŠ¨æ€åˆ†ç‰‡"""
        print(f"\n[SPEED] æ‰§è¡Œç¬¬ä¸‰æ­¥: åŠ¨æ€åˆ†ç‰‡ (Epoch {epoch})...")

        embeddings = step2_output['embeddings'].to(self.device)

        # åŠ¨æ€åˆ†ç‰‡å¤„ç†
        shard_assignments, shard_loss = self.dynamic_sharder(embeddings, feedback_signal)

        # è®¡ç®—åˆ†ç‰‡ç»Ÿè®¡
        hard_assignments = torch.argmax(shard_assignments, dim=1)
        num_shards = shard_assignments.size(1)
        shard_sizes = [(hard_assignments == i).sum().item() for i in range(num_shards)]

        # è®¡ç®—æ›´è¯¦ç»†çš„å¹³è¡¡æŒ‡æ ‡
        balance_coefficient = np.std(shard_sizes) / (np.mean(shard_sizes) + 1e-8)

        # è®¡ç®—è·¨ç‰‡è¾¹æ¯”ä¾‹
        cross_shard_edges = 0
        total_edges = edge_index.size(1)
        if total_edges > 0:
            u, v = edge_index[0], edge_index[1]
            valid_mask = (u < len(hard_assignments)) & (v < len(hard_assignments))
            if valid_mask.sum() > 0:
                valid_u, valid_v = u[valid_mask], v[valid_mask]
                cross_shard_edges = (hard_assignments[valid_u] != hard_assignments[valid_v]).sum().item()

        cross_shard_ratio = cross_shard_edges / max(total_edges, 1)

        # æ„å»ºè¾“å‡º
        output = {
            'shard_assignments': shard_assignments,
            'hard_assignments': hard_assignments,
            'shard_loss': shard_loss,
            'predicted_shards': num_shards,
            'shard_sizes': shard_sizes,
            'balance_coefficient': balance_coefficient,
            'cross_shard_ratio': cross_shard_ratio,
            'cross_shard_edges': cross_shard_edges,
            'total_edges': total_edges,
            'sharding_quality': {
                'balance_score': max(0, 1 - balance_coefficient),
                'efficiency_score': max(0, 1 - cross_shard_ratio),
                'size_variance': np.var(shard_sizes)
            }
        }

        # è®°å½•åˆ†ç‰‡å†å²
        sharding_record = {
            'epoch': epoch,
            'shard_loss': float(shard_loss),
            'num_shards': num_shards,
            'shard_sizes': shard_sizes,
            'balance_coefficient': balance_coefficient,
            'cross_shard_ratio': cross_shard_ratio,
            'feedback_used': feedback_signal is not None,
            'embeddings_source': step2_output['training_info']['mode'],
            'quality_metrics': output['sharding_quality']
        }

        self.pipeline_history['step3_sharding'].append(sharding_record)

        print(f"[SUCCESS] ç¬¬ä¸‰æ­¥å®Œæˆ:")
        print(f"  - åˆ†ç‰‡æ•°é‡: {num_shards}")
        print(f"  - åˆ†ç‰‡æŸå¤±: {shard_loss:.4f}")
        print(f"  - è´Ÿè½½å‡è¡¡ç³»æ•°: {balance_coefficient:.3f}")
        print(f"  - è·¨ç‰‡äº¤æ˜“æ¯”ä¾‹: {cross_shard_ratio:.3f}")
        print(f"  - åˆ†ç‰‡å¤§å°: {shard_sizes}")

        return output

    def run_complete_pipeline(self, save_results: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å››æ­¥éª¤æµæ°´çº¿ - æ•´åˆçœŸå®ç¬¬äºŒæ­¥"""
        print("=" * 70)
        print("[START] å¼€å§‹å®Œæ•´çš„å››æ­¥éª¤åŒºå—é“¾åˆ†ç‰‡æµæ°´çº¿ (æ•´åˆçœŸå®ç¬¬äºŒæ­¥)")
        print("=" * 70)

        start_time = datetime.now()

        try:
            # ç”Ÿæˆç¤ºä¾‹æ•°æ®
            nodes = self.generate_sample_nodes()
            edge_index = self.generate_sample_network_topology(len(nodes))

            # å½“å‰åé¦ˆæŒ‡å¯¼çŠ¶æ€
            current_step1_guidance = None

            # ä¸»è®­ç»ƒå¾ªç¯
            for epoch in range(self.config['num_epochs']):
                print(f"\n{'='*25} EPOCH {epoch+1}/{self.config['num_epochs']} {'='*25}")

                # ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–
                step1_output = self.run_step1_feature_extraction(
                    nodes, current_step1_guidance, epoch
                )

                # ç¬¬äºŒæ­¥: çœŸå®çš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
                step2_output = self.run_step2_contrastive_learning(
                    step1_output, edge_index, epoch
                )

                # ç¬¬ä¸‰æ­¥: å¢å¼ºçš„åŠ¨æ€åˆ†ç‰‡
                feedback_signal = None
                if epoch > 0 and hasattr(self, 'last_feedback_signal'):
                    feedback_signal = self.last_feedback_signal

                step3_output = self.run_step3_dynamic_sharding(
                    step2_output, edge_index, epoch, feedback_signal
                )

                # ç¬¬å››æ­¥: åˆ†å±‚åé¦ˆä¼˜åŒ–
                feedback_signal, next_step1_guidance = self.run_step4_feedback_optimization(
                    step1_output, step3_output, edge_index, epoch
                )

                # ä¿å­˜åé¦ˆä¿¡å·å’ŒæŒ‡å¯¼ä¾›ä¸‹ä¸€è½®ä½¿ç”¨
                self.last_feedback_signal = feedback_signal
                current_step1_guidance = next_step1_guidance

                # è®°å½•æ•´ä½“æ€§èƒ½
                epoch_performance = {
                    'epoch': epoch,
                    'step1_mode': step1_output.get('feedback_mode', 'unknown'),
                    'step2_loss': step2_output['contrastive_loss'],
                    'step2_mode': step2_output['training_info']['mode'],
                    'step3_loss': float(step3_output['shard_loss']),
                    'num_shards': step3_output['predicted_shards'],
                    'balance_score': feedback_signal[0].item(),
                    'cross_tx_rate': feedback_signal[1].item(),
                    'security_score': feedback_signal[2].item(),
                    'feedback_active': bool(current_step1_guidance),
                    'sharding_quality': step3_output['sharding_quality'],
                    'integration_metrics': {
                        'step1_layers': len(step1_output.get('layered_breakdown', {})),
                        'step2_converged': step2_output['training_info'].get('converged', False),
                        'step3_balance_coeff': step3_output['balance_coefficient'],
                        'cross_shard_ratio': step3_output['cross_shard_ratio']
                    }
                }

                self.pipeline_history['performance_metrics'].append(epoch_performance)

                # æ¯5è½®è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                if (epoch + 1) % 5 == 0:
                    self._print_integrated_epoch_summary(epoch_performance)

        except Exception as e:
            print(f"[ERROR] æµæ°´çº¿æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # æ±‡æ€»ç»“æœ
        final_results = self._compile_integrated_final_results(duration)

        # ä¿å­˜ç»“æœ
        if save_results and self.config['save_results']:
            self._save_integrated_results(final_results)

        self._visualize_integrated_results()

        print("\n" + "=" * 70)
        print("[SUCCESS] å®Œæ•´å››æ­¥éª¤æµæ°´çº¿æ‰§è¡Œå®Œæˆ (æ•´åˆçœŸå®ç¬¬äºŒæ­¥)!")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f}ç§’")
        print(f"ğŸ§  ç¬¬äºŒæ­¥æ¨¡å‹çŠ¶æ€: {self.step2_mscia.get_model_state()}")
        adaptation_report = self.step1_pipeline.get_adaptation_report()
        print(f"ğŸ”„ åé¦ˆæ¨¡å¼: {adaptation_report.get('current_mode', 'unknown')}")
        print("=" * 70)

        return final_results

    # å…¶ä»–æ–¹æ³•çš„å®ç°...
    def generate_sample_nodes(self, num_nodes: int = 100) -> List[Node]:
        """ç”Ÿæˆç¤ºä¾‹èŠ‚ç‚¹æ•°æ®"""
        if os.path.exists(self.config['sample_data_path']):
            print(f"ä» {self.config['sample_data_path']} åŠ è½½èŠ‚ç‚¹æ•°æ®...")
            return load_nodes_from_csv(self.config['sample_data_path'])
        else:
            print(f"ç”Ÿæˆ {num_nodes} ä¸ªç¤ºä¾‹èŠ‚ç‚¹...")
            nodes = []
            for i in range(num_nodes):
                node = Node(
                    node_id=i,
                    node_type='validator',
                    hardware_config={
                        'cpu_cores': np.random.randint(4, 33),
                        'memory_gb': np.random.randint(8, 65),
                        'storage_gb': np.random.randint(100, 1001),
                        'network_mbps': np.random.randint(100, 1001)
                    },
                    performance_metrics={
                        'tps': np.random.uniform(100, 1000),
                        'latency_ms': np.random.uniform(10, 100),
                        'availability': np.random.uniform(0.9, 1.0)
                    }
                )
                nodes.append(node)
            return nodes

    def generate_sample_network_topology(self, num_nodes: int) -> torch.Tensor:
        """ç”Ÿæˆç¤ºä¾‹ç½‘ç»œæ‹“æ‰‘"""
        num_edges = min(num_nodes * 3, num_nodes * (num_nodes - 1) // 2)
        edges = []
        for _ in range(num_edges):
            u = np.random.randint(0, num_nodes)
            v = np.random.randint(0, num_nodes)
            if u != v:
                edges.append([u, v])

        if edges:
            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        else:
            edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long).t().contiguous()

        return edge_index.to(self.device)

    # ä»LayeredFeedbackFeatureExtractorç±»å¤ç”¨ç¬¬ä¸€æ­¥å®ç°
    def run_step1_feature_extraction(self, nodes: List[Node],
                                     step4_guidance: Optional[Dict[str, Any]] = None,
                                     epoch: int = 0) -> Dict[str, torch.Tensor]:
        """ç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå–"""
        print(f"\n[CONFIG] æ‰§è¡Œç¬¬ä¸€æ­¥: åˆ†å±‚åé¦ˆç‰¹å¾æå– (Epoch {epoch})")

        results = self.step1_pipeline.extract_features_with_feedback(
            nodes, step4_guidance, epoch
        )

        extraction_record = {
            'epoch': epoch,
            'f_classic_shape': results['f_classic'].shape,
            'f_graph_shape': results['f_graph'].shape,
            'feedback_applied': results.get('feedback_applied', False),
            'feedback_mode': results.get('feedback_mode', 'cold_start'),
            'layer_count': len(results.get('layered_breakdown', {}))
        }

        if 'f_fused' in results:
            extraction_record['f_fused_shape'] = results['f_fused'].shape

        self.pipeline_history['step1_features'].append(extraction_record)

        print(f" ç¬¬ä¸€æ­¥å®Œæˆ (æ¨¡å¼: {results.get('feedback_mode', 'unknown')}):")
        print(f"  - F_classic: {results['f_classic'].shape}")
        print(f"  - F_graph: {results['f_graph'].shape}")
        print(f"  - åˆ†å±‚ç‰¹å¾: {len(results.get('layered_breakdown', {}))} å±‚")
        if 'f_fused' in results:
            print(f"  - F_fused: {results['f_fused'].shape}")

        return results

    # ä»EnhancedFeedbackControllerç±»å¤ç”¨ç¬¬å››æ­¥å®ç°
    def run_step4_feedback_optimization(self, step1_output: Dict[str, torch.Tensor],
                                        step3_output: Dict[str, Any],
                                        edge_index: torch.Tensor,
                                        epoch: int) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """ç¬¬å››æ­¥: åˆ†å±‚åé¦ˆä¼˜åŒ–"""
        print(f"\n æ‰§è¡Œç¬¬å››æ­¥: åˆ†å±‚åé¦ˆä¼˜åŒ– (Epoch {epoch})...")

        if epoch < self.config['feedback_start_epoch']:
            print("- è·³è¿‡åé¦ˆä¼˜åŒ– (æœªåˆ°å¯åŠ¨è½®æ¬¡)")
            default_feedback = torch.tensor([0.5, 0.1, 0.8], device=self.device)
            return default_feedback, {}

        try:
            feedback_signal, step1_guidance = self.feedback_controller.process_layered_feedback(
                step1_output,
                step3_output['shard_assignments'],
                edge_index,
                self.step2_mscia.model if self.step2_mscia.model else None,
                epoch
            )

        except Exception as e:
            print(f"åé¦ˆå¤„ç†å‡ºé”™ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåé¦ˆ: {e}")

            balance_score = max(0.3, 1.0 - epoch * 0.02)
            cross_tx_rate = min(0.3, 0.1 + epoch * 0.01)
            security_score = max(0.6, 0.9 - epoch * 0.01)

            feedback_signal = torch.tensor([balance_score, cross_tx_rate, security_score], device=self.device)

            step1_guidance = {
                'epoch': epoch,
                'guidance_type': 'simulated',
                'layer_weight_adjustments': {
                    'hardware': 1.0 + (balance_score - 0.5) * 0.2,
                    'onchain_behavior': 1.0 + (security_score - 0.7) * 0.4,
                    'network_topology': 1.0 + (cross_tx_rate - 0.2) * -0.3,
                    'sequence': 1.0 + (security_score - 0.7) * 0.2,
                },
                'layer_enhancement_factors': {
                    'hardware': 1.0 if balance_score > 0.6 else 1.1,
                    'onchain_behavior': 1.1 if security_score < 0.7 else 1.0,
                    'network_topology': 0.9 if cross_tx_rate > 0.25 else 1.0
                }
            }

        feedback_record = {
            'epoch': epoch,
            'balance_score': feedback_signal[0].item(),
            'cross_tx_rate': feedback_signal[1].item(),
            'security_score': feedback_signal[2].item(),
            'has_guidance': bool(step1_guidance),
            'guidance_layers': len(step1_guidance.get('layer_weight_adjustments', {}))
        }

        self.pipeline_history['step4_feedback'].append(feedback_record)

        print(f" ç¬¬å››æ­¥å®Œæˆ: åé¦ˆä¿¡å· [{feedback_signal[0]:.3f}, {feedback_signal[1]:.3f}, {feedback_signal[2]:.3f}]")

        if step1_guidance:
            print(f"   ç”Ÿæˆåˆ†å±‚æŒ‡å¯¼: {len(step1_guidance.get('layer_weight_adjustments', {}))} å±‚æƒé‡è°ƒæ•´")

        return feedback_signal, step1_guidance

    def _print_integrated_epoch_summary(self, epoch_performance: Dict[str, Any]):
        """æ‰“å°æ•´åˆçš„è½®æ¬¡æ‘˜è¦"""
        print(f"\n Epoch {epoch_performance['epoch']} æ•´åˆæ€§èƒ½æ‘˜è¦:")
        print(f"   â€¢ ç¬¬ä¸€æ­¥æ¨¡å¼: {epoch_performance['step1_mode']}")
        print(f"   â€¢ ç¬¬äºŒæ­¥æŸå¤±: {epoch_performance['step2_loss']:.4f} (æ¨¡å¼: {epoch_performance['step2_mode']})")
        print(f"   â€¢ ç¬¬ä¸‰æ­¥æŸå¤±: {epoch_performance['step3_loss']:.4f}")
        print(f"   â€¢ åˆ†ç‰‡æ•°é‡: {epoch_performance['num_shards']}")
        print(f"   â€¢ è´Ÿè½½å‡è¡¡: {epoch_performance['balance_score']:.3f}")
        print(f"   â€¢ è·¨ç‰‡äº¤æ˜“ç‡: {epoch_performance['cross_tx_rate']:.3f}")
        print(f"   â€¢ å®‰å…¨åˆ†æ•°: {epoch_performance['security_score']:.3f}")
        print(f"   â€¢ åˆ†ç‰‡è´¨é‡:")
        for metric, value in epoch_performance['sharding_quality'].items():
            print(f"     - {metric}: {value:.3f}")

    def _compile_integrated_final_results(self, duration: float) -> Dict[str, Any]:
        """ç¼–è¯‘æ•´åˆçš„æœ€ç»ˆç»“æœ"""
        return {
            'execution_info': {
                'duration_seconds': duration,
                'total_epochs': self.config['num_epochs'],
                'feedback_start_epoch': self.config['feedback_start_epoch'],
                'device': str(self.device),
                'integration_type': 'real_step2_mscia'
            },
            'pipeline_history': self.pipeline_history,
            'step2_model_state': self.step2_mscia.get_model_state(),
            'adaptation_report': self.step1_pipeline.get_adaptation_report(),
            'final_metrics': {
                'avg_balance_score': np.mean([m['balance_score'] for m in self.pipeline_history['performance_metrics']]),
                'avg_cross_tx_rate': np.mean([m['cross_tx_rate'] for m in self.pipeline_history['performance_metrics']]),
                'avg_security_score': np.mean([m['security_score'] for m in self.pipeline_history['performance_metrics']]),
                'avg_step2_loss': np.mean([m['step2_loss'] for m in self.pipeline_history['performance_metrics']]),
                'step2_convergence_rate': sum(1 for m in self.pipeline_history['performance_metrics']
                                              if m.get('integration_metrics', {}).get('step2_converged', False)) / len(self.pipeline_history['performance_metrics']),
                'total_feedback_activations': sum(1 for m in self.pipeline_history['performance_metrics'] if m['feedback_active'])
            }
        }

    def _save_integrated_results(self, results: Dict[str, Any]):
        """ä¿å­˜æ•´åˆçš„ç»“æœ"""
        results_path = os.path.join(self.config['results_dir'], 'integrated_full_pipeline_results.json')
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        print(f" æ•´åˆç»“æœå·²ä¿å­˜: {results_path}")

    def _visualize_integrated_results(self):
        """å¯è§†åŒ–æ•´åˆçš„ç»“æœ"""
        try:
            import matplotlib.pyplot as plt

            epochs = [m['epoch'] for m in self.pipeline_history['performance_metrics']]
            balance_scores = [m['balance_score'] for m in self.pipeline_history['performance_metrics']]
            step2_losses = [m['step2_loss'] for m in self.pipeline_history['performance_metrics']]
            step3_losses = [m['step3_loss'] for m in self.pipeline_history['performance_metrics']]

            plt.figure(figsize=(15, 10))

            plt.subplot(2, 3, 1)
            plt.plot(epochs, balance_scores, 'b-', label='Balance Score')
            plt.title('è´Ÿè½½å‡è¡¡åˆ†æ•°')
            plt.xlabel('Epoch')
            plt.ylabel('Score')
            plt.grid(True)

            plt.subplot(2, 3, 2)
            plt.plot(epochs, step2_losses, 'r-', label='Step2 Loss')
            plt.title('ç¬¬äºŒæ­¥å¯¹æ¯”å­¦ä¹ æŸå¤±')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True)

            plt.subplot(2, 3, 3)
            plt.plot(epochs, step3_losses, 'g-', label='Step3 Loss')
            plt.title('ç¬¬ä¸‰æ­¥åˆ†ç‰‡æŸå¤±')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True)

            # æ·»åŠ æ•´åˆçš„å¯è§†åŒ–
            if len(self.pipeline_history['step2_embeddings']) > 0:
                embedding_means = [e['embedding_stats']['mean'] for e in self.pipeline_history['step2_embeddings']]
                plt.subplot(2, 3, 4)
                plt.plot(epochs, embedding_means, 'm-', label='Embedding Mean')
                plt.title('åµŒå…¥ç‰¹å¾å‡å€¼')
                plt.xlabel('Epoch')
                plt.ylabel('Mean Value')
                plt.grid(True)

            plt.tight_layout()

            plot_path = os.path.join(self.config['results_dir'], 'integrated_performance_visualization.png')
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ æ•´åˆæ€§èƒ½å¯è§†åŒ–å·²ä¿å­˜: {plot_path}")

            plt.show()

        except ImportError:
            print(" matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        except Exception as e:
            print(f" å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print(" å››æ­¥éª¤åŒºå—é“¾åˆ†ç‰‡æµæ°´çº¿ - å®Œå…¨æ•´åˆçœŸå®ç¬¬äºŒæ­¥å’Œç¬¬ä¸‰æ­¥")
    print("=" * 80)

    # åˆ›å»ºå®Œå…¨æ•´åˆçš„æµæ°´çº¿æ¼”ç¤ºå®ä¾‹
    demo = FullIntegratedPipelineDemo()

    # è¿è¡Œå®Œæ•´æµæ°´çº¿
    results = demo.run_complete_pipeline(save_results=True)

    # æ‰“å°æœ€ç»ˆæ‘˜è¦
    print(f"\n æœ€ç»ˆæ‰§è¡Œæ‘˜è¦:")
    print(f"   â€¢ æ‰§è¡Œæ—¶é•¿: {results['execution_info']['duration_seconds']:.2f}ç§’")
    print(f"   â€¢ æ€»è½®æ¬¡: {results['execution_info']['total_epochs']}")
    print(f"   â€¢ æ•´åˆç±»å‹: {results['execution_info']['integration_type']}")
    print(f"   â€¢ å¹³å‡è´Ÿè½½å‡è¡¡: {results['final_metrics']['avg_balance_score']:.3f}")
    print(f"   â€¢ å¹³å‡ç¬¬äºŒæ­¥æŸå¤±: {results['final_metrics']['avg_step2_loss']:.3f}")
    print(f"   â€¢ å¹³å‡ç¬¬ä¸‰æ­¥æŸå¤±: {results['final_metrics']['avg_step3_loss']:.3f}")
    print(f"   â€¢ ç¬¬äºŒæ­¥æ”¶æ•›ç‡: {results['final_metrics']['step2_convergence_rate']:.2%}")
    print(f"   â€¢ ç¬¬ä¸‰æ­¥æ”¶æ•›ç‡: {results['final_metrics']['step3_convergence_rate']:.2%}")

    step2_state = results['step2_model_state']
    step3_state = results['step3_model_state']
    print(f"\n ç¬¬äºŒæ­¥æ¨¡å‹æœ€ç»ˆçŠ¶æ€:")
    print(f"   â€¢ åˆå§‹åŒ–çŠ¶æ€: {'å·²å®Œæˆ' if step2_state['initialized'] else 'æœªå®Œæˆ'}")
    print(f"   â€¢ æ¨¡å‹å‚æ•°é‡: {step2_state['model_parameters']:,}")
    print(f"   â€¢ è®­ç»ƒå†å²é•¿åº¦: {step2_state['training_history_length']}")

    print(f"\n ç¬¬ä¸‰æ­¥æ¨¡å‹æœ€ç»ˆçŠ¶æ€:")
    print(f"   â€¢ åˆå§‹åŒ–çŠ¶æ€: {'å·²å®Œæˆ' if step3_state['initialized'] else 'æœªå®Œæˆ'}")
    print(f"   â€¢ EvolveGCNå‚æ•°é‡: {step3_state['model_parameters']:,}")
    print(f"   â€¢ åˆ†ç‰‡æ¨¡å—å‚æ•°é‡: {step3_state['sharding_parameters']:,}")
    print(f"   â€¢ å†å²çŠ¶æ€é•¿åº¦: {step3_state['history_length']}")
    print(f"   â€¢ è®­ç»ƒå†å²é•¿åº¦: {step3_state['training_history_length']}")

    print("\n å®Œå…¨æ•´åˆçœŸå®ç¬¬äºŒæ­¥å’Œç¬¬ä¸‰æ­¥çš„æµæ°´çº¿æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    main()