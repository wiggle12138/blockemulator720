#!/usr/bin/env python3
"""
BlockEmulatoré›†æˆåˆ†ç‰‡ç³»ç»Ÿå®Œæ•´æµ‹è¯•
ä¸¥æ ¼æŒ‰ç…§å››æ­¥æµç¨‹ï¼šç‰¹å¾æå– â†’ å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹  â†’ EvolveGCNåˆ†ç‰‡ â‡„ æ€§èƒ½åé¦ˆ
è¿™æ˜¯æœ€ç»ˆé›†æˆåˆ°BlockEmulatorä¸­çš„åˆ†ç‰‡ç³»ç»Ÿæµ‹è¯•
"""

import sys
import time
import json
import logging
import warnings
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, List

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ è·¯å¾„ - æŒ‰BlockEmulatoré¡¹ç›®ç»“æ„
sys.path.append('.')
sys.path.append('./partition')
sys.path.append('./partition/feature')
sys.path.append('./muti_scale')
sys.path.append('./evolve_GCN')
sys.path.append('./evolve_GCN/models')
sys.path.append('./feedback')

class BlockEmulatorIntegratedShardingSystem:
    """
    BlockEmulatoré›†æˆåˆ†ç‰‡ç³»ç»Ÿ
    å®ç°å®Œæ•´çš„å››æ­¥é—­ç¯æµç¨‹ï¼Œå¯ä»¥é›†æˆåˆ°BlockEmulatorä¸­
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._get_default_config()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ç³»ç»ŸçŠ¶æ€
        self.current_epoch = 0
        self.performance_history = []
        self.sharding_history = []
        
        # ç»„ä»¶å®ä¾‹
        self.step1_pipeline = None
        self.step2_processor = None
        self.step3_sharding_module = None
        self.step4_feedback_engine = None
        
        logger.info("[START] BlockEmulatoré›†æˆåˆ†ç‰‡ç³»ç»Ÿåˆå§‹åŒ–")
        logger.info(f"   è®¾å¤‡: {self.device}")
        logger.info(f"   é…ç½®: {self.config['system_name']}")

    def _get_default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½® - é’ˆå¯¹BlockEmulatorä¼˜åŒ–"""
        return {
            'system_name': 'BlockEmulator-EvolveGCN-DynamicSharding',
            'version': '1.0.0',
            
            # ç¬¬ä¸€æ­¥é…ç½®
            'step1': {
                'feature_extraction_mode': 'comprehensive',
                'output_dim': 128,
                'save_adjacency': True
            },
            
            # ç¬¬äºŒæ­¥é…ç½®
            'step2': {
                'time_window': 3,
                'batch_size': 16,
                'hidden_dim': 64,
                'learning_rate': 0.02,
                'use_real_timestamps': True
            },
            
            # ç¬¬ä¸‰æ­¥é…ç½®
            'step3': {
                'base_shards': 3,
                'max_shards': 6,
                'embedding_dim': 64,
                'max_iterations': 3
            },
            
            # ç¬¬å››æ­¥é…ç½®
            'step4': {
                'enable_feedback': True,
                'convergence_threshold': 0.01,
                'max_feedback_iterations': 5
            },
            
            # ç³»ç»Ÿé›†æˆé…ç½®
            'integration': {
                'auto_apply_sharding': False,  # æ˜¯å¦è‡ªåŠ¨åº”ç”¨åˆ†ç‰‡ç»“æœåˆ°BlockEmulator
                'save_results': True,
                'result_path': './data_exchange',
                'enable_monitoring': True
            }
        }

    def initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        logger.info("[CONFIG] åˆå§‹åŒ–åˆ†ç‰‡ç³»ç»Ÿç»„ä»¶...")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–ç®¡é“
            from partition.feature.system_integration_pipeline import BlockEmulatorStep1Pipeline
            self.step1_pipeline = BlockEmulatorStep1Pipeline(
                use_comprehensive_features=True,
                save_adjacency=True,
                output_dir=self.config['integration']['result_path']
            )
            logger.info("[SUCCESS] ç¬¬ä¸€æ­¥ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"[WARNING] ç¬¬ä¸€æ­¥ç»„ä»¶åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
            self.step1_pipeline = None

        try:
            # ç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
            from muti_scale.realtime_mscia import RealtimeMSCIAProcessor
            from muti_scale.step2_config import Step2Config
            
            step2_config = Step2Config().get_blockemulator_integration_config()
            step2_config.update(self.config['step2'])
            
            self.step2_processor = RealtimeMSCIAProcessor(step2_config)
            logger.info("[SUCCESS] ç¬¬äºŒæ­¥ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"[ERROR] ç¬¬äºŒæ­¥ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

        try:
            # ç¬¬ä¸‰æ­¥ï¼šEvolveGCNåŠ¨æ€åˆ†ç‰‡
            from evolve_GCN.models.sharding_modules import DynamicShardingModule
            
            self.step3_sharding_module = DynamicShardingModule(
                embedding_dim=self.config['step3']['embedding_dim'],
                base_shards=self.config['step3']['base_shards'],
                max_shards=self.config['step3']['max_shards']
            ).to(self.device)
            logger.info("[SUCCESS] ç¬¬ä¸‰æ­¥ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"[ERROR] ç¬¬ä¸‰æ­¥ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

        try:
            # ç¬¬å››æ­¥ï¼šæ€§èƒ½åé¦ˆå¼•æ“
            from feedback.unified_feedback_engine import UnifiedFeedbackEngine
            
            feature_dims = {
                'node_features': self.config['step3']['embedding_dim'],
                'degree_centrality': 1,
                'betweenness_centrality': 1,
                'clustering_coefficient': 1,
                'pagerank': 1,
                'shard_balance': 1
            }
            
            self.step4_feedback_engine = UnifiedFeedbackEngine(
                feature_dims=feature_dims,
                device=self.device
            )
            logger.info("[SUCCESS] ç¬¬å››æ­¥ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"[WARNING] ç¬¬å››æ­¥ç»„ä»¶åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–åé¦ˆ: {e}")
            self.step4_feedback_engine = None

        logger.info("[TARGET] æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œç³»ç»Ÿå°±ç»ª")
        return True

    def run_complete_cycle(self, input_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„å››æ­¥åˆ†ç‰‡å¾ªç¯
        è¿™æ˜¯BlockEmulatorè°ƒç”¨çš„ä¸»è¦æ¥å£
        """
        logger.info("[START] å¼€å§‹å®Œæ•´åˆ†ç‰‡å¾ªç¯")
        logger.info("=" * 80)
        
        cycle_start_time = time.time()
        results = {
            'cycle_id': f"cycle_{self.current_epoch}",
            'timestamp': time.time(),
            'steps': {},
            'final_sharding': None,
            'performance_metrics': {},
            'status': 'running'
        }

        try:
            # ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–
            step1_result = self._execute_step1(input_data)
            results['steps']['step1'] = step1_result
            
            if not step1_result['success']:
                raise Exception("ç¬¬ä¸€æ­¥å¤±è´¥")

            # ç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
            step2_result = self._execute_step2(step1_result['data'])
            results['steps']['step2'] = step2_result
            
            if not step2_result['success']:
                raise Exception("ç¬¬äºŒæ­¥å¤±è´¥")

            # ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥çš„è¿­ä»£å¾ªç¯
            feedback_loop_result = self._execute_feedback_loop(step2_result['data'])
            results['steps']['feedback_loop'] = feedback_loop_result
            
            if not feedback_loop_result['success']:
                raise Exception("åé¦ˆå¾ªç¯å¤±è´¥")

            # æ•´ç†æœ€ç»ˆç»“æœ
            results['final_sharding'] = feedback_loop_result['best_sharding']
            results['performance_metrics'] = feedback_loop_result['final_metrics']
            results['status'] = 'completed'

            # ä¿å­˜ç»“æœ
            if self.config['integration']['save_results']:
                self._save_cycle_results(results)

            cycle_time = time.time() - cycle_start_time
            logger.info(f"[SUCCESS] å®Œæ•´åˆ†ç‰‡å¾ªç¯å®Œæˆï¼Œç”¨æ—¶: {cycle_time:.2f}ç§’")
            logger.info(f"   æœ€ç»ˆåˆ†ç‰‡æ•°: {results['final_sharding']['actual_num_shards']}")
            logger.info(f"   æ€§èƒ½æŒ‡æ ‡: {results['performance_metrics']}")

            self.current_epoch += 1
            return results

        except Exception as e:
            logger.error(f"[ERROR] åˆ†ç‰‡å¾ªç¯å¤±è´¥: {e}")
            results['status'] = 'failed'
            results['error'] = str(e)
            return results

    def _execute_step1(self, input_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–"""
        logger.info("ğŸ” [ç¬¬ä¸€æ­¥] ç‰¹å¾æå–...")
        
        try:
            if self.step1_pipeline and input_data and 'node_features_module' in input_data:
                # çœŸå®çš„BlockEmulatoræ•°æ®
                features_result = self.step1_pipeline.extract_features_from_system(
                    node_features_module=input_data['node_features_module'],
                    experiment_name=f"cycle_{self.current_epoch}"
                )
                
                step1_data = {
                    'f_classic': features_result['features'],
                    'f_graph': features_result.get('adjacency_matrix', torch.eye(features_result['features'].shape[0])),
                    'node_mapping': features_result.get('node_mapping', {}),
                    'metadata': features_result['metadata']
                }
                
            else:
                # æ¨¡æ‹Ÿæ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
                num_nodes = input_data.get('num_nodes', 20) if input_data else 20
                step1_data = {
                    'f_classic': torch.randn(num_nodes, 128),
                    'f_graph': torch.randn(num_nodes, 96),
                    'node_mapping': {i: f"node_{i}" for i in range(num_nodes)},
                    'metadata': {
                        'num_nodes': num_nodes,
                        'data_source': 'simulation',
                        'extraction_time': time.time()
                    }
                }

            logger.info(f"[SUCCESS] [ç¬¬ä¸€æ­¥] å®Œæˆ - æå– {step1_data['metadata']['num_nodes']} ä¸ªèŠ‚ç‚¹ç‰¹å¾")
            
            return {
                'success': True,
                'data': step1_data,
                'metrics': {
                    'num_nodes': step1_data['metadata']['num_nodes'],
                    'feature_dims': {
                        'f_classic': list(step1_data['f_classic'].shape),
                        'f_graph': list(step1_data['f_graph'].shape)
                    }
                }
            }

        except Exception as e:
            logger.error(f"[ERROR] [ç¬¬ä¸€æ­¥] å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

    def _execute_step2(self, step1_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ """
        logger.info("ğŸ§  [ç¬¬äºŒæ­¥] å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ...")
        
        try:
            # è°ƒç”¨ç¬¬äºŒæ­¥å¤„ç†å™¨
            step2_result = self.step2_processor.process_step1_output(
                step1_data,
                timestamp=self.current_epoch,
                blockemulator_timestamp=time.time()
            )
            
            step2_data = {
                'temporal_embeddings': step2_result['temporal_embeddings'],
                'node_mapping': step2_result['node_mapping'],
                'metadata': step2_result['metadata']
            }
            
            logger.info(f"[SUCCESS] [ç¬¬äºŒæ­¥] å®Œæˆ - ç”Ÿæˆæ—¶åºåµŒå…¥: {step2_data['temporal_embeddings'].shape}")
            
            return {
                'success': True,
                'data': step2_data,
                'metrics': {
                    'embedding_shape': list(step2_data['temporal_embeddings'].shape),
                    'loss': step2_result.get('loss', 0.0),
                    'processing_time': step2_result['metadata'].get('processing_time', 0)
                }
            }

        except Exception as e:
            logger.error(f"[ERROR] [ç¬¬äºŒæ­¥] å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

    def _execute_feedback_loop(self, step2_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥åé¦ˆå¾ªç¯"""
        logger.info("ğŸ”„ [ç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥] åé¦ˆå¾ªç¯...")
        
        try:
            embeddings = step2_data['temporal_embeddings'].to(self.device)
            num_nodes = embeddings.shape[0]
            
            best_sharding = None
            best_performance = float('-inf')
            feedback_signal = None
            
            iteration_results = []
            
            for iteration in range(self.config['step3']['max_iterations']):
                logger.info(f"   è¿­ä»£ {iteration + 1}/{self.config['step3']['max_iterations']}")
                
                # ç¬¬ä¸‰æ­¥ï¼šEvolveGCNåˆ†ç‰‡
                step3_result = self._execute_step3(embeddings, feedback_signal, iteration)
                
                if not step3_result['success']:
                    continue
                
                # ç¬¬å››æ­¥ï¼šæ€§èƒ½è¯„ä¼°
                step4_result = self._execute_step4(step3_result['data'], embeddings)
                
                # è®°å½•è¿­ä»£ç»“æœ
                iteration_result = {
                    'iteration': iteration + 1,
                    'step3': step3_result,
                    'step4': step4_result,
                    'performance_score': step4_result.get('performance_score', 0.0)
                }
                iteration_results.append(iteration_result)
                
                # æ›´æ–°æœ€ä½³ç»“æœ
                current_performance = step4_result.get('performance_score', 0.0)
                if current_performance > best_performance:
                    best_performance = current_performance
                    best_sharding = step3_result['data']
                    logger.info(f"     [SUCCESS] æ€§èƒ½æ”¹å–„! åˆ†æ•°: {current_performance:.3f}")
                
                # æ›´æ–°åé¦ˆä¿¡å·
                feedback_signal = step4_result.get('feedback_signal', None)
                
                # æ£€æŸ¥æ”¶æ•›
                if self._check_convergence(iteration_results):
                    logger.info(f"     [TARGET] æ”¶æ•›è¾¾æˆï¼Œæå‰ç»“æŸ")
                    break

            logger.info(f"[SUCCESS] [åé¦ˆå¾ªç¯] å®Œæˆ - æœ€ä½³æ€§èƒ½: {best_performance:.3f}")
            
            return {
                'success': True,
                'best_sharding': best_sharding,
                'final_metrics': {
                    'best_performance_score': best_performance,
                    'total_iterations': len(iteration_results),
                    'converged': self._check_convergence(iteration_results)
                },
                'iteration_history': iteration_results
            }

        except Exception as e:
            logger.error(f"[ERROR] [åé¦ˆå¾ªç¯] å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

    def _execute_step3(self, embeddings: torch.Tensor, feedback_signal: torch.Tensor = None, iteration: int = 0) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬ä¸‰æ­¥ï¼šEvolveGCNåˆ†ç‰‡"""
        try:
            # åŠ¨æ€åˆ†ç‰‡
            shard_assignments, enhanced_embeddings, attention_weights, predicted_num_shards = self.step3_sharding_module(
                embeddings, 
                history_states=None,
                feedback_signal=feedback_signal
            )
            
            # è®¡ç®—ç¡¬åˆ†é…
            hard_assignment = torch.argmax(shard_assignments, dim=1)
            unique_shards, shard_counts = torch.unique(hard_assignment, return_counts=True)
            
            step3_data = {
                'shard_assignments': shard_assignments,
                'hard_assignment': hard_assignment,
                'enhanced_embeddings': enhanced_embeddings,
                'predicted_num_shards': predicted_num_shards,
                'actual_num_shards': len(unique_shards),
                'shard_sizes': shard_counts.tolist()
            }
            
            logger.info(f"     [ç¬¬ä¸‰æ­¥] é¢„æµ‹åˆ†ç‰‡æ•°: {predicted_num_shards}, å®é™…åˆ†ç‰‡: {len(unique_shards)}")
            logger.info(f"     [ç¬¬ä¸‰æ­¥] åˆ†ç‰‡å¤§å°: {shard_counts.tolist()}")
            
            return {
                'success': True,
                'data': step3_data,
                'metrics': {
                    'predicted_shards': predicted_num_shards,
                    'actual_shards': len(unique_shards),
                    'shard_distribution': shard_counts.tolist()
                }
            }

        except Exception as e:
            logger.error(f"[ERROR] [ç¬¬ä¸‰æ­¥] å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

    def _execute_step4(self, step3_data: Dict[str, Any], embeddings: torch.Tensor) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬å››æ­¥ï¼šæ€§èƒ½åé¦ˆè¯„ä¼°"""
        try:
            if self.step4_feedback_engine:
                # ä½¿ç”¨çœŸå®çš„åé¦ˆå¼•æ“
                features = {
                    'node_features': embeddings,
                    'degree_centrality': torch.rand(embeddings.shape[0], 1),
                    'betweenness_centrality': torch.rand(embeddings.shape[0], 1),
                    'clustering_coefficient': torch.rand(embeddings.shape[0], 1),
                    'pagerank': torch.rand(embeddings.shape[0], 1),
                    'shard_balance': torch.rand(embeddings.shape[0], 1)
                }
                
                feedback_matrix = self.step4_feedback_engine.analyze_performance(
                    features,
                    step3_data['hard_assignment'],
                    step3_data['shard_assignments']
                )
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                feedback_signal = feedback_matrix
                performance_score = float(feedback_matrix.mean().item())  # ä½¿ç”¨åé¦ˆçŸ©é˜µçš„å¹³å‡å€¼ä½œä¸ºæ€§èƒ½åˆ†æ•°
                
            else:
                # ç®€åŒ–çš„æ€§èƒ½è®¡ç®—
                hard_assignment = step3_data['hard_assignment']
                shard_counts = step3_data['shard_sizes']
                
                # è´Ÿè½½å‡è¡¡åˆ†æ•°
                if len(shard_counts) > 1:
                    balance_score = 1.0 - (np.std(shard_counts) / (np.mean(shard_counts) + 1e-8))
                else:
                    balance_score = 0.0
                
                # è·¨ç‰‡ç‡åˆ†æ•°ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                num_nodes = embeddings.shape[0]
                edge_index = torch.tensor([[i, (i+1) % num_nodes] for i in range(num_nodes)]).t()
                cross_shard_edges = (hard_assignment[edge_index[0]] != hard_assignment[edge_index[1]]).float()
                cross_rate = torch.mean(cross_shard_edges).item()
                cross_score = 1.0 - cross_rate
                
                # ç»¼åˆæ€§èƒ½åˆ†æ•°
                performance_score = 0.6 * balance_score + 0.4 * cross_score
                feedback_signal = None

            logger.info(f"     [ç¬¬å››æ­¥] æ€§èƒ½åˆ†æ•°: {performance_score:.3f}")
            
            return {
                'success': True,
                'performance_score': performance_score,
                'feedback_signal': feedback_signal,
                'metrics': {
                    'balance_score': balance_score if 'balance_score' in locals() else 0.0,
                    'cross_shard_rate': cross_rate if 'cross_rate' in locals() else 0.0
                }
            }

        except Exception as e:
            logger.error(f"[ERROR] [ç¬¬å››æ­¥] å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

    def _check_convergence(self, iteration_results: List[Dict]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        if len(iteration_results) < 2:
            return False
        
        # æ£€æŸ¥æœ€è¿‘ä¸¤æ¬¡è¿­ä»£çš„æ€§èƒ½å˜åŒ–
        recent_scores = [r.get('performance_score', 0.0) for r in iteration_results[-2:]]
        performance_change = abs(recent_scores[-1] - recent_scores[-2])
        
        return performance_change < self.config['step4']['convergence_threshold']

    def _save_cycle_results(self, results: Dict[str, Any]):
        """ä¿å­˜å¾ªç¯ç»“æœ"""
        try:
            result_dir = Path(self.config['integration']['result_path'])
            result_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜è¯¦ç»†ç»“æœ
            result_file = result_dir / f"sharding_cycle_{self.current_epoch}.json"
            with open(result_file, 'w') as f:
                # å°†tensorè½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
                serializable_results = self._make_json_serializable(results)
                json.dump(serializable_results, f, indent=2)
            
            # ä¿å­˜ç®€åŒ–ç»“æœï¼ˆç”¨äºBlockEmulatoré›†æˆï¼‰
            summary_file = result_dir / "latest_sharding_result.json"
            summary = {
                'cycle_id': results['cycle_id'],
                'timestamp': results['timestamp'],
                'num_shards': results['final_sharding']['actual_num_shards'] if results['final_sharding'] else 0,
                'shard_assignment': results['final_sharding']['hard_assignment'].tolist() if results['final_sharding'] else [],
                'performance_score': results['performance_metrics'].get('best_performance_score', 0.0),
                'status': results['status']
            }
            
            with open(summary_file, 'w') as f:
                json.dump(summary, f, indent=2)
                
            logger.info(f"[SUCCESS] ç»“æœå·²ä¿å­˜: {result_file}")

        except Exception as e:
            logger.error(f"[ERROR] ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _make_json_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼"""
        if isinstance(obj, torch.Tensor):
            return obj.detach().cpu().tolist()
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        else:
            return obj

    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€ï¼ˆç”¨äºBlockEmulatorç›‘æ§ï¼‰"""
        return {
            'system_name': self.config['system_name'],
            'version': self.config['version'],
            'current_epoch': self.current_epoch,
            'device': str(self.device),
            'components_status': {
                'step1_pipeline': self.step1_pipeline is not None,
                'step2_processor': self.step2_processor is not None,
                'step3_sharding_module': self.step3_sharding_module is not None,
                'step4_feedback_engine': self.step4_feedback_engine is not None
            },
            'last_update': time.time()
        }

def test_integrated_system():
    """æµ‹è¯•é›†æˆç³»ç»Ÿ"""
    logger.info("ğŸ§ª æµ‹è¯•BlockEmulatoré›†æˆåˆ†ç‰‡ç³»ç»Ÿ")
    logger.info("=" * 80)

    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = BlockEmulatorIntegratedShardingSystem()
    
    # åˆå§‹åŒ–ç»„ä»¶
    if not system.initialize_components():
        logger.error("[ERROR] ç»„ä»¶åˆå§‹åŒ–å¤±è´¥")
        return False

    # è¿è¡Œæµ‹è¯•å¾ªç¯
    test_input = {
        'num_nodes': 25,
        'test_mode': True
    }
    
    result = system.run_complete_cycle(test_input)
    
    # æ˜¾ç¤ºç»“æœ
    if result['status'] == 'completed':
        logger.info("[SUCCESS] æµ‹è¯•æˆåŠŸå®Œæˆ")
        logger.info(f"   æœ€ç»ˆåˆ†ç‰‡æ•°: {result['final_sharding']['actual_num_shards']}")
        logger.info(f"   æ€§èƒ½åˆ†æ•°: {result['performance_metrics']['best_performance_score']:.3f}")
        logger.info(f"   æ”¶æ•›çŠ¶æ€: {result['performance_metrics']['converged']}")
        
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        status = system.get_system_status()
        logger.info(f"   ç³»ç»ŸçŠ¶æ€: {status['components_status']}")
        
        return True
    else:
        logger.error(f"[ERROR] æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("[START] BlockEmulatoré›†æˆåˆ†ç‰‡ç³»ç»Ÿ")
    logger.info("   è¿™æ˜¯æœ€ç»ˆé›†æˆåˆ°BlockEmulatorä¸­çš„åˆ†ç‰‡ç³»ç»Ÿ")
    logger.info("   ä¸¥æ ¼æŒ‰ç…§å››æ­¥æµç¨‹ï¼šç‰¹å¾æå– â†’ å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹  â†’ EvolveGCNåˆ†ç‰‡ â‡„ æ€§èƒ½åé¦ˆ")
    logger.info("=" * 80)
    
    # è¿è¡Œæµ‹è¯•
    success = test_integrated_system()
    
    if success:
        logger.info("ğŸ‰ ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œå…¨æˆåŠŸï¼")
        logger.info("   è¯¥åˆ†ç‰‡ç³»ç»Ÿå·²å‡†å¤‡å¥½é›†æˆåˆ°BlockEmulatorä¸­")
        logger.info("   å¯ä»¥é€šè¿‡è°ƒç”¨ run_complete_cycle() æ–¹æ³•æ¥æ‰§è¡ŒåŠ¨æ€åˆ†ç‰‡")
    else:
        logger.error("[WARNING] ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

if __name__ == "__main__":
    main()
