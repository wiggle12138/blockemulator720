#!/usr/bin/env python3
"""
å‡†ç¡®çš„æ¶ˆèå®éªŒï¼šåŒ…å«è®­ç»ƒè¿‡ç¨‹
æµ‹è¯•å„ä¸ªä¿®æ”¹åœ¨å®é™…è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•ˆæœ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import sys
from pathlib import Path
import time
import json

sys.path.append(str(Path(__file__).parent / "evolve_GCN"))
sys.path.append(str(Path(__file__).parent / "feedback"))

from evolve_GCN.models.sharding_modules import DynamicShardingModule, GraphAttentionPooling
from evolve_GCN.losses.sharding_losses import multi_objective_sharding_loss

class TrainingAblationTester:
    """åŒ…å«è®­ç»ƒè¿‡ç¨‹çš„æ¶ˆèå®éªŒæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.device = torch.device('cpu')
        self.num_nodes = 200
        self.embed_dim = 64
        self.n_shards = 5
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        self.embeddings = torch.randn(self.num_nodes, self.embed_dim, device=self.device)
        self.edge_index = self._generate_edge_index()
        
        # è®­ç»ƒé…ç½®
        self.training_epochs = 10
        self.learning_rate = 0.001
        
    def _generate_edge_index(self):
        """ç”Ÿæˆæµ‹è¯•ç”¨è¾¹ç´¢å¼•"""
        edges = []
        for i in range(self.num_nodes):
            edges.append([i, (i + 1) % self.num_nodes])
            edges.append([i, (i - 1) % self.num_nodes])
            if i % 5 == 0:  # ä¸€äº›é•¿è·ç¦»è¿æ¥
                edges.append([i, (i + 10) % self.num_nodes])
        
        edge_tensor = torch.tensor(edges, dtype=torch.long).t()
        return edge_tensor
    
    def _create_baseline_module(self):
        """åˆ›å»ºåŸºçº¿ç‰ˆæœ¬æ¨¡å—ï¼ˆåŸå§‹è®¾ç½®ï¼‰"""
        module = DynamicShardingModule(
            embedding_dim=self.embed_dim,
            base_shards=3,
            max_shards=self.n_shards
        )
        
        # ä¿®æ”¹allocatorä¸ºåŸå§‹ç‰ˆæœ¬
        module.allocator = self._create_baseline_pooling()
        return module
    
    def _create_baseline_pooling(self):
        """åˆ›å»ºåŸå§‹ç‰ˆæœ¬çš„poolingï¼ˆæ— å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        return GraphAttentionPooling(
            embedding_dim=self.embed_dim,
            n_heads=4
        )
    
    def _create_enhanced_module(self):
        """åˆ›å»ºå¢å¼ºç‰ˆæœ¬æ¨¡å—ï¼ˆåŒ…å«æ‰€æœ‰ä¿®æ”¹ï¼‰"""
        module = DynamicShardingModule(
            embedding_dim=self.embed_dim,
            base_shards=3,
            max_shards=self.n_shards
        )
        return module  # ä½¿ç”¨å½“å‰çš„å¢å¼ºç‰ˆæœ¬
    
    def _compute_baseline_loss(self, assignment, target_shards=None):
        """åŸå§‹ä½æƒ©ç½šæŸå¤±å‡½æ•°"""
        device = assignment.device
        
        # è®¡ç®—ä½¿ç”¨çš„åˆ†ç‰‡æ•°
        hard_assignment = torch.argmax(assignment, dim=1)
        unique_shards = torch.unique(hard_assignment)
        num_active_shards = len(unique_shards)
        
        # åŸºç¡€æŸå¤± - å‡åŒ€åˆ†å¸ƒ
        target_prob = 1.0 / self.n_shards
        avg_prob = assignment.mean(dim=0)
        balance_loss = torch.sum((avg_prob - target_prob) ** 2)
        
        # åŸå§‹è¾ƒè½»çš„æƒ©ç½š
        if num_active_shards < 2:
            single_shard_penalty = 10.0  # åŸå§‹è¾ƒä½æƒ©ç½š
        else:
            single_shard_penalty = 0.0
        
        total_loss = balance_loss + single_shard_penalty
        
        return total_loss, {
            'balance_loss': balance_loss.item(),
            'single_shard_penalty': single_shard_penalty,
            'num_active_shards': num_active_shards
        }
    
    def _compute_enhanced_loss(self, assignment, target_shards=None):
        """å¢å¼ºç‰ˆé«˜æƒ©ç½šæŸå¤±å‡½æ•°"""
        device = assignment.device
        
        # è®¡ç®—ä½¿ç”¨çš„åˆ†ç‰‡æ•°
        hard_assignment = torch.argmax(assignment, dim=1)
        unique_shards = torch.unique(hard_assignment)
        num_active_shards = len(unique_shards)
        
        # åŸºç¡€æŸå¤± - å‡åŒ€åˆ†å¸ƒ
        target_prob = 1.0 / self.n_shards
        avg_prob = assignment.mean(dim=0)
        balance_loss = torch.sum((avg_prob - target_prob) ** 2)
        
        # æç«¯é«˜æƒ©ç½š
        if num_active_shards == 1:
            single_shard_penalty = 100000.0  # æç«¯æƒ©ç½š
        elif num_active_shards < 3:
            single_shard_penalty = 50000.0   # é«˜æƒ©ç½š
        else:
            single_shard_penalty = 0.0
        
        total_loss = balance_loss + single_shard_penalty
        
        return total_loss, {
            'balance_loss': balance_loss.item(),
            'single_shard_penalty': single_shard_penalty,
            'num_active_shards': num_active_shards
        }
    
    def _train_module(self, module, loss_func, temperature, use_enhanced_balance=False):
        """è®­ç»ƒæ¨¡å—å¹¶è¿”å›ç»“æœ"""
        optimizer = optim.Adam(module.parameters(), lr=self.learning_rate)
        
        results = []
        
        for epoch in range(self.training_epochs):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            assignment, _, _, _ = module(self.embeddings)
            
            # è®¡ç®—æŸå¤±
            loss, loss_details = loss_func(assignment)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # è®°å½•ç»“æœ
            hard_assignment = torch.argmax(assignment, dim=1)
            unique_shards, counts = torch.unique(hard_assignment, return_counts=True)
            
            results.append({
                'epoch': epoch,
                'num_active_shards': len(unique_shards),
                'shard_distribution': counts.tolist(),
                'balance_score': self._compute_balance(counts, self.n_shards),
                'loss': loss.item(),
                'loss_details': loss_details
            })
        
        return results
    
    def _compute_balance(self, counts, total_shards):
        """è®¡ç®—è´Ÿè½½å‡è¡¡åº¦"""
        if len(counts) == 0:
            return 0.0
        
        # æ‰©å±•åˆ°æ‰€æœ‰åˆ†ç‰‡ï¼ˆæœªä½¿ç”¨çš„åˆ†ç‰‡è®¡æ•°ä¸º0ï¼‰
        full_counts = torch.zeros(total_shards)
        for i, count in enumerate(counts):
            full_counts[i] = count
        
        # è®¡ç®—æ ‡å‡†å·®ï¼Œå€¼è¶Šå°è¶Šå‡è¡¡
        mean_count = full_counts.mean()
        if mean_count == 0:
            return 0.0
        
        std = torch.std(full_counts)
        balance_score = 1.0 - (std / mean_count)
        return max(0.0, balance_score.item())
    
    def test_baseline(self):
        """æµ‹è¯•åŸºçº¿ç‰ˆæœ¬ï¼ˆåŸå§‹ä½æ¸©åº¦+ä½æƒ©ç½š+æ— å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        print("\nğŸ”¬ åŸºçº¿æµ‹è¯•ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰")
        print("=" * 60)
        
        module = self._create_baseline_module()
        results = self._train_module(
            module=module,
            loss_func=self._compute_baseline_loss,
            temperature=1.0,  # åŸå§‹ä½æ¸©åº¦
            use_enhanced_balance=False
        )
        
        return self._analyze_training_results("åŸºçº¿ç‰ˆæœ¬", results)
    
    def test_temperature_only(self):
        """æµ‹è¯•ä»…æ¸©åº¦ä¿®æ”¹ï¼ˆé«˜æ¸©åº¦+åŸå§‹æŸå¤±+æ— å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        print("\nğŸŒ¡ï¸ ä»…æ¸©åº¦ä¿®æ”¹æµ‹è¯•")
        print("=" * 60)
        
        module = self._create_baseline_module()
        results = self._train_module(
            module=module,
            loss_func=self._compute_baseline_loss,
            temperature=25.0,  # è¶…é«˜æ¸©åº¦
            use_enhanced_balance=False
        )
        
        return self._analyze_training_results("ä»…æ¸©åº¦ä¿®æ”¹", results)
    
    def test_loss_only(self):
        """æµ‹è¯•ä»…æŸå¤±ä¿®æ”¹ï¼ˆåŸå§‹æ¸©åº¦+é«˜æƒ©ç½š+æ— å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        print("\nâš–ï¸ ä»…æŸå¤±ä¿®æ”¹æµ‹è¯•")
        print("=" * 60)
        
        module = self._create_baseline_module()
        results = self._train_module(
            module=module,
            loss_func=self._compute_enhanced_loss,
            temperature=1.0,   # åŸå§‹ä½æ¸©åº¦
            use_enhanced_balance=False
        )
        
        return self._analyze_training_results("ä»…æŸå¤±ä¿®æ”¹", results)
    
    def test_force_balance_only(self):
        """æµ‹è¯•ä»…å¼ºåˆ¶å¹³è¡¡ï¼ˆåŸå§‹æ¸©åº¦+åŸå§‹æŸå¤±+å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        print("\nâš–ï¸ ä»…å¼ºåˆ¶å¹³è¡¡æµ‹è¯•")
        print("=" * 60)
        
        module = self._create_enhanced_module()  # åŒ…å«å¼ºåˆ¶å¹³è¡¡
        results = self._train_module(
            module=module,
            loss_func=self._compute_baseline_loss,
            temperature=1.0,   # åŸå§‹ä½æ¸©åº¦
            use_enhanced_balance=True
        )
        
        return self._analyze_training_results("ä»…å¼ºåˆ¶å¹³è¡¡", results)
    
    def test_temperature_plus_loss(self):
        """æµ‹è¯•æ¸©åº¦+æŸå¤±ç»„åˆï¼ˆé«˜æ¸©åº¦+é«˜æƒ©ç½š+æ— å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        print("\nğŸŒ¡ï¸âš–ï¸ æ¸©åº¦+æŸå¤±ç»„åˆæµ‹è¯•")
        print("=" * 60)
        
        module = self._create_baseline_module()
        results = self._train_module(
            module=module,
            loss_func=self._compute_enhanced_loss,
            temperature=25.0,  # è¶…é«˜æ¸©åº¦ + é«˜æƒ©ç½š
            use_enhanced_balance=False
        )
        
        return self._analyze_training_results("æ¸©åº¦+æŸå¤±ç»„åˆ", results)
    
    def test_full_combination(self):
        """æµ‹è¯•å®Œæ•´ç»„åˆï¼ˆé«˜æ¸©åº¦+é«˜æƒ©ç½š+å¼ºåˆ¶å¹³è¡¡ï¼‰"""
        print("\n[TARGET] å®Œæ•´ç»„åˆæµ‹è¯•")
        print("=" * 60)
        
        module = self._create_enhanced_module()
        results = self._train_module(
            module=module,
            loss_func=self._compute_enhanced_loss,
            temperature=25.0,  # æ‰€æœ‰ä¿®æ”¹
            use_enhanced_balance=True
        )
        
        return self._analyze_training_results("å®Œæ•´ç»„åˆ", results)
    
    def _analyze_training_results(self, test_name, results):
        """åˆ†æè®­ç»ƒç»“æœ"""
        final_result = results[-1]  # æœ€ç»ˆepochç»“æœ
        initial_result = results[0]  # åˆå§‹epochç»“æœ
        
        # è®¡ç®—æ”¹å–„
        final_shards = final_result['num_active_shards']
        initial_shards = initial_result['num_active_shards']
        shard_improvement = final_shards - initial_shards
        
        final_balance = final_result['balance_score']
        initial_balance = initial_result['balance_score']
        balance_improvement = final_balance - initial_balance
        
        print(f"[DATA] {test_name}ç»“æœ:")
        print(f"  è®­ç»ƒè½®æ•°: {len(results)}")
        print(f"  åˆå§‹åˆ†ç‰‡æ•°: {initial_shards}")
        print(f"  æœ€ç»ˆåˆ†ç‰‡æ•°: {final_shards}")
        print(f"  åˆ†ç‰‡æ•°æ”¹å–„: {shard_improvement:+d}")
        print(f"  åˆå§‹å‡è¡¡åº¦: {initial_balance:.3f}")
        print(f"  æœ€ç»ˆå‡è¡¡åº¦: {final_balance:.3f}")
        print(f"  å‡è¡¡åº¦æ”¹å–„: {balance_improvement:+.3f}")
        print(f"  æœ€ç»ˆåˆ†å¸ƒ: {final_result['shard_distribution']}")
        print(f"  æœ€ç»ˆæŸå¤±: {final_result['loss']:.3f}")
        
        # æ£€æŸ¥æ˜¯å¦è§£å†³å•åˆ†ç‰‡é—®é¢˜
        solved_single_shard = final_shards >= 3
        effective_improvement = shard_improvement > 0 or balance_improvement > 0.1
        
        if solved_single_shard and effective_improvement:
            effectiveness = "ğŸŸ¢ é«˜æ•ˆ"
        elif effective_improvement:
            effectiveness = "ğŸŸ¡ éƒ¨åˆ†æœ‰æ•ˆ"
        else:
            effectiveness = "ğŸ”´ æ— æ•ˆ"
        
        print(f"  æ•ˆæœè¯„çº§: {effectiveness}")
        print()
        
        return {
            'test_name': test_name,
            'initial_shards': initial_shards,
            'final_shards': final_shards,
            'shard_improvement': shard_improvement,
            'initial_balance': initial_balance,
            'final_balance': final_balance,
            'balance_improvement': balance_improvement,
            'final_distribution': final_result['shard_distribution'],
            'solved_single_shard': solved_single_shard,
            'effective': effective_improvement,
            'effectiveness': effectiveness,
            'training_history': results
        }

def main():
    """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæ¶ˆèå®éªŒ"""
    print("ğŸ”¬ è®­ç»ƒç‰ˆæ¶ˆèå®éªŒï¼šç¡®å®šå…³é”®æœ‰æ•ˆä¿®æ”¹")
    print("=" * 80)
    print("æ³¨ï¼šæ¯ä¸ªæµ‹è¯•åŒ…å«å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹")
    print()
    
    tester = TrainingAblationTester()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    all_results = {}
    
    all_results['baseline'] = tester.test_baseline()
    all_results['temperature_only'] = tester.test_temperature_only() 
    all_results['loss_only'] = tester.test_loss_only()
    all_results['force_balance_only'] = tester.test_force_balance_only()
    all_results['temperature_plus_loss'] = tester.test_temperature_plus_loss()
    all_results['full_combination'] = tester.test_full_combination()
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n[DATA] è®­ç»ƒæ¶ˆèå®éªŒæ€»ç»“")
    print("=" * 80)
    
    baseline_shards = all_results['baseline']['final_shards']
    baseline_balance = all_results['baseline']['final_balance']
    
    for test_name, result in all_results.items():
        if test_name == 'baseline':
            continue
            
        shard_gain = result['final_shards'] - baseline_shards
        balance_gain = result['final_balance'] - baseline_balance
        
        print(f"{result['test_name']}:")
        print(f"  åˆ†ç‰‡æ•°å¢ç›Š: {shard_gain:+d} ({baseline_shards}â†’{result['final_shards']})")
        print(f"  å‡è¡¡åº¦å¢ç›Š: {balance_gain:+.3f} ({baseline_balance:.3f}â†’{result['final_balance']:.3f})")
        print(f"  æ•ˆæœè¯„çº§: {result['effectiveness']}")
        print()
    
    # ç¡®å®šæœ€å…³é”®çš„ä¿®æ”¹
    print("[TARGET] å…³é”®å› ç´ è¯†åˆ«:")
    print("=" * 50)
    
    # åˆ†æå“ªä¸ªå•ç‹¬ä¿®æ”¹æœ€æœ‰æ•ˆ
    single_modifications = ['temperature_only', 'loss_only', 'force_balance_only']
    best_single = max(single_modifications, 
                     key=lambda x: all_results[x]['shard_improvement'] + all_results[x]['balance_improvement'])
    
    print(f"æœ€æœ‰æ•ˆçš„å•ç‹¬ä¿®æ”¹: {all_results[best_single]['test_name']}")
    print(f"åˆ†ç‰‡æ”¹å–„: {all_results[best_single]['shard_improvement']:+d}")
    print(f"å‡è¡¡æ”¹å–„: {all_results[best_single]['balance_improvement']:+.3f}")
    print()
    
    # æ£€æŸ¥ç»„åˆæ•ˆæœ
    combo_improvement = (all_results['temperature_plus_loss']['shard_improvement'] + 
                        all_results['temperature_plus_loss']['balance_improvement'])
    full_improvement = (all_results['full_combination']['shard_improvement'] + 
                       all_results['full_combination']['balance_improvement'])
    
    print(f"æ¸©åº¦+æŸå¤±ç»„åˆæ”¹å–„: {combo_improvement:.3f}")
    print(f"å®Œæ•´ç»„åˆæ”¹å–„: {full_improvement:.3f}")
    
    if full_improvement > combo_improvement + 0.1:
        print("[SUCCESS] å¼ºåˆ¶å¹³è¡¡æœºåˆ¶æä¾›äº†é¢å¤–çš„é‡è¦æ”¹è¿›")
    elif combo_improvement > max(all_results[x]['shard_improvement'] + all_results[x]['balance_improvement'] 
                                for x in single_modifications) + 0.1:
        print("[SUCCESS] æ¸©åº¦å’ŒæŸå¤±ä¿®æ”¹çš„ç»„åˆæ•ˆæœæ˜¾è‘—")
    else:
        print("[SUCCESS] å•ç‹¬ä¿®æ”¹å·²è¶³å¤Ÿï¼Œç»„åˆæ•ˆæœæœ‰é™")
    
    # ä¿å­˜ç»“æœ
    with open('training_ablation_results.json', 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: training_ablation_results.json")

if __name__ == "__main__":
    main()
