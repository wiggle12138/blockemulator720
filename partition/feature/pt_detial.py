import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from typing import Dict, Any
import pandas as pd

# æ–¹æ³•1ï¼šç›´æ¥è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

class AdjacencyMatrixAnalyzer:
    """é‚»æ¥çŸ©é˜µåˆ†æå·¥å…·"""

    def __init__(self):
        self.data = None
        self.matrix_info = {}

    def load_pt_file(self, pt_file: str) -> Dict[str, Any]:
        """åŠ è½½.ptæ–‡ä»¶å¹¶æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯"""
        print(f"=== åŠ è½½ {pt_file} ===")

        try:
            self.data = torch.load(pt_file, map_location='cpu')
            print("[SUCCESS] æ–‡ä»¶åŠ è½½æˆåŠŸ")

            # æ˜¾ç¤ºæ–‡ä»¶ç»“æ„
            print("\nğŸ“ æ–‡ä»¶å†…å®¹ç»“æ„:")
            for key, value in self.data.items():
                if isinstance(value, torch.Tensor):
                    print(f"  - {key}: torch.Tensor {value.shape} ({value.dtype})")
                elif isinstance(value, np.ndarray):
                    print(f"  - {key}: numpy.ndarray {value.shape} ({value.dtype})")
                elif isinstance(value, dict):
                    print(f"  - {key}: dict (åŒ…å« {len(value)} ä¸ªé”®)")
                else:
                    print(f"  - {key}: {type(value)} - {str(value)[:50]}...")

            return self.data

        except Exception as e:
            print(f"[ERROR] åŠ è½½å¤±è´¥: {e}")
            return None

    def analyze_adjacency_matrix(self, matrix_key: str = 'adjacency_matrix'):
        """åˆ†æé‚»æ¥çŸ©é˜µ"""
        if self.data is None:
            print("[ERROR] è¯·å…ˆåŠ è½½.ptæ–‡ä»¶")
            return

        # å¯»æ‰¾é‚»æ¥çŸ©é˜µ
        adj_matrix = None
        possible_keys = [matrix_key, 'adjacency_matrix_dense', 'original_adjacency_matrix']

        for key in possible_keys:
            if key in self.data:
                adj_matrix = self.data[key]
                if isinstance(adj_matrix, torch.Tensor):
                    adj_matrix = adj_matrix.numpy()
                print(f"[SUCCESS] æ‰¾åˆ°é‚»æ¥çŸ©é˜µ: {key}")
                break

        if adj_matrix is None:
            print("[ERROR] æœªæ‰¾åˆ°é‚»æ¥çŸ©é˜µ")
            print("å¯ç”¨çš„é”®:", list(self.data.keys()))
            return

        print(f"\n=== é‚»æ¥çŸ©é˜µåˆ†æ ===")
        print(f"çŸ©é˜µå½¢çŠ¶: {adj_matrix.shape}")
        print(f"æ•°æ®ç±»å‹: {adj_matrix.dtype}")
        print(f"æ•°å€¼èŒƒå›´: [{adj_matrix.min():.4f}, {adj_matrix.max():.4f}]")
        print(f"éé›¶å…ƒç´ : {np.count_nonzero(adj_matrix)}")
        print(f"ç¨€ç–åº¦: {(1 - np.count_nonzero(adj_matrix) / adj_matrix.size) * 100:.2f}%")

        # æ£€æŸ¥å¯¹ç§°æ€§
        is_symmetric = np.allclose(adj_matrix, adj_matrix.T, atol=1e-6)
        print(f"æ˜¯å¦å¯¹ç§°: {'æ˜¯' if is_symmetric else 'å¦'}")

        # åº¦ç»Ÿè®¡
        if len(adj_matrix.shape) == 2:
            row_sums = adj_matrix.sum(axis=1)  # å‡ºåº¦
            col_sums = adj_matrix.sum(axis=0)  # å…¥åº¦

            print(f"\n[DATA] åº¦ç»Ÿè®¡:")
            print(f"å¹³å‡å‡ºåº¦: {row_sums.mean():.2f}")
            print(f"å¹³å‡å…¥åº¦: {col_sums.mean():.2f}")
            print(f"æœ€å¤§å‡ºåº¦: {row_sums.max():.0f}")
            print(f"æœ€å¤§å…¥åº¦: {col_sums.max():.0f}")
            print(f"é›¶å‡ºåº¦èŠ‚ç‚¹: {(row_sums == 0).sum()}")
            print(f"é›¶å…¥åº¦èŠ‚ç‚¹: {(col_sums == 0).sum()}")

        # ä¿å­˜åˆ†æç»“æœ
        self.matrix_info = {
            'shape': adj_matrix.shape,
            'dtype': str(adj_matrix.dtype),
            'num_edges': int(np.count_nonzero(adj_matrix)),
            'sparsity': float(1 - np.count_nonzero(adj_matrix) / adj_matrix.size),
            'is_symmetric': bool(is_symmetric),
            'out_degrees': row_sums.tolist() if len(adj_matrix.shape) == 2 else None,
            'in_degrees': col_sums.tolist() if len(adj_matrix.shape) == 2 else None
        }

        return adj_matrix

    def visualize_adjacency_matrix(self, adj_matrix: np.ndarray, max_nodes: int = 100):
        """å¯è§†åŒ–é‚»æ¥çŸ©é˜µ"""
        print(f"\n=== é‚»æ¥çŸ©é˜µå¯è§†åŒ– ===")

        # å¦‚æœçŸ©é˜µå¤ªå¤§ï¼Œåªæ˜¾ç¤ºå‰max_nodesä¸ªèŠ‚ç‚¹
        if adj_matrix.shape[0] > max_nodes:
            print(f"çŸ©é˜µå¤ªå¤§ï¼Œåªæ˜¾ç¤ºå‰{max_nodes}ä¸ªèŠ‚ç‚¹")
            adj_matrix = adj_matrix[:max_nodes, :max_nodes]

        plt.figure(figsize=(12, 10))

        # ä¸»å›¾ï¼šé‚»æ¥çŸ©é˜µçƒ­å›¾
        plt.subplot(2, 2, 1)
        sns.heatmap(adj_matrix, cmap='Blues', cbar=True, square=True)
        plt.title(f'é‚»æ¥çŸ©é˜µçƒ­å›¾ ({adj_matrix.shape[0]}Ã—{adj_matrix.shape[1]})')
        plt.xlabel('ç›®æ ‡èŠ‚ç‚¹')
        plt.ylabel('æºèŠ‚ç‚¹')

        # åº¦åˆ†å¸ƒ
        if len(adj_matrix.shape) == 2:
            row_sums = adj_matrix.sum(axis=1)
            col_sums = adj_matrix.sum(axis=0)

            plt.subplot(2, 2, 2)
            plt.hist(row_sums, bins=20, alpha=0.7, label='å‡ºåº¦')
            plt.hist(col_sums, bins=20, alpha=0.7, label='å…¥åº¦')
            plt.xlabel('åº¦æ•°')
            plt.ylabel('èŠ‚ç‚¹æ•°é‡')
            plt.title('åº¦åˆ†å¸ƒ')
            plt.legend()

            # åº¦ç›¸å…³æ€§
            plt.subplot(2, 2, 3)
            plt.scatter(row_sums, col_sums, alpha=0.6)
            plt.xlabel('å‡ºåº¦')
            plt.ylabel('å…¥åº¦')
            plt.title('å‡ºåº¦vså…¥åº¦')

            # è¿æ¥æ¨¡å¼
            plt.subplot(2, 2, 4)
            # æ˜¾ç¤ºè¿æ¥çš„ç¨€ç–æ¨¡å¼
            rows, cols = np.where(adj_matrix > 0)
            plt.scatter(cols, rows, alpha=0.5, s=1)
            plt.xlabel('ç›®æ ‡èŠ‚ç‚¹')
            plt.ylabel('æºèŠ‚ç‚¹')
            plt.title('è¿æ¥æ¨¡å¼')
            plt.gca().invert_yaxis()

        plt.tight_layout()
        plt.savefig('adjacency_matrix_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("[SUCCESS] å¯è§†åŒ–å·²ä¿å­˜ä¸º adjacency_matrix_analysis.png")

    def analyze_edge_data(self):
        """åˆ†æè¾¹æ•°æ®"""
        if self.data is None:
            print("[ERROR] è¯·å…ˆåŠ è½½.ptæ–‡ä»¶")
            return

        print(f"\n=== è¾¹æ•°æ®åˆ†æ ===")

        # æŸ¥æ‰¾è¾¹ç´¢å¼•å’Œè¾¹ç±»å‹
        edge_index = None
        edge_type = None

        for key in ['edge_index', 'original_edge_index']:
            if key in self.data:
                edge_index = self.data[key]
                print(f"[SUCCESS] æ‰¾åˆ°è¾¹ç´¢å¼•: {key} {edge_index.shape}")
                break

        for key in ['edge_type', 'original_edge_type']:
            if key in self.data:
                edge_type = self.data[key]
                print(f"[SUCCESS] æ‰¾åˆ°è¾¹ç±»å‹: {key} {edge_type.shape}")
                break

        if edge_index is not None:
            if isinstance(edge_index, torch.Tensor):
                edge_index = edge_index.numpy()

            print(f"è¾¹ç´¢å¼•å½¢çŠ¶: {edge_index.shape}")
            print(f"è¾¹æ•°é‡: {edge_index.shape[1] if len(edge_index.shape) > 1 else len(edge_index)}")

            if len(edge_index.shape) == 2 and edge_index.shape[0] == 2:
                sources = edge_index[0]
                targets = edge_index[1]

                print(f"æºèŠ‚ç‚¹èŒƒå›´: [{sources.min()}, {sources.max()}]")
                print(f"ç›®æ ‡èŠ‚ç‚¹èŒƒå›´: [{targets.min()}, {targets.max()}]")

                # æ£€æŸ¥è‡ªç¯
                self_loops = (sources == targets).sum()
                print(f"è‡ªç¯æ•°é‡: {self_loops}")

        if edge_type is not None:
            if isinstance(edge_type, torch.Tensor):
                edge_type = edge_type.numpy()

            print(f"\n[DATA] è¾¹ç±»å‹ç»Ÿè®¡:")
            unique_types, counts = np.unique(edge_type, return_counts=True)
            for utype, count in zip(unique_types, counts):
                print(f"  ç±»å‹ {utype}: {count} æ¡è¾¹ ({count/len(edge_type)*100:.1f}%)")

    def check_matrix_quality(self, adj_matrix: np.ndarray) -> Dict[str, bool]:
        """æ£€æŸ¥é‚»æ¥çŸ©é˜µè´¨é‡"""
        print(f"\n=== é‚»æ¥çŸ©é˜µè´¨é‡æ£€æŸ¥ ===")

        checks = {}

        # 1. åŸºæœ¬å½¢çŠ¶æ£€æŸ¥
        checks['is_square'] = adj_matrix.shape[0] == adj_matrix.shape[1]
        print(f"[SUCCESS] æ–¹å½¢çŸ©é˜µ: {checks['is_square']}")

        # 2. æ•°å€¼æ£€æŸ¥
        checks['no_negative'] = (adj_matrix >= 0).all()
        checks['no_nan'] = not np.isnan(adj_matrix).any()
        checks['no_inf'] = not np.isinf(adj_matrix).any()
        print(f"[SUCCESS] éè´Ÿæ•°å€¼: {checks['no_negative']}")
        print(f"[SUCCESS] æ— NaNå€¼: {checks['no_nan']}")
        print(f"[SUCCESS] æ— Infå€¼: {checks['no_inf']}")

        # 3. è¿é€šæ€§æ£€æŸ¥
        checks['has_edges'] = np.count_nonzero(adj_matrix) > 0
        checks['not_too_sparse'] = np.count_nonzero(adj_matrix) / adj_matrix.size > 0.001
        checks['not_too_dense'] = np.count_nonzero(adj_matrix) / adj_matrix.size < 0.5
        print(f"[SUCCESS] æœ‰è¾¹å­˜åœ¨: {checks['has_edges']}")
        print(f"[SUCCESS] ç¨€ç–åº¦åˆç†: {checks['not_too_sparse']} (>0.1%)")
        print(f"[SUCCESS] ä¸è¿‡äºå¯†é›†: {checks['not_too_dense']} (<50%)")

        # 4. å­¤ç«‹èŠ‚ç‚¹æ£€æŸ¥
        row_sums = adj_matrix.sum(axis=1)
        col_sums = adj_matrix.sum(axis=0)
        isolated_nodes = ((row_sums + col_sums) == 0).sum()
        checks['few_isolated'] = isolated_nodes < adj_matrix.shape[0] * 0.1
        print(f"[SUCCESS] å­¤ç«‹èŠ‚ç‚¹å°‘: {checks['few_isolated']} ({isolated_nodes}ä¸ª)")

        # 5. åº¦åˆ†å¸ƒæ£€æŸ¥
        max_degree = max(row_sums.max(), col_sums.max())
        checks['reasonable_max_degree'] = max_degree < adj_matrix.shape[0] * 0.8
        print(f"[SUCCESS] æœ€å¤§åº¦åˆç†: {checks['reasonable_max_degree']} (æœ€å¤§åº¦: {max_degree})")

        overall_quality = all(checks.values())
        print(f"\n{'[SUCCESS]' if overall_quality else '[ERROR]'} æ€»ä½“è´¨é‡: {'è‰¯å¥½' if overall_quality else 'éœ€è¦æ”¹è¿›'}")

        return checks

def analyze_pt_files():
    """åˆ†æå¤šä¸ª.ptæ–‡ä»¶ä¸­çš„é‚»æ¥çŸ©é˜µ"""
    analyzer = AdjacencyMatrixAnalyzer()

    # é¢„æœŸçš„æ–‡ä»¶åˆ—è¡¨
    pt_files = [
        "step1_adjacency_raw.pt",
        "step1_rgcn_layers.pt",
        "step1_large_samples_adjacency_complete.pt",
        # "evolve_gcno_input.pt"
    ]

    results = {}

    for pt_file in pt_files:
        print(f"\n{'='*60}")
        print(f"åˆ†ææ–‡ä»¶: {pt_file}")
        print(f"{'='*60}")

        try:
            # åŠ è½½æ–‡ä»¶
            data = analyzer.load_pt_file(pt_file)
            if data is None:
                continue

            # åˆ†æé‚»æ¥çŸ©é˜µ
            adj_matrix = analyzer.analyze_adjacency_matrix()
            if adj_matrix is not None:
                # è´¨é‡æ£€æŸ¥
                quality_checks = analyzer.check_matrix_quality(adj_matrix)

                # è¾¹æ•°æ®åˆ†æ
                analyzer.analyze_edge_data()

                # å¯è§†åŒ–ï¼ˆä»…å¯¹è¾ƒå°çš„çŸ©é˜µï¼‰
                if adj_matrix.shape[0] <= 500:
                    analyzer.visualize_adjacency_matrix(adj_matrix)

                results[pt_file] = {
                    'matrix_info': analyzer.matrix_info,
                    'quality_checks': quality_checks,
                    'suitable_for_evolve_gcno': all(quality_checks.values())
                }

        except FileNotFoundError:
            print(f"[WARNING] æ–‡ä»¶ä¸å­˜åœ¨: {pt_file}")
        except Exception as e:
            print(f"[ERROR] åˆ†æå‡ºé”™: {e}")

    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    generate_analysis_report(results)
    return results

def generate_analysis_report(results: Dict):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    print(f"\n{'='*80}")
    print(f"[DATA] é‚»æ¥çŸ©é˜µåˆ†ææŠ¥å‘Š")
    print(f"{'='*80}")

    if not results:
        print("[ERROR] æ²¡æœ‰æˆåŠŸåˆ†æçš„æ–‡ä»¶")
        return

    for filename, result in results.items():
        print(f"\nğŸ“ {filename}:")
        matrix_info = result.get('matrix_info', {})
        quality_checks = result.get('quality_checks', {})

        print(f"  - çŸ©é˜µå¤§å°: {matrix_info.get('shape', 'N/A')}")
        print(f"  - è¾¹æ•°é‡: {matrix_info.get('num_edges', 'N/A')}")
        print(f"  - ç¨€ç–åº¦: {matrix_info.get('sparsity', 0)*100:.2f}%")
        print(f"  - å¯¹ç§°æ€§: {'æ˜¯' if matrix_info.get('is_symmetric', False) else 'å¦'}")
        print(f"  - è´¨é‡è¯„åˆ†: {sum(quality_checks.values())}/{len(quality_checks)}")
        print(f"  - é€‚åˆEvolveGCNO: {'[SUCCESS]' if result.get('suitable_for_evolve_gcno', False) else '[ERROR]'}")

    # æ¨è
    print(f"\n[TARGET] æ¨èä½¿ç”¨:")
    suitable_files = [f for f, r in results.items() if r.get('suitable_for_evolve_gcno', False)]
    if suitable_files:
        for f in suitable_files:
            print(f"  [SUCCESS] {f}")
    else:
        print("  [WARNING] æ‰€æœ‰æ–‡ä»¶éƒ½éœ€è¦æ”¹è¿›")

if __name__ == "__main__":
    # è¿è¡Œåˆ†æ
    results = analyze_pt_files()