#!/usr/bin/env python3
"""
å®Œæ•´çš„BlockEmulatorå››æ­¥åˆ†ç‰‡æµç¨‹é›†æˆæµ‹è¯•
æ•´åˆç‰¹å¾æå–ã€å¤šå°ºåº¦å­¦ä¹ ã€EvolveGCNåˆ†ç‰‡å’Œæ€§èƒ½åé¦ˆçš„å®Œæ•´æµç¨‹
"""

import sys
import time
import json
import logging
import warnings
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./partition')
sys.path.append('./partition/feature')
sys.path.append('./muti_scale')
sys.path.append('./evolve_GCN')
sys.path.append('./evolve_GCN/models')
sys.path.append('./feedback')

class IntegratedFourStepShardingSystem:
    """å®Œæ•´çš„å››æ­¥åˆ†ç‰‡ç³»ç»Ÿé›†æˆ"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.results = {}
        
        logger.info("ğŸ¯ åˆå§‹åŒ–å››æ­¥åˆ†ç‰‡ç³»ç»Ÿé›†æˆ")
        logger.info(f"   è®¾å¤‡: {self.device}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir = Path("./integrated_test_outputs")
        self.output_dir.mkdir(exist_ok=True)
        
    def create_mock_blockchain_data(self, num_nodes: int = 20) -> Dict[str, Any]:
        """åˆ›å»ºæ¨¡æ‹Ÿçš„åŒºå—é“¾èŠ‚ç‚¹æ•°æ®"""
        logger.info(f"ğŸ“Š åˆ›å»ºæ¨¡æ‹ŸåŒºå—é“¾æ•°æ® ({num_nodes} ä¸ªèŠ‚ç‚¹)")
        
        # åˆ›å»ºç¬¦åˆBlockEmulatoræ ¼å¼çš„èŠ‚ç‚¹ç‰¹å¾æ•°æ®
        class MockNodeFeaturesModule:
            def GetAllCollectedData(self):
                mock_data = []
                for i in range(num_nodes):
                    node_data = {
                        'ShardID': i % 4,  # 4ä¸ªåˆ†ç‰‡
                        'NodeID': i,
                        'Timestamp': int(time.time() * 1000),
                        'RequestID': f"req_{i}",
                        'NodeState': {
                            'Static': {
                                'ResourceCapacity': {
                                    'Hardware': {
                                        'CPU': {'CoreCount': 4, 'Architecture': 'amd64'},
                                        'Memory': {'TotalCapacity': 8, 'Type': 'DDR4', 'Bandwidth': 50.0},
                                        'Storage': {'Capacity': 100, 'Type': 'SSD', 'ReadWriteSpeed': 500.0},
                                        'Network': {'UpstreamBW': 100.0, 'DownstreamBW': 1000.0, 'Latency': 50.0}
                                    }
                                },
                                'NetworkTopology': {
                                    'GeoLocation': {'Timezone': 'UTC+8'},
                                    'Connections': {
                                        'IntraShardConn': 3, 'InterShardConn': 2,
                                        'WeightedDegree': 5.0, 'ActiveConn': 4
                                    },
                                    'ShardAllocation': {'Adaptability': 0.7}
                                },
                                'HeterogeneousType': {
                                    'NodeType': 'full_node',
                                    'FunctionTags': 'consensus,validation',
                                    'SupportedFuncs': {'Functions': 'tx_processing'},
                                    'Application': {
                                        'CurrentState': 'active',
                                        'LoadMetrics': {'TxFrequency': 100, 'StorageOps': 50}
                                    }
                                }
                            },
                            'Dynamic': {
                                'OnChainBehavior': {
                                    'TransactionCapability': {
                                        'AvgTPS': 50.0,
                                        'CrossShardTx': {'InterNodeVolume': '1MB', 'InterShardVolume': '5MB'},
                                        'ConfirmationDelay': 100.0,
                                        'ResourcePerTx': {
                                            'CPUPerTx': 0.1, 'MemPerTx': 0.05,
                                            'DiskPerTx': 0.02, 'NetworkPerTx': 0.01
                                        }
                                    },
                                    'BlockGeneration': {
                                        'AvgInterval': 5.0, 'IntervalStdDev': 1.0
                                    },
                                    'TransactionTypes': {
                                        'NormalTxRatio': 0.8, 'ContractTxRatio': 0.2
                                    },
                                    'Consensus': {
                                        'ParticipationRate': 0.9, 'TotalReward': 100.0, 'SuccessRate': 0.95
                                    },
                                    'SmartContractUsage': {'InvocationFrequency': 0},
                                    'EconomicContribution': {'FeeContributionRatio': 0.01}
                                },
                                'DynamicAttributes': {
                                    'Compute': {
                                        'CPUUsage': 30.0, 'MemUsage': 40.0, 'ResourceFlux': 0.1
                                    },
                                    'Storage': {
                                        'Available': 80.0, 'Utilization': 20.0
                                    },
                                    'Network': {
                                        'LatencyFlux': 0.05, 'AvgLatency': 50.0, 'BandwidthUsage': 0.3
                                    },
                                    'Transactions': {
                                        'Frequency': 10, 'ProcessingDelay': 200.0
                                    }
                                }
                            }
                        }
                    }
                    mock_data.append(node_data)
                return mock_data
        
        return {
            'node_features_module': MockNodeFeaturesModule(),
            'num_nodes': num_nodes,
            'transaction_graph': {
                'edges': [(i, (i+1) % num_nodes) for i in range(num_nodes)] +  # ç¯å½¢è¿æ¥
                        [(i, (i+2) % num_nodes) for i in range(0, num_nodes, 2)]  # é¢å¤–è¿æ¥
            }
        }
    
    def run_step1_feature_extraction(self, blockchain_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–"""
        logger.info("ğŸ” [STEP 1] ç‰¹å¾æå–")
        logger.info("-" * 40)
        
        try:
            # å°è¯•ä½¿ç”¨çœŸå®çš„ç‰¹å¾æå–ç®¡é“
            from partition.feature.system_integration_pipeline import BlockEmulatorStep1Pipeline
            
            pipeline = BlockEmulatorStep1Pipeline(
                use_comprehensive_features=True,
                save_adjacency=True,
                output_dir=str(self.output_dir / "step1")
            )
            
            # æ‰§è¡Œç‰¹å¾æå–
            result = pipeline.extract_features_from_system(
                node_features_module=blockchain_data['node_features_module'],
                experiment_name="integrated_test"
            )
            
            logger.info(f"   âœ… ç‰¹å¾æå–å®Œæˆ: {result['features'].shape}")
            return result
            
        except Exception as e:
            logger.warning(f"   âš ï¸ çœŸå®ç‰¹å¾æå–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ–¹æ³•: {e}")
            
            # ä½¿ç”¨æ¨¡æ‹Ÿçš„ç‰¹å¾æå–
            num_nodes = blockchain_data['num_nodes']
            features = torch.randn(num_nodes, 128)  # 128ç»´ç‰¹å¾
            
            # ç”Ÿæˆè¾¹ç´¢å¼• (ç¯å½¢æ‹“æ‰‘ + é¢å¤–è¿æ¥)
            edges = []
            for i in range(num_nodes):
                edges.append([i, (i + 1) % num_nodes])  # ç¯å½¢è¿æ¥
                if i % 2 == 0 and i + 2 < num_nodes:
                    edges.append([i, i + 2])  # é¢å¤–è¿æ¥
            
            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
            
            result = {
                'features': features,
                'edge_index': edge_index,
                'metadata': {
                    'total_nodes': num_nodes,
                    'feature_dim': 128,
                    'edge_count': len(edges),
                    'timestamp': time.time()
                },
                'adjacency_matrix': torch.eye(num_nodes),  # ç®€åŒ–çš„é‚»æ¥çŸ©é˜µ
                'node_mapping': {str(i): i for i in range(num_nodes)}
            }
            
            logger.info(f"   âœ… æ¨¡æ‹Ÿç‰¹å¾æå–å®Œæˆ: {features.shape}")
            return result
    
    def run_step2_multiscale_learning(self, step1_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ """
        logger.info("ğŸ§  [STEP 2] å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ")
        logger.info("-" * 40)
        
        try:
            # å°è¯•ä½¿ç”¨çœŸå®çš„å¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ 
            from muti_scale.realtime_mscia import RealtimeMSCIAProcessor
            from muti_scale.step2_config import Step2Config
            
            config = Step2Config().get_blockemulator_integration_config()
            processor = RealtimeMSCIAProcessor(config)
            
            # æ‰§è¡Œå¤šå°ºåº¦å­¦ä¹ 
            result = processor.process_step1_output(
                step1_data,
                timestamp=1,
                blockemulator_timestamp=time.time()
            )
            
            logger.info(f"   âœ… å¤šå°ºåº¦å­¦ä¹ å®Œæˆ: {result['temporal_embeddings'].shape}")
            return result
            
        except Exception as e:
            logger.warning(f"   âš ï¸ çœŸå®å¤šå°ºåº¦å­¦ä¹ å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ–¹æ³•: {e}")
            
            # ä½¿ç”¨æ¨¡æ‹Ÿçš„å¤šå°ºåº¦å­¦ä¹ 
            features = step1_data['features']
            num_nodes = features.shape[0]
            
            # æ¨¡æ‹Ÿæ—¶åºåµŒå…¥ (64ç»´)
            temporal_embeddings = torch.randn(num_nodes, 64)
            
            result = {
                'temporal_embeddings': temporal_embeddings,
                'node_mapping': step1_data.get('node_mapping', {}),
                'metadata': {
                    'embedding_dim': 64,
                    'num_nodes': num_nodes,
                    'processing_time': time.time()
                }
            }
            
            logger.info(f"   âœ… æ¨¡æ‹Ÿå¤šå°ºåº¦å­¦ä¹ å®Œæˆ: {temporal_embeddings.shape}")
            return result
    
    def run_step3_evolve_gcn_sharding(self, step2_data: Dict[str, Any], step1_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç¬¬ä¸‰æ­¥ï¼šEvolveGCNåŠ¨æ€åˆ†ç‰‡"""
        logger.info("ğŸ”„ [STEP 3] EvolveGCNåŠ¨æ€åˆ†ç‰‡")
        logger.info("-" * 40)
        
        try:
            # å°è¯•ä½¿ç”¨çœŸå®çš„EvolveGCNåˆ†ç‰‡
            from evolve_GCN.models.sharding_modules import DynamicShardingModule
            
            embeddings = step2_data['temporal_embeddings'].to(self.device)
            
            # åˆå§‹åŒ–åˆ†ç‰‡æ¨¡å—
            sharding_module = DynamicShardingModule(
                embedding_dim=embeddings.shape[1],
                base_shards=3,
                max_shards=6
            ).to(self.device)
            
            # æ‰§è¡Œåˆ†ç‰‡å†³ç­–
            shard_assignments, enhanced_embeddings, attention_weights, predicted_num_shards = sharding_module(
                embeddings,
                history_states=[],
                feedback_signal=None
            )
            
            # è®¡ç®—ç¡¬åˆ†é…
            hard_assignment = torch.argmax(shard_assignments, dim=1)
            unique_shards, shard_counts = torch.unique(hard_assignment, return_counts=True)
            
            result = {
                'shard_assignments': shard_assignments,
                'hard_assignment': hard_assignment,
                'enhanced_embeddings': enhanced_embeddings,
                'attention_weights': attention_weights,
                'predicted_num_shards': predicted_num_shards,
                'actual_num_shards': len(unique_shards),
                'shard_distribution': dict(zip(unique_shards.cpu().tolist(), shard_counts.cpu().tolist())),
                'edge_index': step1_data.get('edge_index', torch.empty((2, 0)))
            }
            
            logger.info(f"   âœ… EvolveGCNåˆ†ç‰‡å®Œæˆ: {len(unique_shards)} ä¸ªåˆ†ç‰‡")
            logger.info(f"      åˆ†ç‰‡åˆ†å¸ƒ: {result['shard_distribution']}")
            return result
            
        except Exception as e:
            logger.warning(f"   âš ï¸ çœŸå®EvolveGCNåˆ†ç‰‡å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ–¹æ³•: {e}")
            
            # ä½¿ç”¨æ¨¡æ‹Ÿçš„åˆ†ç‰‡ç®—æ³•
            num_nodes = step2_data['temporal_embeddings'].shape[0]
            num_shards = 4  # é»˜è®¤4ä¸ªåˆ†ç‰‡
            
            # ç®€å•çš„åŸºäºèŠ‚ç‚¹IDçš„åˆ†ç‰‡åˆ†é…
            hard_assignment = torch.arange(num_nodes) % num_shards
            
            # åˆ›å»ºè½¯åˆ†é… (one-hot)
            shard_assignments = torch.zeros(num_nodes, num_shards)
            shard_assignments[torch.arange(num_nodes), hard_assignment] = 1.0
            
            unique_shards, shard_counts = torch.unique(hard_assignment, return_counts=True)
            
            result = {
                'shard_assignments': shard_assignments,
                'hard_assignment': hard_assignment,
                'predicted_num_shards': num_shards,
                'actual_num_shards': len(unique_shards),
                'shard_distribution': dict(zip(unique_shards.tolist(), shard_counts.tolist())),
                'edge_index': step1_data.get('edge_index', torch.empty((2, 0)))
            }
            
            logger.info(f"   âœ… æ¨¡æ‹Ÿåˆ†ç‰‡å®Œæˆ: {num_shards} ä¸ªåˆ†ç‰‡")
            return result
    
    def run_step4_performance_feedback(self, step3_data: Dict[str, Any], step1_data: Dict[str, Any], step2_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç¬¬å››æ­¥ï¼šæ€§èƒ½åé¦ˆè¯„ä¼°"""
        logger.info("ğŸ“Š [STEP 4] æ€§èƒ½åé¦ˆè¯„ä¼°")
        logger.info("-" * 40)
        
        try:
            # å°è¯•ä½¿ç”¨çœŸå®çš„åé¦ˆç³»ç»Ÿ
            from feedback.unified_feedback_engine import UnifiedFeedbackEngine
            
            engine = UnifiedFeedbackEngine()
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            step1_features = step1_data.get('features', torch.randn(20, 128))
            shard_assignments = step3_data.get('shard_assignments', torch.randn(20, 4))
            edge_index = step3_data.get('edge_index', torch.empty((2, 0)))
            
            # æ‰§è¡Œåé¦ˆè¯„ä¼°
            feedback_result = engine.comprehensive_feedback_evaluation(
                step1_features,
                step2_data.get('temporal_embeddings', torch.randn(20, 64)),
                shard_assignments,
                edge_index
            )
            
            logger.info(f"   âœ… æ€§èƒ½åé¦ˆå®Œæˆ")
            return feedback_result
            
        except Exception as e:
            logger.warning(f"   âš ï¸ çœŸå®æ€§èƒ½åé¦ˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ–¹æ³•: {e}")
            
            # è®¡ç®—æ¨¡æ‹Ÿçš„æ€§èƒ½æŒ‡æ ‡
            shard_assignments = step3_data.get('hard_assignment', torch.arange(20) % 4)
            edge_index = step3_data.get('edge_index', torch.empty((2, 0)))
            
            # è®¡ç®—è·¨åˆ†ç‰‡è¾¹æ•°
            cross_shard_edges = 0
            total_edges = edge_index.shape[1] if edge_index.numel() > 0 else 0
            
            if total_edges > 0:
                for i in range(total_edges):
                    src, dst = edge_index[:, i]
                    if shard_assignments[src] != shard_assignments[dst]:
                        cross_shard_edges += 1
            
            cross_shard_ratio = cross_shard_edges / max(total_edges, 1)
            
            # è®¡ç®—è´Ÿè½½å‡è¡¡
            unique_shards, shard_counts = torch.unique(shard_assignments, return_counts=True)
            load_balance = 1.0 - torch.std(shard_counts.float()) / torch.mean(shard_counts.float())
            
            result = {
                'performance_metrics': {
                    'cross_shard_ratio': float(cross_shard_ratio),
                    'load_balance': float(load_balance),
                    'security_score': 0.85,  # æ¨¡æ‹Ÿå®‰å…¨åˆ†æ•°
                    'consensus_latency': 125.0  # æ¨¡æ‹Ÿå…±è¯†å»¶è¿Ÿ(ms)
                },
                'feedback_signal': [
                    float(load_balance),
                    1.0 - cross_shard_ratio,  # è·¨åˆ†ç‰‡ç‡è¶Šä½è¶Šå¥½
                    0.85,  # å®‰å…¨åˆ†æ•°
                    0.9   # æ•´ä½“ç³»ç»Ÿå¥åº·åº¦
                ],
                'detailed_metrics': {
                    'total_nodes': len(shard_assignments),
                    'total_shards': len(unique_shards),
                    'cross_shard_edges': cross_shard_edges,
                    'total_edges': total_edges,
                    'shard_distribution': dict(zip(unique_shards.tolist(), shard_counts.tolist()))
                },
                'recommendations': self._generate_recommendations(cross_shard_ratio, load_balance)
            }
            
            overall_score = np.mean(result['feedback_signal'])
            
            logger.info(f"   âœ… æ¨¡æ‹Ÿæ€§èƒ½åé¦ˆå®Œæˆ")
            logger.info(f"      è·¨åˆ†ç‰‡ç‡: {cross_shard_ratio:.3f}")
            logger.info(f"      è´Ÿè½½å‡è¡¡: {load_balance:.3f}")
            logger.info(f"      æ•´ä½“åˆ†æ•°: {overall_score:.3f}")
            
            return result
    
    def _generate_recommendations(self, cross_shard_ratio: float, load_balance: float) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if cross_shard_ratio > 0.3:
            recommendations.append("è·¨åˆ†ç‰‡äº¤æ˜“ç‡è¾ƒé«˜ï¼Œå»ºè®®è°ƒæ•´åˆ†ç‰‡ç­–ç•¥ä»¥å‡å°‘è·¨åˆ†ç‰‡é€šä¿¡")
        
        if load_balance < 0.7:
            recommendations.append("è´Ÿè½½ä¸å‡è¡¡ï¼Œå»ºè®®é‡æ–°åˆ†é…èŠ‚ç‚¹ä»¥å¹³è¡¡å„åˆ†ç‰‡è´Ÿè½½")
        
        if not recommendations:
            recommendations.append("å½“å‰åˆ†ç‰‡é…ç½®è‰¯å¥½ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        
        return recommendations
    
    def save_results_for_blockemulator_call(self, final_results: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿å­˜åˆ†ç‰‡ç»“æœä¾›BlockEmulatorè°ƒç”¨"""
        logger.info("ï¿½ [INTEGRATION] ä¿å­˜ç»“æœä¾›BlockEmulatorè°ƒç”¨")
        logger.info("-" * 40)
        
        try:
            # å‡†å¤‡å®Œæ•´ç»“æœ
            complete_results = {
                'shard_assignments': final_results['step3']['hard_assignment'].tolist(),
                'performance_metrics': final_results['step4']['performance_metrics'],
                'optimized_feedback': {'overall_score': np.mean(final_results['step4']['feedback_signal'])},
                'smart_suggestions': final_results['step4']['recommendations'],
                'anomaly_report': {'anomaly_count': 0},
                'timestamp': time.time(),
                'node_count': len(final_results['step3']['hard_assignment']),
                'shard_distribution': final_results['step3']['shard_distribution']
            }
            
            # ä¿å­˜ç»“æœæ–‡ä»¶
            results_file = self.output_dir / "four_step_sharding_results.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(complete_results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"   âœ… åˆ†ç‰‡ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
            
            # åˆ›å»ºAPIæ¥å£æ–‡ä»¶
            api_script = self.create_api_interface()
            logger.info(f"   ğŸ”— APIæ¥å£å·²åˆ›å»º: {api_script}")
            
            # ä¿å­˜åˆ°æ ‡å‡†ä½ç½®ä¾›BlockEmulatorè°ƒç”¨
            standard_location = Path("./sharding_api_results.json")
            with open(standard_location, 'w', encoding='utf-8') as f:
                json.dump(complete_results, f, indent=2, ensure_ascii=False, default=str)
            
            return {
                'success': True,
                'results_file': str(results_file),
                'standard_file': str(standard_location),
                'api_interface': api_script,
                'ready_for_blockemulator_call': True
            }
            
        except Exception as e:
            logger.error(f"   âŒ ç»“æœä¿å­˜å¤±è´¥: {e}")
            
            return {
                'success': False,
                'error': str(e)
            }
    
    def run_complete_integration_test(self, num_nodes: int = 20) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´å››æ­¥åˆ†ç‰‡æµç¨‹é›†æˆæµ‹è¯•")
        logger.info("=" * 80)
        
        start_time = time.time()
        test_results = {
            'test_start_time': start_time,
            'test_config': {'num_nodes': num_nodes},
            'steps': {}
        }
        
        try:
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            logger.info(f"ğŸ“‹ æµ‹è¯•é…ç½®: {num_nodes} ä¸ªèŠ‚ç‚¹")
            blockchain_data = self.create_mock_blockchain_data(num_nodes)
            
            # ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–
            step1_result = self.run_step1_feature_extraction(blockchain_data)
            test_results['steps']['step1'] = {
                'success': True,
                'feature_shape': str(step1_result['features'].shape),
                'edge_count': step1_result['edge_index'].shape[1] if 'edge_index' in step1_result else 0
            }
            
            # ç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å­¦ä¹ 
            step2_result = self.run_step2_multiscale_learning(step1_result)
            test_results['steps']['step2'] = {
                'success': True,
                'embedding_shape': str(step2_result['temporal_embeddings'].shape)
            }
            
            # ç¬¬ä¸‰æ­¥ï¼šEvolveGCNåˆ†ç‰‡
            step3_result = self.run_step3_evolve_gcn_sharding(step2_result, step1_result)
            test_results['steps']['step3'] = {
                'success': True,
                'num_shards': step3_result['actual_num_shards'],
                'shard_distribution': step3_result['shard_distribution']
            }
            
            # ç¬¬å››æ­¥ï¼šæ€§èƒ½åé¦ˆ
            step4_result = self.run_step4_performance_feedback(step3_result, step1_result, step2_result)
            test_results['steps']['step4'] = {
                'success': True,
                'performance_metrics': step4_result['performance_metrics'],
                'overall_score': np.mean(step4_result['feedback_signal'])
            }
            
            # æ•´åˆæ‰€æœ‰ç»“æœ
            final_results = {
                'step1': step1_result,
                'step2': step2_result,
                'step3': step3_result,
                'step4': step4_result
            }
            
            # åº”ç”¨åˆ°BlockEmulator
            integration_result = self.apply_to_blockemulator(final_results)
            test_results['integration'] = integration_result
            
            # è®¡ç®—æ€»ä½“æµ‹è¯•æ—¶é—´
            test_results['test_duration'] = time.time() - start_time
            test_results['overall_success'] = True
            
            logger.info("ğŸ‰ é›†æˆæµ‹è¯•å®Œå…¨æˆåŠŸï¼")
            logger.info(f"   æ€»è€—æ—¶: {test_results['test_duration']:.2f} ç§’")
            logger.info(f"   æ•´ä½“æ€§èƒ½åˆ†æ•°: {test_results['steps']['step4']['overall_score']:.3f}")
            
            return test_results
            
        except Exception as e:
            test_results['overall_success'] = False
            test_results['error'] = str(e)
            test_results['test_duration'] = time.time() - start_time
            
            logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            return test_results

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•"""
    print("ğŸ¯ BlockEmulatorå››æ­¥åˆ†ç‰‡ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºé›†æˆç³»ç»Ÿ
    system = IntegratedFourStepShardingSystem()
    
    # è¿è¡Œæµ‹è¯•
    results = system.run_complete_integration_test(num_nodes=25)
    
    # ä¿å­˜å®Œæ•´æµ‹è¯•ç»“æœ
    results_file = system.output_dir / "complete_integration_test_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nğŸ“‹ å®Œæ•´æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
    print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   æ•´ä½“çŠ¶æ€: {'âœ… æˆåŠŸ' if results['overall_success'] else 'âŒ å¤±è´¥'}")
    print(f"   æ€»è€—æ—¶: {results['test_duration']:.2f} ç§’")
    
    if results['overall_success']:
        print(f"   æ€§èƒ½åˆ†æ•°: {results['steps']['step4']['overall_score']:.3f}")
        print(f"   åˆ†ç‰‡æ•°é‡: {results['steps']['step3']['num_shards']}")
        print(f"   è´Ÿè½½å‡è¡¡: {results['steps']['step4']['performance_metrics']['load_balance']:.3f}")
        print(f"   è·¨åˆ†ç‰‡ç‡: {results['steps']['step4']['performance_metrics']['cross_shard_ratio']:.3f}")
    
    print("\nğŸ”§ é›†æˆæ¥å£å·²å‡†å¤‡å¥½ä¾›BlockEmulatorè°ƒç”¨ï¼")
    return results['overall_success']

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
