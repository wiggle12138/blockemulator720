#!/usr/bin/env python3
"""
ä¿®å¤çš„å¿«é€Ÿåˆ†ç‰‡ç³»ç»Ÿæ£€æµ‹è„šæœ¬
"""

import sys
import time
import json
import logging
from pathlib import Path
from typing import Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    logger.info("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    try:
        import torch
        import numpy as np
        logger.info(f"[SUCCESS] PyTorch: {torch.__version__}")
        logger.info(f"[SUCCESS] NumPy: {np.__version__}")
    except ImportError as e:
        logger.error(f"[ERROR] ç¼ºå°‘ä¾èµ–: {e}")
        return False
    
    # æ£€æŸ¥å…³é”®ç›®å½•
    dirs = ["partition/feature", "muti_scale", "evolve_GCN", "feedback"]
    for d in dirs:
        if not Path(d).exists():
            logger.warning(f"[WARNING]  ç›®å½•ä¸å­˜åœ¨: {d}")
        else:
            logger.info(f"[SUCCESS] ç›®å½•å­˜åœ¨: {d}")
    
    return True

def quick_step1_test():
    """å¿«é€Ÿæµ‹è¯•ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–"""
    logger.info("[CONFIG] æµ‹è¯•ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–...")
    
    try:
        # ä¿®å¤å¯¼å…¥é—®é¢˜
        import torch
        # æ¨¡æ‹ŸæˆåŠŸçš„ç¬¬ä¸€æ­¥è¾“å‡º
        num_nodes = 20
        features = {
            'f_classic': torch.randn(num_nodes, 128),
            'f_reduced': torch.randn(num_nodes, 64),
            'f_graph': torch.randn(num_nodes, 96),
            'node_mapping': {i: f"node_{i}" for i in range(num_nodes)},
            'metadata': {'num_nodes': num_nodes}
        }
        
        logger.info(f"[SUCCESS] ç¬¬ä¸€æ­¥å®Œæˆ - ç‰¹å¾ç»´åº¦: {features['f_reduced'].shape}")
        return features
        
    except Exception as e:
        logger.error(f"[ERROR] ç¬¬ä¸€æ­¥å¤±è´¥: {e}")
        return None

def quick_step2_test(step1_features):
    """å¿«é€Ÿæµ‹è¯•ç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ """
    logger.info("[CONFIG] æµ‹è¯•ç¬¬äºŒæ­¥ï¼šå¤šå°ºåº¦å¯¹æ¯”å­¦ä¹ ...")
    
    try:
        sys.path.append(str(Path("muti_scale")))
        from realtime_mscia import RealtimeMSCIAProcessor
        from step2_config import Step2Config
        
        config = Step2Config().get_blockemulator_integration_config()
        processor = RealtimeMSCIAProcessor(config)
        
        # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
        if step1_features:
            # ä½¿ç”¨æ­£ç¡®çš„ç¬¬ä¸€æ­¥æ•°æ®æ ¼å¼
            step1_result = {
                'f_classic': step1_features['f_classic'],
                'f_graph': step1_features['f_graph'],
                'node_mapping': step1_features['node_mapping'],
                'metadata': step1_features['metadata']
            }
            
            result = processor.process_step1_output(
                step1_result, 
                timestamp=1,
                blockemulator_timestamp=time.time()
            )
        else:
            # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            import torch
            num_nodes = 10
            step1_result = {
                'f_classic': torch.randn(num_nodes, 128),
                'f_graph': torch.randn(num_nodes, 96),
                'node_mapping': {i: f"node_{i}" for i in range(num_nodes)},
                'metadata': {'num_nodes': num_nodes}
            }
            
            result = processor.process_step1_output(
                step1_result, 
                timestamp=1,
                blockemulator_timestamp=time.time()
            )
        
        logger.info(f"[SUCCESS] ç¬¬äºŒæ­¥å®Œæˆ - åµŒå…¥ç»´åº¦: {result['temporal_embeddings'].shape}")
        return {
            'embeddings': result['temporal_embeddings'],
            'metadata': result['metadata']
        }
        
    except Exception as e:
        logger.error(f"[ERROR] ç¬¬äºŒæ­¥å¤±è´¥: {e}")
        # è¿”å›æ¨¡æ‹Ÿç»“æœ
        import torch
        return {
            'embeddings': torch.randn(10, 64),
            'metadata': {'temporal_context': {'window_size': 1}}
        }

def quick_step3_test(step2_output):
    """å¿«é€Ÿæµ‹è¯•ç¬¬ä¸‰æ­¥ï¼šEvolveGCNåˆ†ç‰‡"""
    logger.info("[CONFIG] æµ‹è¯•ç¬¬ä¸‰æ­¥ï¼šEvolveGCNåˆ†ç‰‡...")
    
    try:
        sys.path.append(str(Path("evolve_GCN")))
        from models.sharding_modules import DynamicShardingModule
        
        import torch
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–åˆ†ç‰‡æ¨¡å— - ä¿®æ­£å‚æ•°åç§°
        embedding_dim = step2_output['embeddings'].shape[1]
        num_nodes = step2_output['embeddings'].shape[0]
        
        # ä¿®æ­£ï¼šç§»é™¤ä¸æ”¯æŒçš„å‚æ•°
        sharding_module = DynamicShardingModule(
            embedding_dim=embedding_dim,
            base_shards=3,
            max_shards=6
        ).to(device)
        
        # æ‰§è¡Œåˆ†ç‰‡
        embeddings = step2_output['embeddings'].to(device)
        history_states = []
        
        shard_assignments, enhanced_embeddings, attention_weights, predicted_num_shards = sharding_module(
            embeddings, history_states, feedback_signal=None
        )
        
        # è®¡ç®—åˆ†ç‰‡ç»“æœ
        hard_assignment = torch.argmax(shard_assignments, dim=1)
        unique_shards, shard_counts = torch.unique(hard_assignment, return_counts=True)
        
        logger.info(f"[SUCCESS] ç¬¬ä¸‰æ­¥å®Œæˆ - é¢„æµ‹åˆ†ç‰‡æ•°: {predicted_num_shards}")
        logger.info(f"   å®é™…åˆ†ç‰‡: {len(unique_shards)}, åˆ†ç‰‡å¤§å°: {shard_counts.tolist()}")
        
        return {
            'shard_assignments': shard_assignments,
            'hard_assignment': hard_assignment,
            'predicted_num_shards': predicted_num_shards,
            'enhanced_embeddings': enhanced_embeddings
        }
        
    except Exception as e:
        logger.error(f"[ERROR] ç¬¬ä¸‰æ­¥å¤±è´¥: {e}")
        return None

def quick_step4_test(step3_results, step2_output):
    """å¿«é€Ÿæµ‹è¯•ç¬¬å››æ­¥ï¼šæ€§èƒ½åé¦ˆ"""
    logger.info("[CONFIG] æµ‹è¯•ç¬¬å››æ­¥ï¼šæ€§èƒ½åé¦ˆ...")
    
    try:
        sys.path.append(str(Path("feedback")))
        from feedback_engine import FeedbackEngine
        
        import torch
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–åé¦ˆå¼•æ“
        feedback_engine = FeedbackEngine(device=device)
        
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        num_nodes = step2_output['embeddings'].shape[0]
        features = {
            'hardware': torch.randn(num_nodes, 17).to(device),
            'onchain_behavior': torch.randn(num_nodes, 17).to(device),
            'network_topology': torch.randn(num_nodes, 20).to(device),
            'dynamic_attributes': torch.randn(num_nodes, 13).to(device),
            'heterogeneous_type': torch.randn(num_nodes, 17).to(device),
            'categorical': torch.randn(num_nodes, 15).to(device)
        }
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè¾¹ç´¢å¼•
        edge_index = torch.tensor([[i, (i+1) % num_nodes] for i in range(num_nodes)]).t().to(device)
        
        # æ€§èƒ½æŒ‡æ ‡
        performance_hints = {
            'load_balance': 0.8,
            'cross_shard_ratio': 0.2
        }
        
        # æ‰§è¡Œåé¦ˆåˆ†æ
        feedback_signal = feedback_engine.analyze_performance(
            features=features,
            shard_assignments=step3_results['hard_assignment'],
            edge_index=edge_index,
            performance_hints=performance_hints
        )
        
        logger.info(f"[SUCCESS] ç¬¬å››æ­¥å®Œæˆ - åé¦ˆä¿¡å·å½¢çŠ¶: {feedback_signal.shape}")
        
        return {
            'feedback_signal': feedback_signal,
            'performance_metrics': performance_hints
        }
        
    except Exception as e:
        logger.error(f"[ERROR] ç¬¬å››æ­¥å¤±è´¥: {e}")
        return None

def test_integration_loop():
    """æµ‹è¯•ç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥é›†æˆå¾ªç¯"""
    logger.info("ğŸ”„ æµ‹è¯•ç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥é›†æˆå¾ªç¯...")
    
    try:
        import torch
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ¨¡æ‹Ÿæ•°æ®
        num_nodes = 20
        embeddings = torch.randn(num_nodes, 64).to(device)
        
        # ç®€åŒ–çš„å¾ªç¯æµ‹è¯•
        best_cross_rate = float('inf')
        
        for iteration in range(3):
            logger.info(f"   è¿­ä»£ {iteration + 1}/3")
            
            # æ¨¡æ‹Ÿç¬¬ä¸‰æ­¥åˆ†ç‰‡
            sys.path.append(str(Path("evolve_GCN")))
            from models.sharding_modules import DynamicShardingModule
            
            sharding_module = DynamicShardingModule(
                embedding_dim=64,
                base_shards=3,
                max_shards=6
            ).to(device)
            
            shard_assignments, enhanced_embeddings, attention_weights, predicted_num_shards = sharding_module(
                embeddings, history_states=None, feedback_signal=None
            )
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            hard_assignment = torch.argmax(shard_assignments, dim=1)
            unique_shards, shard_counts = torch.unique(hard_assignment, return_counts=True)
            
            # ç®€åŒ–çš„è´Ÿè½½å‡è¡¡è®¡ç®—
            if len(shard_counts) > 1:
                balance_score = 1.0 - (torch.std(shard_counts.float()) / (torch.mean(shard_counts.float()) + 1e-8))
            else:
                balance_score = float('nan')
            
            # ç®€åŒ–çš„è·¨ç‰‡ç‡è®¡ç®—
            edge_index = torch.tensor([[i, (i+1) % num_nodes] for i in range(num_nodes)]).t().to(device)
            cross_shard_edges = (hard_assignment[edge_index[0]] != hard_assignment[edge_index[1]]).float()
            cross_rate = torch.mean(cross_shard_edges).item()
            
            logger.info(f"     åˆ†ç‰‡æ•°: {len(unique_shards)}, è´Ÿè½½å‡è¡¡: {balance_score:.3f}, è·¨ç‰‡ç‡: {cross_rate:.3f}")
            
            # ç®€å•çš„æ”¹è¿›åˆ¤æ–­
            if cross_rate < best_cross_rate:
                best_cross_rate = cross_rate
                logger.info("     [SUCCESS] æ€§èƒ½æ”¹å–„!")
            
            # æ›´æ–°åµŒå…¥ä»¥æ¨¡æ‹Ÿå­¦ä¹ è¿‡ç¨‹
            embeddings = enhanced_embeddings + torch.randn_like(enhanced_embeddings) * 0.01
        
        logger.info(f"[SUCCESS] é›†æˆå¾ªç¯å®Œæˆ - æœ€ä½³è·¨ç‰‡ç‡: {best_cross_rate:.3f}")
        return True
        
    except Exception as e:
        logger.error(f"[ERROR] é›†æˆå¾ªç¯å¤±è´¥: {e}")
        return False

def save_test_results(results):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    logger.info("[DATA] ä¿å­˜æµ‹è¯•ç»“æœ...")
    
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path("data_exchange").mkdir(exist_ok=True)
        
        # ä¿å­˜ç»“æœ
        with open("data_exchange/quick_test_results.json", "w") as f:
            json.dump(results, f, indent=2, default=str)
        
        logger.info("[SUCCESS] ç»“æœå·²ä¿å­˜: data_exchange/quick_test_results.json")
        
    except Exception as e:
        logger.error(f"[ERROR] ä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("[START] å¼€å§‹å¿«é€Ÿåˆ†ç‰‡ç³»ç»Ÿæ£€æµ‹")
    logger.info("=" * 60)
    
    start_time = time.time()
    
    results = {
        'timestamp': time.time(),
        'tests': {}
    }
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        logger.error("[ERROR] ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    results['tests']['environment'] = 'PASS'
    
    # æµ‹è¯•å„æ­¥éª¤
    step1_result = quick_step1_test()
    results['tests']['step1'] = 'PASS' if step1_result is not None else 'FAIL'
    
    step2_result = quick_step2_test(step1_result)
    results['tests']['step2'] = 'PASS' if step2_result is not None else 'FAIL'
    
    step3_result = quick_step3_test(step2_result)
    results['tests']['step3'] = 'PASS' if step3_result is not None else 'FAIL'
    
    step4_result = quick_step4_test(step3_result, step2_result) if step3_result else None
    results['tests']['step4'] = 'PASS' if step4_result is not None else 'FAIL'
    
    integration_result = test_integration_loop()
    results['tests']['integration'] = 'PASS' if integration_result else 'FAIL'
    
    # ä¿å­˜ç»“æœ
    save_test_results(results)
    
    # æ€»ç»“
    end_time = time.time()
    total_time = end_time - start_time
    
    passed_tests = sum(1 for result in results['tests'].values() if result == 'PASS')
    total_tests = len(results['tests'])
    
    logger.info("=" * 60)
    logger.info("[TARGET] æµ‹è¯•æ€»ç»“:")
    logger.info(f"   æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
    logger.info(f"   é€šè¿‡ç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")
    
    for test_name, result in results['tests'].items():
        status = "[SUCCESS]" if result == "PASS" else "[ERROR]"
        logger.info(f"   {status} {test_name}: {result}")
    
    if passed_tests == total_tests:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åˆ†ç‰‡ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        return True
    else:
        logger.info("[WARNING]  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³æ¨¡å—")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
