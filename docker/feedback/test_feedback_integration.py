#!/usr/bin/env python3
"""
ç¬¬å››æ­¥åé¦ˆæœºåˆ¶é›†æˆæµ‹è¯•
æµ‹è¯•ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥çš„æ•°æ®æµå¯¹æ¥
"""

import torch
import numpy as np
import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent / "evolve_GCN"))

def test_simple_feedback_integration():
    """ç®€å•çš„åé¦ˆé›†æˆæµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹ç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥åé¦ˆé›†æˆæµ‹è¯•...")
    
    # 1. æ¨¡æ‹Ÿç¬¬ä¸‰æ­¥åˆ†ç‰‡ç»“æœ
    print("\n[DATA] æ¨¡æ‹Ÿç¬¬ä¸‰æ­¥åˆ†ç‰‡ç»“æœ:")
    num_nodes = 60
    num_shards = 3
    embedding_dim = 64
    
    # èŠ‚ç‚¹åµŒå…¥
    node_embeddings = torch.randn(num_nodes, embedding_dim)
    
    # åˆ†ç‰‡åˆ†é…çŸ©é˜µ (æ¨¡æ‹Ÿç¬¬ä¸‰æ­¥è¾“å‡º)
    shard_assignment = torch.zeros(num_nodes, num_shards)
    for i in range(num_nodes):
        shard_id = i % num_shards  # ç®€å•è½®è¯¢åˆ†é…
        shard_assignment[i, shard_id] = 1.0
    
    print(f"   èŠ‚ç‚¹æ•°: {num_nodes}")
    print(f"   åˆ†ç‰‡æ•°: {num_shards}")
    print(f"   åµŒå…¥ç»´åº¦: {embedding_dim}")
    
    # è®¡ç®—åˆ†ç‰‡å¤§å°
    shard_sizes = torch.sum(shard_assignment, dim=0)
    print(f"   åˆ†ç‰‡å¤§å°: {shard_sizes.tolist()}")
    
    # 2. å¯¼å…¥ç¬¬ä¸‰æ­¥åˆ†ç‰‡æ¨¡å—
    print("\n[CONFIG] æµ‹è¯•ç¬¬ä¸‰æ­¥åˆ†ç‰‡æ¨¡å—:")
    try:
        from models.sharding_modules import DynamicShardingModule
        
        # åˆ›å»ºåˆ†ç‰‡æ¨¡å—
        sharding_module = DynamicShardingModule(
            embedding_dim=embedding_dim,
            base_shards=3,
            max_shards=6,
            min_shard_size=5,
            max_empty_ratio=0.2
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        result_assignment, enhanced_embeddings, attention_weights, actual_k = sharding_module(
            Z=node_embeddings,
            history_states=None,
            feedback_signal=None
        )
        
        print(f"   [SUCCESS] ç¬¬ä¸‰æ­¥åˆ†ç‰‡æ¨¡å—å·¥ä½œæ­£å¸¸")
        print(f"   è¾“å‡ºåˆ†ç‰‡æ•°: {actual_k}")
        print(f"   è¾“å‡ºåˆ†é…çŸ©é˜µå½¢çŠ¶: {result_assignment.shape}")
        
    except Exception as e:
        print(f"   [ERROR] ç¬¬ä¸‰æ­¥æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        result_assignment = shard_assignment
        actual_k = num_shards
    
    # 3. å¯¼å…¥å¹¶æµ‹è¯•ç¬¬å››æ­¥åé¦ˆå¼•æ“
    print("\nğŸ”„ æµ‹è¯•ç¬¬å››æ­¥åé¦ˆå¼•æ“:")
    try:
        from unified_feedback_engine import UnifiedFeedbackEngine
        
        # åˆ›å»ºåé¦ˆå¼•æ“
        feedback_engine = UnifiedFeedbackEngine()
        
        # æ¨¡æ‹Ÿç¬¬å››æ­¥æ‰€éœ€çš„ç‰¹å¾æ•°æ®
        features = {
            'hardware': torch.randn(num_nodes, 17),
            'onchain_behavior': torch.randn(num_nodes, 17),
            'network_topology': torch.randn(num_nodes, 20),
            'dynamic_attributes': torch.randn(num_nodes, 13),
            'heterogeneous_type': torch.randn(num_nodes, 17),
            'categorical': torch.randn(num_nodes, 15)
        }
        
        # è½¬æ¢åˆ†ç‰‡åˆ†é…ä¸ºç¡¬æ ‡ç­¾
        hard_assignment = torch.argmax(result_assignment, dim=1)
        
        # æ¨¡æ‹Ÿæ€§èƒ½æç¤º
        performance_hints = {
            'throughput': [850.0, 820.0, 880.0],  # æ¯ä¸ªåˆ†ç‰‡çš„ååé‡
            'latency': [45.0, 52.0, 38.0],       # æ¯ä¸ªåˆ†ç‰‡çš„å»¶è¿Ÿ
            'load_balance': 0.85,                 # æ•´ä½“è´Ÿè½½å‡è¡¡åº¦
            'cross_shard_ratio': 0.18,           # è·¨ç‰‡äº¤æ˜“æ¯”ä¾‹
            'security_level': 0.95,              # å®‰å…¨ç­‰çº§
            'consensus_efficiency': 0.88          # å…±è¯†æ•ˆç‡
        }
        
        # æ‰§è¡Œåé¦ˆåˆ†æ
        feedback_matrix = feedback_engine.analyze_performance(
            features=features,
            shard_assignments=hard_assignment,
            edge_index=None,
            performance_hints=performance_hints
        )
        
        print(f"   [SUCCESS] ç¬¬å››æ­¥åé¦ˆå¼•æ“å·¥ä½œæ­£å¸¸")
        print(f"   åé¦ˆä¿¡å·å½¢çŠ¶: {feedback_matrix.shape}")
        
        # æ¨¡æ‹Ÿå®Œæ•´åé¦ˆç»“æœä»¥å…¼å®¹åç»­æµ‹è¯•
        feedback_result = {
            'feedback_signal': feedback_matrix,
            'overall_score': 0.85,
            'recommendations': ['improve_load_balance', 'reduce_cross_shard']
        }
        print(f"   æ”¹è¿›å»ºè®®æ•°é‡: {len(feedback_result.get('recommendations', []))}")
        
        # 4. æµ‹è¯•åé¦ˆä¿¡å·æ³¨å…¥ç¬¬ä¸‰æ­¥
        print("\nğŸ” æµ‹è¯•åé¦ˆä¿¡å·æ³¨å…¥:")
        
        feedback_signal = feedback_result['feedback_signal']
        enhanced_assignment, _, _, _ = sharding_module(
            Z=node_embeddings,
            history_states=None,
            feedback_signal=feedback_signal
        )
        
        # è®¡ç®—åé¦ˆå‰åçš„å·®å¼‚
        assignment_diff = torch.norm(enhanced_assignment - result_assignment).item()
        print(f"   åé¦ˆå‰ååˆ†é…å·®å¼‚: {assignment_diff:.4f}")
        
        if assignment_diff > 0.01:
            print(f"   [SUCCESS] åé¦ˆä¿¡å·æˆåŠŸå½±å“äº†åˆ†ç‰‡åˆ†é…")
        else:
            print(f"   [WARNING] åé¦ˆä¿¡å·å½±å“è¾ƒå°")
        
        # 5. åˆ†æåé¦ˆæ•ˆæœ
        print("\nğŸ“ˆ åé¦ˆæ•ˆæœåˆ†æ:")
        
        # è®¡ç®—æ–°åˆ†ç‰‡å¤§å°
        new_hard_assignment = torch.argmax(enhanced_assignment, dim=1)
        new_shard_sizes = torch.bincount(new_hard_assignment, minlength=int(actual_k))
        
        print(f"   åŸå§‹åˆ†ç‰‡å¤§å°: {torch.sum(result_assignment, dim=0).tolist()}")
        print(f"   åé¦ˆååˆ†ç‰‡å¤§å°: {new_shard_sizes.tolist()}")
        
        # è®¡ç®—è´Ÿè½½å‡è¡¡æ”¹è¿›
        original_balance = 1.0 - torch.std(torch.sum(result_assignment, dim=0)) / torch.mean(torch.sum(result_assignment, dim=0))
        new_balance = 1.0 - torch.std(new_shard_sizes.float()) / torch.mean(new_shard_sizes.float())
        
        print(f"   åŸå§‹è´Ÿè½½å‡è¡¡åº¦: {original_balance:.3f}")
        print(f"   åé¦ˆåè´Ÿè½½å‡è¡¡åº¦: {new_balance:.3f}")
        
        if new_balance > original_balance:
            print(f"   [SUCCESS] è´Ÿè½½å‡è¡¡å¾—åˆ°æ”¹å–„ (+{(new_balance - original_balance):.3f})")
        else:
            print(f"   [WARNING] è´Ÿè½½å‡è¡¡ç•¥æœ‰ä¸‹é™ ({(new_balance - original_balance):.3f})")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] ç¬¬å››æ­¥åé¦ˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_edge_cases():
    """æµ‹è¯•è¾¹ç¼˜æƒ…å†µ"""
    print("\nğŸ” æµ‹è¯•è¾¹ç¼˜æƒ…å†µ:")
    
    # æµ‹è¯•ç»´åº¦ä¸åŒ¹é…çš„åé¦ˆ
    print("   æµ‹è¯•ç»´åº¦ä¸åŒ¹é…...")
    try:
        from models.sharding_modules import DynamicShardingModule
        
        sharding_module = DynamicShardingModule(embedding_dim=32, base_shards=3)
        embeddings = torch.randn(50, 32)
        
        # åˆ›å»ºä¸åŒ¹é…ç»´åº¦çš„åé¦ˆä¿¡å·
        mismatched_feedback = torch.randn(50, 6)  # 6ä¸ªåˆ†ç‰‡çš„åé¦ˆï¼Œä½†å½“å‰åªæœ‰3ä¸ª
        
        result, _, _, actual_k = sharding_module(
            Z=embeddings,
            feedback_signal=mismatched_feedback
        )
        
        print(f"   [SUCCESS] ç»´åº¦ä¸åŒ¹é…å¤„ç†æˆåŠŸ: {mismatched_feedback.shape} -> {result.shape}")
        
    except Exception as e:
        print(f"   [ERROR] ç»´åº¦ä¸åŒ¹é…æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•ç©ºåˆ†ç‰‡å¤„ç†
    print("   æµ‹è¯•ç©ºåˆ†ç‰‡å¤„ç†...")
    try:
        # åˆ›å»ºå®¹æ˜“äº§ç”Ÿç©ºåˆ†ç‰‡çš„æ•°æ®
        clustered_embeddings = torch.zeros(30, 32)
        clustered_embeddings[:15, :] = torch.randn(15, 32) + 2  # ç¬¬ä¸€ä¸ªèšç±»
        clustered_embeddings[15:25, :] = torch.randn(10, 32) - 2  # ç¬¬äºŒä¸ªèšç±»
        clustered_embeddings[25:, :] = torch.randn(5, 32)  # æ•£ç‚¹
        
        result, _, _, actual_k = sharding_module(
            Z=clustered_embeddings,
            feedback_signal=None
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºåˆ†ç‰‡
        hard_assignment = torch.argmax(result, dim=1)
        shard_sizes = torch.bincount(hard_assignment, minlength=int(actual_k))
        empty_shards = torch.sum(shard_sizes == 0).item()
        
        print(f"   [SUCCESS] ç©ºåˆ†ç‰‡å¤„ç†: {empty_shards} ä¸ªç©ºåˆ†ç‰‡, æœ€ç»ˆ {actual_k} ä¸ªåˆ†ç‰‡")
        
    except Exception as e:
        print(f"   [ERROR] ç©ºåˆ†ç‰‡æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("=" * 70)
    print("ç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥åé¦ˆæœºåˆ¶é›†æˆæµ‹è¯•")
    print("=" * 70)
    
    # ä¸»è¦æµ‹è¯•
    success = test_simple_feedback_integration()
    
    # è¾¹ç¼˜æƒ…å†µæµ‹è¯•
    test_edge_cases()
    
    print("\n" + "=" * 70)
    if success:
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼ç¬¬ä¸‰æ­¥-ç¬¬å››æ­¥åé¦ˆé›†æˆå·¥ä½œæ­£å¸¸")
    else:
        print("[ERROR] æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—")
    print("=" * 70)
