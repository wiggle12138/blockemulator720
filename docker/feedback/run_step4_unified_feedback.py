#!/usr/bin/env python3
"""
ç¬¬å››æ­¥ï¼šç»Ÿä¸€åé¦ˆå¤„ç†ä¸»å…¥å£
æ•´åˆä¼˜åŒ–æ€§èƒ½è¯„ä¼°ã€é‡è¦æ€§åˆ†æã€å¼‚å¸¸æ£€æµ‹ç­‰æœºåˆ¶ï¼Œä¸ºç¬¬ä¸‰æ­¥åˆ†ç‰‡ä¼˜åŒ–æä¾›æ™ºèƒ½åé¦ˆ
"""

import torch
import numpy as np
import pickle
import json
import sys
import os
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.append(str(project_root))
sys.path.append(str(current_dir))

from unified_feedback_engine import UnifiedFeedbackEngine

def load_step3_results(step3_output_dir: str = "../evolve_GCN/") -> Tuple[Dict[str, torch.Tensor], torch.Tensor, torch.Tensor]:
    """
    åŠ è½½ç¬¬ä¸‰æ­¥çš„åˆ†ç‰‡ç»“æœ
    
    Returns:
        features: 6ç±»ç‰¹å¾å­—å…¸
        shard_assignments: åˆ†ç‰‡åˆ†é…ç»“æœ
        edge_index: è¾¹ç´¢å¼•
    """
    step3_dir = Path(step3_output_dir)
    
    print(f"ğŸ“‚ ä»ç¬¬ä¸‰æ­¥åŠ è½½åˆ†ç‰‡ç»“æœ...")
    print(f"   æŸ¥æ‰¾ç›®å½•: {step3_dir.resolve()}")
    
    # 1. åŠ è½½ç‰¹å¾æ•°æ® - æ™ºèƒ½æŸ¥æ‰¾
    possible_files = [
        "step1_large_samples.pt",
        "large_samples.pt", 
        "../large_samples.csv",
        "../examples/large_samples.csv"
    ]
    
    features_file = None
    for filename in possible_files:
        candidate = step3_dir / filename
        if candidate.exists():
            features_file = candidate
            break
    
    if features_file is None:
        print(f"[WARNING] æœªæ‰¾åˆ°ç‰¹å¾æ–‡ä»¶ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
        num_nodes = 100
        features = {
            'node_features': torch.randn(num_nodes, 64),
            'timestamps': torch.arange(num_nodes, dtype=torch.float32),
            'num_nodes': num_nodes
        }
        step3_data = features
    else:
        try:
            if features_file.suffix == '.csv':
                import pandas as pd
                df = pd.read_csv(features_file)
                features = {
                    'node_features': torch.tensor(df.select_dtypes(include=[float, int]).values[:100], dtype=torch.float32),
                    'timestamps': torch.arange(min(100, len(df)), dtype=torch.float32),
                    'num_nodes': min(100, len(df))
                }
                step3_data = features
            else:
                step3_data = torch.load(features_file, map_location='cpu')
            print(f"   [SUCCESS] ç‰¹å¾æ–‡ä»¶: {features_file.name}")
        except Exception as e:
            print(f"   [ERROR] åŠ è½½å¤±è´¥: {e}, ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            features = {
                'node_features': torch.randn(100, 64),
                'timestamps': torch.arange(100, dtype=torch.float32), 
                'num_nodes': 100
            }
            step3_data = features
    
    # 2. åŠ è½½é‚»æ¥ä¿¡æ¯
    adjacency_file = step3_dir / "step1_adjacency_raw.pt"
    if not adjacency_file.exists():
        adjacency_file = step3_dir / "adjacency_raw.pt" 
    
    if adjacency_file.exists():
        adjacency_data = torch.load(adjacency_file, map_location='cpu')
        print(f"   é‚»æ¥æ–‡ä»¶: {adjacency_file.name}")
    else:
        print(f"[WARNING] æœªæ‰¾åˆ°é‚»æ¥æ–‡ä»¶ï¼Œå°†ç”Ÿæˆæ¨¡æ‹Ÿè¾¹ç´¢å¼•")
        adjacency_data = None
    
    # 3. æå–æˆ–ç”Ÿæˆåˆ†ç‰‡åˆ†é…ç»“æœ
    if 'shard_assignments' in step3_data:
        shard_assignments = step3_data['shard_assignments']
        print(f"   åˆ†ç‰‡åˆ†é…: {shard_assignments.shape} - {shard_assignments.max().item()+1} ä¸ªåˆ†ç‰‡")
    else:
        # ç”Ÿæˆæ¨¡æ‹Ÿåˆ†ç‰‡åˆ†é…
        num_nodes = step3_data.get('f_classic', torch.randn(1000, 128)).shape[0]
        num_shards = min(8, max(3, num_nodes // 100))
        shard_assignments = torch.randint(0, num_shards, (num_nodes,))
        print(f"   æ¨¡æ‹Ÿåˆ†ç‰‡åˆ†é…: {num_nodes} èŠ‚ç‚¹ -> {num_shards} åˆ†ç‰‡")
    
    # 4. æå–6ç±»ç‰¹å¾
    features = extract_six_feature_types(step3_data)
    
    # 5. æå–è¾¹ç´¢å¼•
    edge_index = extract_edge_index_from_data(adjacency_data, len(shard_assignments))
    
    print(f"[SUCCESS] ç¬¬ä¸‰æ­¥æ•°æ®åŠ è½½å®Œæˆ")
    print(f"   èŠ‚ç‚¹æ•°: {len(shard_assignments)}")
    print(f"   ç‰¹å¾ç±»åˆ«: {list(features.keys())}")
    print(f"   è¾¹æ•°: {edge_index.size(1) if edge_index is not None else 0}")
    
    return features, shard_assignments, edge_index


def extract_six_feature_types(step3_data: Dict) -> Dict[str, torch.Tensor]:
    """ä»ç¬¬ä¸‰æ­¥æ•°æ®ä¸­æå–6ç±»ç‰¹å¾"""
    
    # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„åˆ†ç±»ç‰¹å¾
    if all(k in step3_data for k in ['hardware', 'onchain_behavior', 'network_topology', 
                                     'dynamic_attributes', 'heterogeneous_type', 'categorical']):
        return {k: step3_data[k] for k in ['hardware', 'onchain_behavior', 'network_topology',
                                          'dynamic_attributes', 'heterogeneous_type', 'categorical']}
    
    # ä»ç»å…¸ç‰¹å¾ä¸­åˆ†å‰²
    if 'f_classic' in step3_data:
        f_classic = step3_data['f_classic']
        num_nodes = f_classic.shape[0]
        feature_dim = f_classic.shape[1]
        
        print(f"   ä» f_classic åˆ†å‰²6ç±»ç‰¹å¾: {f_classic.shape}")
        
        # æŒ‰é¢„å®šä¹‰ç»´åº¦åˆ†å‰²
        original_dims = {
            'hardware': 17,
            'onchain_behavior': 17, 
            'network_topology': 20,
            'dynamic_attributes': 13,
            'heterogeneous_type': 17,
            'categorical': 15
        }
        
        features = {}
        start_idx = 0
        
        for feature_name, dim in original_dims.items():
            end_idx = start_idx + dim
            if end_idx <= feature_dim:
                features[feature_name] = f_classic[:, start_idx:end_idx].clone()
            else:
                # ç»´åº¦ä¸è¶³æ—¶ç”Ÿæˆåˆç†ç‰¹å¾
                features[feature_name] = generate_realistic_feature(feature_name, num_nodes, dim)
            start_idx = end_idx
            print(f"     {feature_name}: {features[feature_name].shape}")
        
        return features
    
    # å…œåº•ï¼šç”Ÿæˆå®Œæ•´çš„æ¨¡æ‹Ÿç‰¹å¾
    num_nodes = step3_data.get('num_nodes', 1000)
    print(f"   ç”Ÿæˆæ¨¡æ‹Ÿ6ç±»ç‰¹å¾: {num_nodes} èŠ‚ç‚¹")
    
    return {
        'hardware': generate_realistic_feature('hardware', num_nodes, 17),
        'onchain_behavior': generate_realistic_feature('onchain_behavior', num_nodes, 17),
        'network_topology': generate_realistic_feature('network_topology', num_nodes, 20),
        'dynamic_attributes': generate_realistic_feature('dynamic_attributes', num_nodes, 13),
        'heterogeneous_type': generate_realistic_feature('heterogeneous_type', num_nodes, 17),
        'categorical': generate_realistic_feature('categorical', num_nodes, 15)
    }


def generate_realistic_feature(feature_name: str, num_nodes: int, dim: int) -> torch.Tensor:
    """ç”Ÿæˆç¬¦åˆå®é™…ä¸šåŠ¡çš„ç‰¹å¾æ•°æ®"""
    
    base_ranges = {
        'hardware': (0.4, 0.9),           # ç¡¬ä»¶æ€§èƒ½é€šå¸¸åœ¨ä¸­ç­‰åä¸ŠèŒƒå›´
        'onchain_behavior': (0.3, 0.9),   # é“¾ä¸Šè¡Œä¸ºè¡¨ç°å·®å¼‚è¾ƒå¤§
        'network_topology': (0.3, 0.7),   # ç½‘ç»œæ‹“æ‰‘ç›¸å¯¹ç¨³å®š
        'dynamic_attributes': (0.1, 0.9), # åŠ¨æ€å±æ€§å˜åŒ–å¾ˆå¤§
        'heterogeneous_type': (0.2, 0.8), # å¼‚æ„ç±»å‹ç›¸å¯¹é›†ä¸­
        'categorical': (0.3, 0.8)         # åˆ†ç±»ç‰¹å¾ç›¸å¯¹ç¨³å®š
    }
    
    min_val, max_val = base_ranges.get(feature_name, (0.25, 0.75))
    
    # ç”Ÿæˆå¸¦æœ‰ä¸€å®šåˆ†å¸ƒç‰¹å¾çš„æ•°æ®
    base_tensor = torch.rand(num_nodes, dim)
    scaled_tensor = base_tensor * (max_val - min_val) + min_val
    
    # æ·»åŠ ä¸€äº›çœŸå®æ€§ï¼šæŸäº›ç‰¹å¾ç›¸å…³æ€§
    if feature_name == 'hardware':
        # ç¡¬ä»¶ç‰¹å¾é€šå¸¸ç›¸å…³ï¼ˆCPUé«˜çš„æœºå™¨å†…å­˜ä¹Ÿé«˜ï¼‰
        correlation_factor = torch.randn(num_nodes, 1) * 0.1
        scaled_tensor += correlation_factor.expand(-1, dim)
    elif feature_name == 'dynamic_attributes':
        # åŠ¨æ€ç‰¹å¾å¢åŠ æ—¶é—´ç›¸å…³æ€§
        time_factor = torch.sin(torch.arange(num_nodes).float() / 100).unsqueeze(1)
        scaled_tensor += time_factor.expand(-1, dim) * 0.1
    
    return torch.clamp(scaled_tensor, 0.0, 1.0)


def extract_edge_index_from_data(adjacency_data: Dict, num_nodes: int) -> torch.Tensor:
    """ä»é‚»æ¥æ•°æ®ä¸­æå–è¾¹ç´¢å¼•"""
    
    if adjacency_data is None:
        # ç”Ÿæˆæ¨¡æ‹Ÿç½‘ç»œå›¾
        print(f"   ç”Ÿæˆæ¨¡æ‹Ÿè¾¹ç´¢å¼•: {num_nodes} èŠ‚ç‚¹")
        edges_per_node = min(8, max(2, num_nodes // 50))  # æ¯èŠ‚ç‚¹å¹³å‡è¿æ¥æ•°
        total_edges = num_nodes * edges_per_node // 2
        
        # éšæœºç”Ÿæˆè¾¹ï¼Œç¡®ä¿ä¸€å®šçš„è¿é€šæ€§
        source_nodes = torch.randint(0, num_nodes, (total_edges,))
        target_nodes = torch.randint(0, num_nodes, (total_edges,))
        
        # å»é™¤è‡ªç¯
        valid_mask = source_nodes != target_nodes
        source_nodes = source_nodes[valid_mask]
        target_nodes = target_nodes[valid_mask]
        
        edge_index = torch.stack([source_nodes, target_nodes], dim=0)
        return edge_index
    
    # ä»å·²æœ‰æ•°æ®ä¸­æå–
    if 'edge_index' in adjacency_data:
        edge_index = adjacency_data['edge_index']
    elif 'original_edge_index' in adjacency_data:
        edge_index = adjacency_data['original_edge_index']
    elif 'adjacency_matrix' in adjacency_data:
        adj_matrix = adjacency_data['adjacency_matrix']
        edges = torch.nonzero(adj_matrix, as_tuple=False)
        edge_index = edges.t()
    else:
        print(f"[WARNING] é‚»æ¥æ•°æ®æ ¼å¼æœªçŸ¥ï¼Œç”Ÿæˆæ¨¡æ‹Ÿè¾¹ç´¢å¼•")
        return extract_edge_index_from_data(None, num_nodes)
    
    # ç¡®ä¿æ ¼å¼æ­£ç¡® [2, num_edges]
    if edge_index.shape[0] != 2:
        edge_index = edge_index.t()
    
    return edge_index


def run_step4_feedback(step3_output_dir: str = "../evolve_GCN/", 
                      output_dir: str = "./", 
                      config: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    è¿è¡Œç¬¬å››æ­¥ç»Ÿä¸€åé¦ˆå¤„ç†
    
    Args:
        step3_output_dir: ç¬¬ä¸‰æ­¥è¾“å‡ºç›®å½•
        output_dir: ç¬¬å››æ­¥è¾“å‡ºç›®å½•  
        config: åé¦ˆå¼•æ“é…ç½®
        
    Returns:
        åé¦ˆå¤„ç†ç»“æœ
    """
    
    print(f"\n[START] å¼€å§‹ç¬¬å››æ­¥ç»Ÿä¸€åé¦ˆå¤„ç†...")
    print(f"   ç¬¬ä¸‰æ­¥ç›®å½•: {step3_output_dir}")
    print(f"   ç¬¬å››æ­¥ç›®å½•: {output_dir}")
    
    try:
        # 1. åŠ è½½ç¬¬ä¸‰æ­¥ç»“æœ
        features, shard_assignments, edge_index = load_step3_results(step3_output_dir)
        
        # 2. åˆå§‹åŒ–ç»Ÿä¸€åé¦ˆå¼•æ“
        feature_dims = {k: v.shape[1] for k, v in features.items()}
        feedback_engine = UnifiedFeedbackEngine(feature_dims, config)
        
        # 3. å¤„ç†åˆ†ç‰‡åé¦ˆ
        feedback_result = feedback_engine.process_sharding_feedback(
            features=features,
            shard_assignments=shard_assignments,
            edge_index=edge_index,
            performance_hints=None
        )
        
        # 4. ä¿å­˜ç»“æœ
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ä¸»åé¦ˆç»“æœ
        main_result_file = output_path / "step4_feedback_result.pkl"
        with open(main_result_file, 'wb') as f:
            pickle.dump(feedback_result, f)
        
        # ä¸“é—¨ç»™ç¬¬ä¸‰æ­¥çš„åé¦ˆåŒ…
        step3_feedback_file = output_path / "step3_performance_feedback.pkl"
        with open(step3_feedback_file, 'wb') as f:
            pickle.dump(feedback_result['step3_feedback_package'], f)
        
        # JSONæ ¼å¼çš„å¯è¯»ç»“æœ
        readable_result = {
            'overall_score': feedback_result['optimized_feedback']['overall_score'],
            'performance_metrics': feedback_result['performance_metrics'],
            'feature_importance': feedback_result['importance_analysis']['feature_importance'],
            'smart_suggestions': feedback_result['smart_suggestions'],
            'anomaly_count': feedback_result['anomaly_report']['anomaly_count'],
            'engine_status': feedback_result['engine_status']
        }
        
        readable_file = output_path / "step4_readable_result.json"
        with open(readable_file, 'w', encoding='utf-8') as f:
            json.dump(readable_result, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜å¼•æ“çŠ¶æ€
        engine_state_file = output_path / "feedback_engine_state.pkl"
        feedback_engine.save_feedback_state(str(engine_state_file))
        
        print(f"\n[SUCCESS] ç¬¬å››æ­¥åé¦ˆå¤„ç†å®Œæˆ!")
        print(f"   ä¸»ç»“æœæ–‡ä»¶: {main_result_file}")
        print(f"   ç¬¬ä¸‰æ­¥åé¦ˆ: {step3_feedback_file}")
        print(f"   å¯è¯»ç»“æœ: {readable_file}")
        print(f"   å¼•æ“çŠ¶æ€: {engine_state_file}")
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        print(f"\n[DATA] åé¦ˆå¤„ç†æ‘˜è¦:")
        perf = feedback_result['performance_metrics']
        print(f"   ç»¼åˆè¯„åˆ†: {feedback_result['optimized_feedback']['overall_score']:.3f}")
        print(f"   è´Ÿè½½å‡è¡¡: {perf['load_balance']:.3f}")
        print(f"   è·¨ç‰‡äº¤æ˜“ç‡: {perf['cross_shard_rate']:.3f}")
        print(f"   å®‰å…¨æ€§è¯„åˆ†: {perf['security_score']:.3f}")
        print(f"   å…±è¯†å»¶è¿Ÿ: {perf['consensus_latency']:.3f}")
        print(f"   æ™ºèƒ½å»ºè®®æ•°: {len(feedback_result['smart_suggestions'])}")
        print(f"   æ£€æµ‹å¼‚å¸¸æ•°: {feedback_result['anomaly_report']['anomaly_count']}")
        
        # æ‰“å°é‡è¦ç‰¹å¾
        importance = feedback_result['importance_analysis']['feature_importance']
        print(f"\n[TARGET] ç‰¹å¾é‡è¦æ€§æ’åº:")
        sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)
        for feat, score in sorted_importance:
            print(f"   {feat}: {score:.3f}")
        
        # æ‰“å°å…³é”®å»ºè®®
        high_priority_suggestions = [s for s in feedback_result['smart_suggestions'] if s['priority'] == 'high']
        if high_priority_suggestions:
            print(f"\n[WARNING] é«˜ä¼˜å…ˆçº§å»ºè®®:")
            for suggestion in high_priority_suggestions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"   - {suggestion['description']}")
        
        return feedback_result
        
    except Exception as e:
        print(f"[ERROR] ç¬¬å››æ­¥åé¦ˆå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e), 'success': False}


def main():
    """ä¸»å‡½æ•°å…¥å£"""
    
    # é»˜è®¤é…ç½®
    default_config = {
        'max_history': 50,
        'learning_rate': 0.01,
        'feedback_weights': {
            'balance': 0.35,
            'cross_shard': 0.25,
            'security': 0.20,
            'consensus': 0.20
        },
        'adaptive_threshold': 0.15,
        'anomaly_threshold': 2.0,
        'evolution_enabled': True
    }
    
    # è¿è¡Œç¬¬å››æ­¥åé¦ˆå¤„ç†
    result = run_step4_feedback(
        step3_output_dir="../evolve_GCN/",  # æŒ‡å‘ç¬¬ä¸‰æ­¥ç›®å½•
        output_dir="./",
        config=default_config
    )
    
    if result.get('success', True):  # æ²¡æœ‰errorå­—æ®µè¡¨ç¤ºæˆåŠŸ
        print(f"\n ç¬¬å››æ­¥åé¦ˆå¤„ç†æˆåŠŸå®Œæˆ!")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦å»ºè®®éœ€è¦ç«‹å³å…³æ³¨
        if 'smart_suggestions' in result:
            critical_suggestions = [s for s in result['smart_suggestions'] 
                                  if s['priority'] == 'high' and 'balance' in s['type']]
            if critical_suggestions:
                print(f"\n[FIX] å‘ç° {len(critical_suggestions)} ä¸ªå…³é”®è´Ÿè½½å‡è¡¡é—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†!")
    else:
        print(f"\nğŸ’¥ ç¬¬å››æ­¥åé¦ˆå¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å¹¶ä¿®å¤é—®é¢˜")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
