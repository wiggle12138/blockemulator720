"""
ç¬¬å››æ­¥ï¼šåˆ†ç‰‡ç»“æœåé¦ˆä¼˜åŒ–ç‰¹å¾ç©ºé—´ - æ”¯æŒ6ç±»åŸå§‹ç‰¹å¾
"""
import torch
import torch.nn as nn
import numpy as np
from sklearn.feature_selection import mutual_info_regression
from sklearn.metrics import normalized_mutual_info_score
from typing import Dict, List, Tuple, Any, Optional
import json
from collections import defaultdict

class PerformanceEvaluator(nn.Module):
    """å±‚æ¬¡åŒ–åˆ†ç‰‡æ€§èƒ½è¯„ä¼°å™¨ - æ”¯æŒ6ç±»åŸå§‹ç‰¹å¾"""

    def __init__(self, feature_dims: Dict[str, int]):
        super().__init__()
        self.feature_dims = feature_dims

        # éªŒè¯å¿…éœ€çš„6ç±»ç‰¹å¾
        required_features = ['hardware', 'onchain_behavior', 'network_topology',
                             'dynamic_attributes', 'heterogeneous_type', 'categorical']

        for feature in required_features:
            if feature not in feature_dims:
                print(f"[WARNING] ç¼ºå¤±ç‰¹å¾ç±»åˆ«: {feature}ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦")

        # è·å–å®é™…ç‰¹å¾ç»´åº¦ï¼Œè®¾ç½®é»˜è®¤å€¼
        self.hw_dim = feature_dims.get('hardware', 17)
        self.onchain_dim = feature_dims.get('onchain_behavior', 17)
        self.topology_dim = feature_dims.get('network_topology', 20)
        self.dynamic_dim = feature_dims.get('dynamic_attributes', 13)
        self.hetero_dim = feature_dims.get('heterogeneous_type', 17)
        self.categorical_dim = feature_dims.get('categorical', 15)

        print(f"ğŸ“‹ PerformanceEvaluator æ”¯æŒçš„6ç±»ç‰¹å¾:")
        print(f"  - hardware: {self.hw_dim}ç»´")
        print(f"  - onchain_behavior: {self.onchain_dim}ç»´")
        print(f"  - network_topology: {self.topology_dim}ç»´")
        print(f"  - dynamic_attributes: {self.dynamic_dim}ç»´")
        print(f"  - heterogeneous_type: {self.hetero_dim}ç»´")
        print(f"  - categorical: {self.categorical_dim}ç»´")

        # 6ç±»ç‰¹å¾å¯¹åº”çš„æƒé‡å‚æ•°
        self.feature_weights = nn.ParameterDict({
            # è´Ÿè½½å‡è¡¡ç›¸å…³æƒé‡
            'hw_to_balance': nn.Parameter(torch.tensor(0.4)),           # ç¡¬ä»¶â†’è´Ÿè½½å‡è¡¡
            'topology_to_balance': nn.Parameter(torch.tensor(0.3)),     # æ‹“æ‰‘â†’è´Ÿè½½å‡è¡¡
            'dynamic_to_balance': nn.Parameter(torch.tensor(0.3)),      # åŠ¨æ€å±æ€§â†’è´Ÿè½½å‡è¡¡

            # è·¨ç‰‡äº¤æ˜“ç›¸å…³æƒé‡
            'categorical_to_cross': nn.Parameter(torch.tensor(0.4)),    # åˆ†ç±»â†’è·¨ç‰‡
            'topology_to_cross': nn.Parameter(torch.tensor(0.3)),       # æ‹“æ‰‘â†’è·¨ç‰‡
            'hetero_to_cross': nn.Parameter(torch.tensor(0.3)),         # å¼‚æ„â†’è·¨ç‰‡

            # å®‰å…¨æ€§ç›¸å…³æƒé‡
            'onchain_to_security': nn.Parameter(torch.tensor(0.6)),     # é“¾ä¸Šè¡Œä¸ºâ†’å®‰å…¨
            'hetero_to_security': nn.Parameter(torch.tensor(0.4)),      # å¼‚æ„ç±»å‹â†’å®‰å…¨

            # ä¸€è‡´æ€§ç›¸å…³æƒé‡
            'onchain_to_consensus': nn.Parameter(torch.tensor(0.5)),    # é“¾ä¸Šè¡Œä¸ºâ†’å…±è¯†
            'dynamic_to_consensus': nn.Parameter(torch.tensor(0.5)),    # åŠ¨æ€å±æ€§â†’å…±è¯†
        })

        # åŸºäº6ç±»ç‰¹å¾çš„æ€§èƒ½æŒ‡æ ‡è®¡ç®—å±‚
        self.metric_calculators = nn.ModuleDict({
            # è´Ÿè½½å‡è¡¡ï¼šç¡¬ä»¶+æ‹“æ‰‘+åŠ¨æ€å±æ€§
            'balance': nn.Linear(self.hw_dim + self.topology_dim + self.dynamic_dim, 1),

            # è·¨ç‰‡äº¤æ˜“ï¼šåˆ†ç±»+æ‹“æ‰‘+å¼‚æ„ç±»å‹
            'cross_shard': nn.Linear(self.categorical_dim + self.topology_dim + self.hetero_dim, 1),

            # å®‰å…¨æ€§ï¼šé“¾ä¸Šè¡Œä¸º+å¼‚æ„ç±»å‹
            'security': nn.Linear(self.onchain_dim + self.hetero_dim, 1),

            # å…±è¯†æ—¶å»¶ï¼šé“¾ä¸Šè¡Œä¸º+åŠ¨æ€å±æ€§
            'consensus': nn.Linear(self.onchain_dim + self.dynamic_dim, 1),

            # ç‰¹å¾èåˆè´¨é‡ï¼šæ‰€æœ‰6ç±»ç‰¹å¾
            'fusion_quality': nn.Linear(
                self.hw_dim + self.onchain_dim + self.topology_dim +
                self.dynamic_dim + self.hetero_dim + self.categorical_dim, 1
            ),
        })

        # 6ç±»ç‰¹å¾çš„ä¸“é—¨è¯„ä¼°å™¨
        self.feature_evaluators = nn.ModuleDict({
            'hardware_evaluator': nn.Sequential(
                nn.Linear(self.hw_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 16),
                nn.ReLU(),
                nn.Linear(16, 1),
                nn.Sigmoid()
            ),
            'onchain_evaluator': nn.Sequential(
                nn.Linear(self.onchain_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'topology_evaluator': nn.Sequential(
                nn.Linear(self.topology_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'dynamic_evaluator': nn.Sequential(
                nn.Linear(self.dynamic_dim, 16),
                nn.ReLU(),
                nn.Linear(16, 1),
                nn.Sigmoid()
            ),
            'hetero_evaluator': nn.Sequential(
                nn.Linear(self.hetero_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'categorical_evaluator': nn.Sequential(
                nn.Linear(self.categorical_dim, 24),
                nn.ReLU(),
                nn.Linear(24, 1),
                nn.Sigmoid()
            ),
        })

        # å†å²çŠ¶æ€ç¼“å­˜
        self.history_window = 24
        self.performance_history = []

        # 6ç±»ç‰¹å¾è´¨é‡å†å²
        self.feature_quality_history = {
            'hardware': [],
            'onchain_behavior': [],
            'network_topology': [],
            'dynamic_attributes': [],
            'heterogeneous_type': [],
            'categorical': []
        }

    def forward(self, features: Dict[str, torch.Tensor],
                shard_assignments: torch.Tensor,
                edge_index: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        åŸºäº6ç±»åŸå§‹ç‰¹å¾çš„å±‚æ¬¡åŒ–æ€§èƒ½è¯„ä¼°

        Args:
            features: 6ç±»åŸå§‹ç‰¹å¾å­—å…¸
            shard_assignments: åˆ†ç‰‡åˆ†é…ç»“æœ [num_nodes, num_shards]
            edge_index: è¾¹ç´¢å¼• [2, num_edges]

        Returns:
            performance_metrics: æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        print(f" è¯„ä¼°è¾“å…¥ç‰¹å¾: {list(features.keys())}")

        # éªŒè¯å¹¶æå–6ç±»ç‰¹å¾
        extracted_features = self._extract_six_feature_types(features)

        metrics = {}

        try:
            # 1. åŸºäºç¡¬ä»¶+æ‹“æ‰‘+åŠ¨æ€å±æ€§çš„è´Ÿè½½å‡è¡¡è¯„ä¼°
            balance_features = self._combine_features_for_balance(extracted_features)
            metrics['balance_score'] = self._compute_load_balance(
                shard_assignments, balance_features, extracted_features
            )

            # 2. åŸºäºåˆ†ç±»+æ‹“æ‰‘+å¼‚æ„çš„è·¨ç‰‡äº¤æ˜“è¯„ä¼°
            cross_features = self._combine_features_for_cross_shard(extracted_features)
            metrics['cross_tx_rate'] = self._compute_cross_shard_rate(
                shard_assignments, edge_index, cross_features, extracted_features
            )

            # 3. åŸºäºé“¾ä¸Šè¡Œä¸º+å¼‚æ„ç±»å‹çš„å®‰å…¨æ€§è¯„ä¼°
            security_features = self._combine_features_for_security(extracted_features)
            metrics['security_score'] = self._compute_security_threshold(
                shard_assignments, security_features, extracted_features
            )

            # 4. åŸºäºé“¾ä¸Šè¡Œä¸º+åŠ¨æ€å±æ€§çš„å…±è¯†æ—¶å»¶è¯„ä¼°
            consensus_features = self._combine_features_for_consensus(extracted_features)
            metrics['consensus_latency'] = self._compute_consensus_latency(
                consensus_features, extracted_features
            )

            # 5. 6ç±»ç‰¹å¾çš„èåˆè´¨é‡è¯„ä¼°
            metrics['fusion_quality'] = self._compute_fusion_quality(
                extracted_features, shard_assignments
            )

            # 6. å„ç±»ç‰¹å¾çš„ç‹¬ç«‹è´¨é‡è¯„ä¼°
            feature_quality_scores = self._evaluate_individual_feature_quality(
                extracted_features, shard_assignments
            )
            metrics.update(feature_quality_scores)

            # 7. ç‰¹å¾é—´ååŒæ€§è¯„ä¼°
            metrics['feature_synergy'] = self._compute_feature_synergy(
                extracted_features, shard_assignments
            )

            # 8. åŠ¨æ€æƒé‡è°ƒæ•´
            metrics = self._apply_six_feature_entropy_weights(metrics, extracted_features)

            # 9. æ›´æ–°å†å²è®°å½•
            self._update_feature_quality_history(feature_quality_scores)
            self._update_history(metrics)

        except Exception as e:
            print(f"[WARNING] 6ç±»ç‰¹å¾æ€§èƒ½è¯„ä¼°å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤æŒ‡æ ‡
            device = shard_assignments.device
            metrics = self._get_default_metrics(device)

        return metrics

    def _extract_six_feature_types(self, features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """æå–å¹¶éªŒè¯6ç±»ç‰¹å¾"""
        extracted = {}

        # è·å–ç¬¬ä¸€ä¸ªç‰¹å¾çš„è®¾å¤‡å’Œæ‰¹æ¬¡å¤§å°ç”¨äºç”Ÿæˆå ä½ç¬¦
        if features:
            sample_tensor = next(iter(features.values()))
            device = sample_tensor.device
            batch_size = sample_tensor.size(0)
        else:
            device = torch.device('cpu')
            batch_size = 100

        # æå–6ç±»ç‰¹å¾ï¼Œå¦‚æœç¼ºå¤±åˆ™ç”Ÿæˆå ä½ç¬¦
        feature_specs = {
            'hardware': self.hw_dim,
            'onchain_behavior': self.onchain_dim,
            'network_topology': self.topology_dim,
            'dynamic_attributes': self.dynamic_dim,
            'heterogeneous_type': self.hetero_dim,
            'categorical': self.categorical_dim
        }

        for feature_name, expected_dim in feature_specs.items():
            if feature_name in features:
                extracted[feature_name] = features[feature_name]
                print(f"[SUCCESS] æå–ç‰¹å¾: {feature_name} {features[feature_name].shape}")
            else:
                # ç”Ÿæˆæœ‰æ„ä¹‰çš„å ä½ç¬¦
                placeholder = self._generate_feature_placeholder(
                    feature_name, batch_size, expected_dim, device
                )
                extracted[feature_name] = placeholder
                print(f"[CONFIG] ç”Ÿæˆå ä½ç¬¦: {feature_name} {placeholder.shape}")

        return extracted

    def _generate_feature_placeholder(self, feature_name: str, batch_size: int,
                                      dim: int, device: torch.device) -> torch.Tensor:
        """ä¸ºç¼ºå¤±çš„ç‰¹å¾ç±»åˆ«ç”Ÿæˆæœ‰æ„ä¹‰çš„å ä½ç¬¦"""
        if feature_name == 'hardware':
            # ç¡¬ä»¶ç‰¹å¾ï¼šCPUã€å†…å­˜ã€å­˜å‚¨ç­‰ï¼Œé€šå¸¸å€¼è¾ƒé«˜
            return torch.rand(batch_size, dim, device=device) * 0.6 + 0.3  # [0.3, 0.9]
        elif feature_name == 'onchain_behavior':
            # é“¾ä¸Šè¡Œä¸ºï¼šäº¤æ˜“å¤„ç†ã€å…±è¯†å‚ä¸ç­‰ï¼Œä¸­ç­‰å˜åŒ–
            return torch.rand(batch_size, dim, device=device) * 0.5 + 0.4  # [0.4, 0.9]
        elif feature_name == 'network_topology':
            # ç½‘ç»œæ‹“æ‰‘ï¼šè¿æ¥æ€§ã€å»¶è¿Ÿç­‰ï¼Œç›¸å¯¹ç¨³å®š
            return torch.rand(batch_size, dim, device=device) * 0.4 + 0.3  # [0.3, 0.7]
        elif feature_name == 'dynamic_attributes':
            # åŠ¨æ€å±æ€§ï¼šè´Ÿè½½ã€çŠ¶æ€ç­‰ï¼Œå˜åŒ–è¾ƒå¤§
            return torch.rand(batch_size, dim, device=device) * 0.8 + 0.1  # [0.1, 0.9]
        elif feature_name == 'heterogeneous_type':
            # å¼‚æ„ç±»å‹ï¼šèŠ‚ç‚¹ç±»å‹ã€è§’è‰²ç­‰ï¼Œç¦»æ•£æ€§è¾ƒå¼º
            return torch.rand(batch_size, dim, device=device) * 0.3 + 0.2  # [0.2, 0.5]
        elif feature_name == 'categorical':
            # åˆ†ç±»ç‰¹å¾ï¼šç±»åˆ«ã€æ ‡ç­¾ç­‰ï¼Œé€šå¸¸è¾ƒä¸ºç¨³å®š
            return torch.rand(batch_size, dim, device=device) * 0.5 + 0.25 # [0.25, 0.75]
        else:
            return torch.rand(batch_size, dim, device=device) * 0.5 + 0.25

    def _combine_features_for_balance(self, features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """ç»„åˆç¡¬ä»¶+æ‹“æ‰‘+åŠ¨æ€å±æ€§ç‰¹å¾ç”¨äºè´Ÿè½½å‡è¡¡è¯„ä¼°"""
        hw_weighted = features['hardware'] * self.feature_weights['hw_to_balance']
        topo_weighted = features['network_topology'] * self.feature_weights['topology_to_balance']
        dynamic_weighted = features['dynamic_attributes'] * self.feature_weights['dynamic_to_balance']

        return torch.cat([hw_weighted, topo_weighted, dynamic_weighted], dim=1)

    def _combine_features_for_cross_shard(self, features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """ç»„åˆåˆ†ç±»+æ‹“æ‰‘+å¼‚æ„ç‰¹å¾ç”¨äºè·¨ç‰‡äº¤æ˜“è¯„ä¼°"""
        cat_weighted = features['categorical'] * self.feature_weights['categorical_to_cross']
        topo_weighted = features['network_topology'] * self.feature_weights['topology_to_cross']
        hetero_weighted = features['heterogeneous_type'] * self.feature_weights['hetero_to_cross']

        return torch.cat([cat_weighted, topo_weighted, hetero_weighted], dim=1)

    def _combine_features_for_security(self, features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """ç»„åˆé“¾ä¸Šè¡Œä¸º+å¼‚æ„ç±»å‹ç‰¹å¾ç”¨äºå®‰å…¨æ€§è¯„ä¼°"""
        onchain_weighted = features['onchain_behavior'] * self.feature_weights['onchain_to_security']
        hetero_weighted = features['heterogeneous_type'] * self.feature_weights['hetero_to_security']

        return torch.cat([onchain_weighted, hetero_weighted], dim=1)

    def _combine_features_for_consensus(self, features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """ç»„åˆé“¾ä¸Šè¡Œä¸º+åŠ¨æ€å±æ€§ç‰¹å¾ç”¨äºå…±è¯†è¯„ä¼°"""
        onchain_weighted = features['onchain_behavior'] * self.feature_weights['onchain_to_consensus']
        dynamic_weighted = features['dynamic_attributes'] * self.feature_weights['dynamic_to_consensus']

        return torch.cat([onchain_weighted, dynamic_weighted], dim=1)

    def _compute_load_balance(self, shard_assignments: torch.Tensor,
                              balance_features: torch.Tensor,
                              original_features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """åŸºäºç¡¬ä»¶+æ‹“æ‰‘+åŠ¨æ€å±æ€§è®¡ç®—è´Ÿè½½å‡è¡¡åº¦"""
        hard_assignment = torch.argmax(shard_assignments, dim=1)
        num_shards = shard_assignments.size(1)

        # è®¡ç®—æ¯ä¸ªåˆ†ç‰‡çš„è´Ÿè½½
        shard_loads = torch.zeros(num_shards, device=shard_assignments.device)

        for s in range(num_shards):
            shard_mask = (hard_assignment == s)
            shard_size = torch.sum(shard_mask).item()

            if shard_size > 0:
                # åŸºç¡€èŠ‚ç‚¹æ•°è´Ÿè½½
                base_load = float(shard_size)

                # ç¡¬ä»¶èƒ½åŠ›åŠ æƒï¼ˆç¡¬ä»¶èƒ½åŠ›é«˜çš„èŠ‚ç‚¹è´Ÿè½½èƒ½åŠ›å¼ºï¼‰
                hw_capability = torch.mean(original_features['hardware'][shard_mask]).item()

                # ç½‘ç»œæ‹“æ‰‘å½±å“ï¼ˆè¿æ¥æ€§å¥½çš„èŠ‚ç‚¹é€šä¿¡å¼€é”€ä½ï¼‰
                topo_efficiency = torch.mean(original_features['network_topology'][shard_mask]).item()

                # åŠ¨æ€å±æ€§å½±å“ï¼ˆå½“å‰è´Ÿè½½çŠ¶æ€ï¼‰
                dynamic_load = torch.mean(original_features['dynamic_attributes'][shard_mask]).item()

                # ç»¼åˆè´Ÿè½½è®¡ç®—
                effective_load = base_load * (1.0 - hw_capability * 0.3) * (1.0 - topo_efficiency * 0.2) * (1.0 + dynamic_load * 0.5)
                shard_loads[s] = effective_load

        # è´Ÿè½½å‡è¡¡åº¦è®¡ç®—ï¼ˆåŸºäºå˜å¼‚ç³»æ•°ï¼‰
        mean_load = torch.mean(shard_loads)
        std_load = torch.std(shard_loads)
        balance_score = 1.0 - (std_load / (mean_load + 1e-8))

        return torch.clamp(balance_score, 0.0, 1.0)

    def _compute_cross_shard_rate(self, shard_assignments: torch.Tensor,
                                  edge_index: torch.Tensor,
                                  cross_features: torch.Tensor,
                                  original_features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """åŸºäºåˆ†ç±»+æ‹“æ‰‘+å¼‚æ„ç‰¹å¾è®¡ç®—è·¨ç‰‡äº¤æ˜“ç‡"""
        hard_assignment = torch.argmax(shard_assignments, dim=1)

        u, v = edge_index[0], edge_index[1]

        # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
        valid_mask = (u < len(hard_assignment)) & (v < len(hard_assignment))
        if valid_mask.sum() == 0:
            return torch.tensor(0.0, device=shard_assignments.device)

        u_valid, v_valid = u[valid_mask], v[valid_mask]
        cross_shard_mask = (hard_assignment[u_valid] != hard_assignment[v_valid])

        total_edges = valid_mask.sum().item()
        cross_edges = cross_shard_mask.sum().item()
        base_cross_rate = cross_edges / max(total_edges, 1)

        if cross_edges > 0:
            cross_u = u_valid[cross_shard_mask]
            cross_v = v_valid[cross_shard_mask]

            # ç¡®ä¿ç‰¹å¾ç´¢å¼•æœ‰æ•ˆ
            max_idx = min(cross_features.size(0) - 1, len(original_features['categorical']) - 1)
            cross_u_clamped = torch.clamp(cross_u, 0, max_idx)
            cross_v_clamped = torch.clamp(cross_v, 0, max_idx)

            # åˆ†ç±»ç‰¹å¾å·®å¼‚ï¼ˆè¯­ä¹‰è·ç¦»ï¼‰
            cat_diff = torch.norm(
                original_features['categorical'][cross_u_clamped] -
                original_features['categorical'][cross_v_clamped], dim=1
            ).mean()

            # å¼‚æ„ç±»å‹å·®å¼‚
            hetero_diff = torch.norm(
                original_features['heterogeneous_type'][cross_u_clamped] -
                original_features['heterogeneous_type'][cross_v_clamped], dim=1
            ).mean()

            # æ‹“æ‰‘è·ç¦»å½±å“
            topo_penalty = torch.norm(
                original_features['network_topology'][cross_u_clamped] -
                original_features['network_topology'][cross_v_clamped], dim=1
            ).mean()

            # ç»¼åˆè·¨ç‰‡å¼€é”€
            semantic_penalty = (cat_diff * 0.4 + hetero_diff * 0.3 + topo_penalty * 0.3).item()
            adjusted_rate = base_cross_rate * (1.0 + semantic_penalty * 0.2)
        else:
            adjusted_rate = base_cross_rate

        return torch.clamp(torch.tensor(adjusted_rate, device=shard_assignments.device), 0.0, 1.0)

    def _compute_security_threshold(self, shard_assignments: torch.Tensor,
                                    security_features: torch.Tensor,
                                    original_features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """åŸºäºé“¾ä¸Šè¡Œä¸º+å¼‚æ„ç±»å‹è®¡ç®—å®‰å…¨é˜ˆå€¼"""
        hard_assignment = torch.argmax(shard_assignments, dim=1)
        num_shards = shard_assignments.size(1)

        min_security = 1.0

        for s in range(num_shards):
            shard_mask = (hard_assignment == s)
            shard_size = torch.sum(shard_mask).item()

            if shard_size > 0:
                # é“¾ä¸Šè¡Œä¸ºå®‰å…¨æ€§ï¼ˆå…±è¯†å‚ä¸ç‡ã€æˆåŠŸç‡ç­‰ï¼‰
                onchain_security = torch.mean(original_features['onchain_behavior'][shard_mask]).item()

                # å¼‚æ„ç±»å‹å¤šæ ·æ€§ï¼ˆç±»å‹è¶Šå¤šæ ·ï¼Œå®‰å…¨æ€§è¶Šé«˜ï¼‰
                hetero_features = original_features['heterogeneous_type'][shard_mask]
                hetero_diversity = torch.std(hetero_features, dim=0).mean().item()

                # åˆ†ç‰‡å¤§å°å®‰å…¨æ€§ï¼ˆè¿‡å°æˆ–è¿‡å¤§çš„åˆ†ç‰‡éƒ½ä¸å®‰å…¨ï¼‰
                size_factor = min(shard_size / 10.0, 1.0) * (1.0 - max(shard_size - 50, 0) / 100.0)

                # ç»¼åˆå®‰å…¨åˆ†æ•°
                shard_security = onchain_security * 0.6 + hetero_diversity * 0.2 + size_factor * 0.2
                min_security = min(min_security, shard_security)

        return torch.tensor(max(min_security, 0.0), device=shard_assignments.device)

    def _compute_consensus_latency(self, consensus_features: torch.Tensor,
                                   original_features: Dict[str, torch.Tensor]) -> torch.Tensor:
        """åŸºäºé“¾ä¸Šè¡Œä¸º+åŠ¨æ€å±æ€§è®¡ç®—å…±è¯†æ—¶å»¶"""
        # é“¾ä¸Šè¡Œä¸ºä¸­çš„å…±è¯†æ•ˆç‡
        onchain_efficiency = torch.mean(original_features['onchain_behavior']).item()

        # åŠ¨æ€å±æ€§ä¸­çš„å½“å‰è´Ÿè½½çŠ¶æ€
        current_load = torch.mean(original_features['dynamic_attributes']).item()

        # å…±è¯†æ—¶å»¶è®¡ç®—ï¼ˆæ•ˆç‡é«˜ã€è´Ÿè½½ä½ â†’ æ—¶å»¶ä½ï¼‰
        base_latency = 1.0 - onchain_efficiency  # æ•ˆç‡è¶Šé«˜ï¼ŒåŸºç¡€æ—¶å»¶è¶Šä½
        load_penalty = current_load * 0.3        # è´Ÿè½½è¶Šé«˜ï¼Œæ—¶å»¶å¢åŠ 

        total_latency = base_latency + load_penalty

        return torch.tensor(max(0.0, min(total_latency, 1.0)), device=consensus_features.device)

    def _compute_fusion_quality(self, features: Dict[str, torch.Tensor],
                                shard_assignments: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—6ç±»ç‰¹å¾çš„èåˆè´¨é‡"""
        # å°†æ‰€æœ‰6ç±»ç‰¹å¾æ‹¼æ¥
        all_features = torch.cat([
            features['hardware'],
            features['onchain_behavior'],
            features['network_topology'],
            features['dynamic_attributes'],
            features['heterogeneous_type'],
            features['categorical']
        ], dim=1)

        # ä½¿ç”¨èåˆè´¨é‡è®¡ç®—å™¨
        fusion_score = self.metric_calculators['fusion_quality'](all_features)

        return torch.sigmoid(fusion_score.mean())  # å½’ä¸€åŒ–åˆ°[0,1]

    def _evaluate_individual_feature_quality(self, features: Dict[str, torch.Tensor],
                                             shard_assignments: torch.Tensor) -> Dict[str, torch.Tensor]:
        """è¯„ä¼°æ¯ç±»ç‰¹å¾çš„ç‹¬ç«‹è´¨é‡"""
        quality_scores = {}

        for feature_name, feature_tensor in features.items():
            if feature_name in self.feature_evaluators:
                evaluator = self.feature_evaluators[feature_name]
                quality_score = evaluator(feature_tensor).mean()
                quality_scores[f'{feature_name}_quality'] = quality_score

        return quality_scores

    def _compute_feature_synergy(self, features: Dict[str, torch.Tensor],
                                 shard_assignments: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—6ç±»ç‰¹å¾é—´çš„ååŒæ€§"""
        # è®¡ç®—ç‰¹å¾é—´çš„ç›¸å…³æ€§
        feature_list = list(features.values())
        synergy_scores = []

        for i in range(len(feature_list)):
            for j in range(i+1, len(feature_list)):
                # è®¡ç®—ç‰¹å¾å¯¹çš„ç›¸ä¼¼æ€§
                feat_i_mean = torch.mean(feature_list[i], dim=1)  # [N]
                feat_j_mean = torch.mean(feature_list[j], dim=1)  # [N]

                # çš®å°”é€Šç›¸å…³ç³»æ•°
                correlation = torch.corrcoef(torch.stack([feat_i_mean, feat_j_mean]))[0, 1]
                synergy_scores.append(abs(correlation))

        if synergy_scores:
            return torch.stack(synergy_scores).mean()
        else:
            return torch.tensor(0.5, device=shard_assignments.device)

    def _apply_six_feature_entropy_weights(self, metrics: Dict[str, torch.Tensor],
                                           features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """åŸºäº6ç±»ç‰¹å¾å†å²çš„ç†µæƒè°ƒæ•´"""
        if len(self.performance_history) < 3:
            return metrics

        try:
            # åŸºäºç‰¹å¾è´¨é‡å†å²è°ƒæ•´æƒé‡
            for feature_name in features.keys():
                quality_key = f'{feature_name}_quality'
                if quality_key in metrics and feature_name in self.feature_quality_history:
                    history = self.feature_quality_history[feature_name]
                    if len(history) >= 3:
                        # è®¡ç®—è´¨é‡ç¨³å®šæ€§
                        stability = 1.0 - np.std(history[-5:]) if len(history) >= 5 else 0.5
                        # è°ƒæ•´å¯¹åº”æŒ‡æ ‡æƒé‡
                        metrics[quality_key] = metrics[quality_key] * stability

        except Exception as e:
            print(f"[WARNING] 6ç±»ç‰¹å¾ç†µæƒè°ƒæ•´å¤±è´¥: {e}")

        return metrics

    def _update_feature_quality_history(self, quality_scores: Dict[str, torch.Tensor]):
        """æ›´æ–°ç‰¹å¾è´¨é‡å†å²"""
        for key, score in quality_scores.items():
            if key.endswith('_quality'):
                feature_name = key.replace('_quality', '')
                if feature_name in self.feature_quality_history:
                    self.feature_quality_history[feature_name].append(score.item())
                    # ä¿æŒå†å²é•¿åº¦
                    if len(self.feature_quality_history[feature_name]) > self.history_window:
                        self.feature_quality_history[feature_name].pop(0)

    def _get_default_metrics(self, device: torch.device) -> Dict[str, torch.Tensor]:
        """è¿”å›é»˜è®¤çš„æ€§èƒ½æŒ‡æ ‡"""
        return {
            'balance_score': torch.tensor(0.5, device=device),
            'cross_tx_rate': torch.tensor(0.2, device=device),
            'security_score': torch.tensor(0.8, device=device),
            'consensus_latency': torch.tensor(0.1, device=device),
            'fusion_quality': torch.tensor(0.6, device=device),
            'hardware_quality': torch.tensor(0.7, device=device),
            'onchain_behavior_quality': torch.tensor(0.6, device=device),
            'network_topology_quality': torch.tensor(0.8, device=device),
            'dynamic_attributes_quality': torch.tensor(0.5, device=device),
            'heterogeneous_type_quality': torch.tensor(0.7, device=device),
            'categorical_quality': torch.tensor(0.6, device=device),
            'feature_synergy': torch.tensor(0.5, device=device)
        }

    def _update_history(self, metrics: Dict[str, torch.Tensor]):
        """æ›´æ–°å†å²è®°å½•"""
        self.performance_history.append(metrics.copy())
        if len(self.performance_history) > self.history_window:
            self.performance_history.pop(0)


class FeatureImportanceAnalyzer:
    """6ç±»ç‰¹å¾é‡è¦æ€§åˆ†æå™¨"""

    def __init__(self, feature_dims: Dict[str, int]):
        self.feature_dims = feature_dims
        self.importance_history = defaultdict(list)

        # 6ç±»ç‰¹å¾åç§°
        self.six_features = ['hardware', 'onchain_behavior', 'network_topology',
                             'dynamic_attributes', 'heterogeneous_type', 'categorical']

    def analyze_importance(self, features: Dict[str, torch.Tensor],
                           performance_scores: Dict[str, torch.Tensor],
                           model: Optional[nn.Module] = None) -> Dict[str, Dict[str, float]]:
        """
        åˆ†æ6ç±»ç‰¹å¾çš„é‡è¦æ€§

        Returns:
            layer_importance: 6ç±»ç‰¹å¾é‡è¦æ€§çŸ©é˜µ
        """
        print(f" åˆ†æ6ç±»ç‰¹å¾é‡è¦æ€§: {list(features.keys())}")

        importance_matrix = {}

        try:
            # 1. æ¢¯åº¦é‡è¦æ€§åˆ†æ
            gradient_importance = self._gradient_importance_analysis(
                features, performance_scores, model
            )

            # 2. äº’ä¿¡æ¯é‡è¦æ€§åˆ†æ
            mutual_info_importance = self._mutual_info_analysis(
                features, performance_scores
            )

            # 3. æ–¹å·®è´¡çŒ®åˆ†æ
            variance_importance = self._variance_contribution_analysis(
                features, performance_scores
            )

            # 4. ç‰¹å¾æ¶ˆèé‡è¦æ€§åˆ†æ
            ablation_importance = self._ablation_importance_analysis(
                features, performance_scores
            )

            # 5. ç»¼åˆé‡è¦æ€§è¯„åˆ†
            for feature_name in self.six_features:
                if feature_name in features:
                    importance_matrix[feature_name] = {
                        'gradient': gradient_importance.get(feature_name, 0.0),
                        'mutual_info': mutual_info_importance.get(feature_name, 0.0),
                        'variance': variance_importance.get(feature_name, 0.0),
                        'ablation': ablation_importance.get(feature_name, 0.0),
                        'combined': self._combine_six_feature_importance(
                            gradient_importance.get(feature_name, 0.0),
                            mutual_info_importance.get(feature_name, 0.0),
                            variance_importance.get(feature_name, 0.0),
                            ablation_importance.get(feature_name, 0.0)
                        )
                    }
                else:
                    # ä¸ºç¼ºå¤±çš„ç‰¹å¾æä¾›é»˜è®¤é‡è¦æ€§
                    importance_matrix[feature_name] = {
                        'gradient': 0.3, 'mutual_info': 0.3, 'variance': 0.3, 'ablation': 0.3, 'combined': 0.3
                    }

        except Exception as e:
            print(f"[WARNING] 6ç±»ç‰¹å¾é‡è¦æ€§åˆ†æå‡ºé”™: {e}")
            # è¿”å›é»˜è®¤é‡è¦æ€§
            for feature_name in self.six_features:
                importance_matrix[feature_name] = {
                    'gradient': 0.5, 'mutual_info': 0.5, 'variance': 0.5, 'ablation': 0.5, 'combined': 0.5
                }

        return importance_matrix

    def _gradient_importance_analysis(self, features: Dict[str, torch.Tensor],
                                      performance_scores: Dict[str, torch.Tensor],
                                      model: Optional[nn.Module] = None) -> Dict[str, float]:
        """åŸºäºæ¢¯åº¦çš„6ç±»ç‰¹å¾é‡è¦æ€§åˆ†æ"""
        importance_scores = {}

        try:
            for feature_name in self.six_features:
                if feature_name in features:
                    feature_tensor = features[feature_name].detach().requires_grad_(True)

                    # è®¡ç®—æ€§èƒ½åˆ†æ•°æ€»å’Œ
                    main_scores = ['balance_score', 'cross_tx_rate', 'security_score', 'consensus_latency']
                    total_score = sum(performance_scores[k] for k in main_scores if k in performance_scores)

                    if isinstance(total_score, torch.Tensor) and total_score.requires_grad:
                        total_score.backward(retain_graph=True)

                        if feature_tensor.grad is not None:
                            grad_norm = torch.norm(feature_tensor.grad, p=2).item()
                            importance_scores[feature_name] = grad_norm
                        else:
                            importance_scores[feature_name] = 0.0
                    else:
                        importance_scores[feature_name] = 0.0
                else:
                    importance_scores[feature_name] = 0.0

        except Exception as e:
            print(f"[WARNING] æ¢¯åº¦é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
            for feature_name in self.six_features:
                importance_scores[feature_name] = 0.5

        return importance_scores

    def _mutual_info_analysis(self, features: Dict[str, torch.Tensor],
                              performance_scores: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """6ç±»ç‰¹å¾çš„äº’ä¿¡æ¯é‡è¦æ€§åˆ†æ"""
        importance_scores = {}

        try:
            # å‡†å¤‡ç›®æ ‡å˜é‡
            main_scores = ['balance_score', 'cross_tx_rate', 'security_score']
            score_values = []
            for score_name in main_scores:
                if score_name in performance_scores:
                    score_values.append(performance_scores[score_name].detach().cpu())

            if score_values:
                target = torch.stack(score_values).mean(dim=0).numpy()

                for feature_name in self.six_features:
                    if feature_name in features:
                        feature_np = features[feature_name].detach().cpu().numpy()

                        # è®¡ç®—æ¯ä¸ªç»´åº¦ä¸ç›®æ ‡çš„äº’ä¿¡æ¯
                        mi_scores = []
                        max_dims = min(feature_np.shape[1], 8)  # é™åˆ¶ç»´åº¦æ•°
                        for dim in range(max_dims):
                            try:
                                mi = mutual_info_regression(
                                    feature_np[:, dim].reshape(-1, 1),
                                    target
                                )[0]
                                mi_scores.append(mi)
                            except:
                                mi_scores.append(0.0)

                        importance_scores[feature_name] = np.mean(mi_scores) if mi_scores else 0.0
                    else:
                        importance_scores[feature_name] = 0.0
            else:
                for feature_name in self.six_features:
                    importance_scores[feature_name] = 0.0

        except Exception as e:
            print(f"[WARNING] äº’ä¿¡æ¯åˆ†æå¤±è´¥: {e}")
            for feature_name in self.six_features:
                importance_scores[feature_name] = 0.5

        return importance_scores

    def _variance_contribution_analysis(self, features: Dict[str, torch.Tensor],
                                        performance_scores: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """6ç±»ç‰¹å¾çš„æ–¹å·®è´¡çŒ®åˆ†æ"""
        importance_scores = {}

        try:
            for feature_name in self.six_features:
                if feature_name in features:
                    feature_tensor = features[feature_name]

                    # è®¡ç®—ç‰¹å¾æ–¹å·®
                    feature_var = torch.var(feature_tensor, dim=0).mean().item()

                    # è®¡ç®—ç‰¹å¾ä¸æ€§èƒ½æŒ‡æ ‡çš„åæ–¹å·®
                    feature_mean = torch.mean(feature_tensor, dim=1)  # [N]

                    covariances = []
                    for score_name, score_tensor in performance_scores.items():
                        if score_name in ['balance_score', 'cross_tx_rate', 'security_score']:
                            try:
                                if isinstance(score_tensor, torch.Tensor):
                                    if score_tensor.dim() == 0:  # æ ‡é‡
                                        score_expanded = score_tensor.expand(len(feature_mean))
                                    else:
                                        score_expanded = score_tensor

                                    cov = torch.cov(torch.stack([feature_mean, score_expanded]))[0, 1].item()
                                    covariances.append(abs(cov))
                            except:
                                continue

                    avg_covariance = np.mean(covariances) if covariances else 0.0
                    importance_scores[feature_name] = feature_var * avg_covariance
                else:
                    importance_scores[feature_name] = 0.0

        except Exception as e:
            print(f"[WARNING] æ–¹å·®è´¡çŒ®åˆ†æå¤±è´¥: {e}")
            for feature_name in self.six_features:
                importance_scores[feature_name] = 0.5

        return importance_scores

    def _ablation_importance_analysis(self, features: Dict[str, torch.Tensor],
                                      performance_scores: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """6ç±»ç‰¹å¾çš„æ¶ˆèé‡è¦æ€§åˆ†æ"""
        importance_scores = {}

        try:
            # åŸºå‡†æ€§èƒ½ï¼ˆä½¿ç”¨æ‰€æœ‰ç‰¹å¾ï¼‰
            baseline_score = sum(score.item() if isinstance(score, torch.Tensor) else score
                                 for key, score in performance_scores.items()
                                 if key in ['balance_score', 'cross_tx_rate', 'security_score'])

            for feature_name in self.six_features:
                if feature_name in features:
                    # æ¨¡æ‹Ÿç§»é™¤è¯¥ç‰¹å¾åçš„æ€§èƒ½ä¸‹é™
                    # è¿™é‡Œç®€åŒ–ä¸ºåŸºäºç‰¹å¾ç»Ÿè®¡é‡çš„ä¼°è®¡
                    feature_contribution = torch.mean(features[feature_name]).item()

                    # ä¸åŒç‰¹å¾ç±»å‹çš„æƒé‡ä¸åŒ
                    feature_weights = {
                        'hardware': 0.3,
                        'onchain_behavior': 0.25,
                        'network_topology': 0.2,
                        'dynamic_attributes': 0.1,
                        'heterogeneous_type': 0.1,
                        'categorical': 0.05
                    }

                    weight = feature_weights.get(feature_name, 0.1)
                    estimated_drop = baseline_score * weight * feature_contribution
                    importance_scores[feature_name] = estimated_drop
                else:
                    importance_scores[feature_name] = 0.0

        except Exception as e:
            print(f"[WARNING] æ¶ˆèåˆ†æå¤±è´¥: {e}")
            for feature_name in self.six_features:
                importance_scores[feature_name] = 0.5

        return importance_scores

    def _combine_six_feature_importance(self, gradient: float, mutual_info: float,
                                        variance: float, ablation: float) -> float:
        """ç»„åˆ6ç±»ç‰¹å¾çš„é‡è¦æ€§åˆ†æ•°"""
        # ä¸åŒåˆ†ææ–¹æ³•çš„æƒé‡
        weights = [0.3, 0.3, 0.2, 0.2]  # gradient, mutual_info, variance, ablation
        scores = [gradient, mutual_info, variance, ablation]

        # å½’ä¸€åŒ–åˆ†æ•°åˆ°[0,1]
        normalized_scores = []
        for score in scores:
            normalized_scores.append(max(0.0, min(1.0, score)))

        combined = sum(w * s for w, s in zip(weights, normalized_scores))
        return max(0.0, min(1.0, combined))


class FeedbackController:
    """ç¬¬å››æ­¥åé¦ˆæ§åˆ¶å™¨ - æ”¯æŒ6ç±»åŸå§‹ç‰¹å¾"""

    def __init__(self, feature_dims: Dict[str, int]):
        self.performance_evaluator = PerformanceEvaluator(feature_dims)
        self.importance_analyzer = FeatureImportanceAnalyzer(feature_dims)
        self.feature_evolution = None

        # 6ç±»ç‰¹å¾åç§°
        self.six_features = ['hardware', 'onchain_behavior', 'network_topology',
                             'dynamic_attributes', 'heterogeneous_type', 'categorical']

        print(f"[SUCCESS] FeedbackController åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒ6ç±»åŸå§‹ç‰¹å¾:")
        for feature in self.six_features:
            dim = feature_dims.get(feature, 0)
            print(f"  - {feature}: {dim}ç»´")

    def process_feedback(self, features: Dict[str, torch.Tensor],
                         shard_assignments: torch.Tensor,
                         edge_index: torch.Tensor,
                         evolve_gcn_model: Optional[nn.Module] = None) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        å¤„ç†6ç±»åŸå§‹ç‰¹å¾çš„åé¦ˆå¹¶ä¼˜åŒ–ç‰¹å¾ç©ºé—´

        Args:
            features: 6ç±»åŸå§‹ç‰¹å¾å­—å…¸
            shard_assignments: åˆ†ç‰‡åˆ†é…ç»“æœ
            edge_index: è¾¹ç´¢å¼•
            evolve_gcn_model: EvolveGCNæ¨¡å‹

        Returns:
            feedback_signal: åé¦ˆä¿¡å· [4] (è´Ÿè½½å‡è¡¡, è·¨ç‰‡ç‡, å®‰å…¨æ€§, ç‰¹å¾è´¨é‡)
            evolved_features: ä¼˜åŒ–åçš„ç‰¹å¾ç©ºé—´
        """
        print(f" å¤„ç†6ç±»åŸå§‹ç‰¹å¾åé¦ˆ - è¾“å…¥ç‰¹å¾: {list(features.keys())}")

        try:
            # 1. åŸºäº6ç±»ç‰¹å¾çš„æ€§èƒ½è¯„ä¼°
            performance_metrics = self.performance_evaluator(
                features, shard_assignments, edge_index
            )

            # 2. 6ç±»ç‰¹å¾é‡è¦æ€§åˆ†æ
            importance_matrix = self.importance_analyzer.analyze_importance(
                features, performance_metrics, evolve_gcn_model
            )

            # 3. 6ç±»ç‰¹å¾ç©ºé—´æ¼”åŒ–
            if self.feature_evolution is None:
                self.feature_evolution = SixFeatureEvolution(features)

            evolved_features = self.feature_evolution.evolve_six_feature_space(
                importance_matrix, performance_metrics
            )

            # 4. ç”Ÿæˆå¢å¼ºçš„åé¦ˆä¿¡å·
            feedback_signal = torch.tensor([
                performance_metrics['balance_score'].item(),
                performance_metrics['cross_tx_rate'].item(),
                performance_metrics['security_score'].item(),
                performance_metrics['fusion_quality'].item()  # æ·»åŠ ç‰¹å¾èåˆè´¨é‡
            ], device=shard_assignments.device)

            print(f"[SUCCESS] 6ç±»ç‰¹å¾åé¦ˆå¤„ç†å®Œæˆ")
            print(f"   åé¦ˆä¿¡å·: {[f'{x:.3f}' for x in feedback_signal.tolist()]}")
            print(f"   é‡è¦æ€§æœ€é«˜çš„ç‰¹å¾: {max(importance_matrix.keys(), key=lambda k: importance_matrix[k]['combined'])}")

        except Exception as e:
            print(f"[WARNING] 6ç±»ç‰¹å¾åé¦ˆå¤„ç†å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤å€¼
            device = shard_assignments.device
            feedback_signal = torch.tensor([0.5, 0.2, 0.8, 0.6], device=device)
            evolved_features = features

        return feedback_signal, evolved_features


class SixFeatureEvolution:
    """6ç±»ç‰¹å¾ç©ºé—´æ¼”åŒ–å™¨"""

    def __init__(self, initial_features: Dict[str, torch.Tensor]):
        self.current_features = initial_features.copy()
        self.feature_history = [initial_features.copy()]
        self.six_features = ['hardware', 'onchain_behavior', 'network_topology',
                             'dynamic_attributes', 'heterogeneous_type', 'categorical']

    def evolve_six_feature_space(self, importance_matrix: Dict[str, Dict[str, float]],
                                 performance_metrics: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """æ¼”åŒ–6ç±»ç‰¹å¾ç©ºé—´"""
        evolved_features = self.current_features.copy()

        # åŸºäºé‡è¦æ€§çŸ©é˜µè°ƒæ•´6ç±»ç‰¹å¾
        for feature_name in self.six_features:
            if feature_name in evolved_features and feature_name in importance_matrix:
                importance = importance_matrix[feature_name]['combined']

                # æ ¹æ®é‡è¦æ€§è°ƒæ•´ç‰¹å¾
                if importance > 0.8:
                    # é«˜é‡è¦æ€§ï¼šå¢å¼ºç‰¹å¾
                    evolved_features[feature_name] = evolved_features[feature_name] * 1.15
                elif importance > 0.6:
                    # ä¸­ç­‰é‡è¦æ€§ï¼šè½»å¾®å¢å¼º
                    evolved_features[feature_name] = evolved_features[feature_name] * 1.05
                elif importance < 0.3:
                    # ä½é‡è¦æ€§ï¼šé™æƒ
                    evolved_features[feature_name] = evolved_features[feature_name] * 0.9

                # ç‰¹å¾ç‰¹å®šçš„è°ƒæ•´ç­–ç•¥
                evolved_features[feature_name] = self._apply_feature_specific_evolution(
                    feature_name, evolved_features[feature_name], performance_metrics
                )

        self.current_features = evolved_features
        self.feature_history.append(evolved_features.copy())

        return evolved_features

    def _apply_feature_specific_evolution(self, feature_name: str, feature_tensor: torch.Tensor,
                                          performance_metrics: Dict[str, torch.Tensor]) -> torch.Tensor:
        """åº”ç”¨ç‰¹å¾ç‰¹å®šçš„æ¼”åŒ–ç­–ç•¥"""
        if feature_name == 'hardware':
            # ç¡¬ä»¶ç‰¹å¾ï¼šå¦‚æœè´Ÿè½½ä¸å‡è¡¡ï¼Œå¢å¼ºç¡¬ä»¶å·®å¼‚åŒ–
            if 'balance_score' in performance_metrics and performance_metrics['balance_score'] < 0.5:
                feature_tensor = feature_tensor * 1.1

        elif feature_name == 'onchain_behavior':
            # é“¾ä¸Šè¡Œä¸ºï¼šå¦‚æœå®‰å…¨æ€§ä½ï¼Œå¢å¼ºå…±è¯†ç›¸å…³ç‰¹å¾
            if 'security_score' in performance_metrics and performance_metrics['security_score'] < 0.6:
                feature_tensor = feature_tensor * 1.08

        elif feature_name == 'network_topology':
            # ç½‘ç»œæ‹“æ‰‘ï¼šå¦‚æœè·¨ç‰‡ç‡é«˜ï¼Œå¢å¼ºæ‹“æ‰‘ç‰¹å¾
            if 'cross_tx_rate' in performance_metrics and performance_metrics['cross_tx_rate'] > 0.3:
                feature_tensor = feature_tensor * 1.05

        return feature_tensor