"""
ä¸»è¦æµæ°´çº¿
"""
from datetime import datetime

import torch
import torch.nn as nn
import json
import csv
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Any, Optional
def smart_import():
    """æ™ºèƒ½å¯¼å…¥å‡½æ•°"""
    try:
        # ç›´æ¥å¯¼å…¥æ¨¡å—ï¼Œå¤±è´¥æ—¶ç«‹å³æŠ¥é”™
        from nodeInitialize import Node, load_nodes_from_csv
        from feature_extractor import UnifiedFeatureExtractor
        from feature_fusion import FeatureFusionPipeline
        from config import FeatureDimensions
        from adaptive_feature_extractor import AdaptiveFeatureExtractor
        return Node, load_nodes_from_csv, UnifiedFeatureExtractor, FeatureFusionPipeline, FeatureDimensions, AdaptiveFeatureExtractor
    except ImportError as e:
        raise ImportError(f"ä¸»è¦æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            return Node, load_nodes_from_csv, UnifiedFeatureExtractor, FeatureFusionPipeline, FeatureDimensions, AdaptiveFeatureExtractor
        except ImportError:
            # æ–¹å¼3ï¼šç›´æ¥å¯¼å…¥ï¼ˆè„šæœ¬æ¨¡å¼ï¼‰
            import sys
            import os
            current_dir = os.path.dirname(os.path.abspath(__file__))
            sys.path.insert(0, current_dir)
            
            from nodeInitialize import Node, load_nodes_from_csv
            from feature_extractor import UnifiedFeatureExtractor
            from feature_fusion import FeatureFusionPipeline
            from config import FeatureDimensions
            from adaptive_feature_extractor import AdaptiveFeatureExtractor
            return Node, load_nodes_from_csv, UnifiedFeatureExtractor, FeatureFusionPipeline, FeatureDimensions, AdaptiveFeatureExtractor

# æ‰§è¡Œæ™ºèƒ½å¯¼å…¥
Node, load_nodes_from_csv, UnifiedFeatureExtractor, FeatureFusionPipeline, FeatureDimensions, AdaptiveFeatureExtractor = smart_import()

class Pipeline:
    """ç¬¬ä¸€æ­¥å®Œæ•´æµæ°´çº¿ - ä½¿ç”¨å…¨é¢ç‰¹å¾"""

    def __init__(self, use_fusion: bool = True, save_adjacency: bool = True):
        """
        åˆå§‹åŒ–æµæ°´çº¿

        Args:
            use_fusion: æ˜¯å¦ä½¿ç”¨ç‰¹å¾èåˆ
            save_adjacency: æ˜¯å¦ä¿å­˜é‚»æ¥çŸ©é˜µä¿¡æ¯
        """
        self.use_fusion = use_fusion
        self.save_adjacency = save_adjacency  # æ–°å¢å‚æ•°
        self.dims = FeatureDimensions()
        self.adaptive_mode = False
        self.adaptive_extractor = None

        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.feature_extractor = UnifiedFeatureExtractor()

        if self.use_fusion:
            self.fusion_pipeline = FeatureFusionPipeline(
                classic_dim=self.dims.CLASSIC_DIM,
                graph_dim=self.dims.GRAPH_OUTPUT_DIM,
                fused_dim=self.dims.FUSED_DIM
            )

        print(f"Step1Pipelineåˆå§‹åŒ–å®Œæˆ - èåˆæ¨¡å¼: {use_fusion}, é‚»æ¥çŸ©é˜µä¿å­˜: {save_adjacency}")
        print(f"é…ç½®ç»´åº¦ - Classic: {self.dims.CLASSIC_DIM}, Graph: {self.dims.GRAPH_OUTPUT_DIM}, Fused: {self.dims.FUSED_DIM}")

    def extract_features(self, nodes: List[Node]) -> Dict[str, torch.Tensor]:
        """
        æ‰§è¡Œå®Œæ•´çš„ç‰¹å¾æå–æµç¨‹

        Args:
            nodes: èŠ‚ç‚¹åˆ—è¡¨

        Returns:
            results: åŒ…å«F_classic, F_graph, F_fusedçš„å­—å…¸
        """
        print(f"å¼€å§‹å¤„ç† {len(nodes)} ä¸ªèŠ‚ç‚¹çš„å…¨é¢ç‰¹å¾æå–...")

        # æå–F_classicå’ŒF_graph
        f_classic, f_graph = self.feature_extractor(nodes)

        results = {
            'f_classic': f_classic,   # [N, 128]
            'f_graph': f_graph,       # [N, 96]
            'nodes': nodes
        }

        print(f"åŸºç¡€ç‰¹å¾æå–å®Œæˆ - F_classic: {f_classic.shape}, F_graph: {f_graph.shape}")

        # æ–°å¢ï¼šä¿å­˜é‚»æ¥çŸ©é˜µä¿¡æ¯
        if self.save_adjacency:
            self._save_adjacency_information()

        # å¦‚æœå¯ç”¨èåˆ
        if self.use_fusion:
            print("å¼€å§‹ç‰¹å¾èåˆ...")
            f_fused, contrastive_loss = self.fusion_pipeline(f_classic, f_graph)
            results['f_fused'] = f_fused  # [N, 256]
            results['contrastive_loss'] = contrastive_loss
            print(f"ç‰¹å¾èåˆå®Œæˆ - F_fused: {f_fused.shape}, å¯¹æ¯”æŸå¤±: {contrastive_loss:.4f}")

        return results

    def _save_adjacency_information(self):
        """ä¿å­˜é‚»æ¥çŸ©é˜µç›¸å…³ä¿¡æ¯"""
        print(f"\n=== ä¿å­˜é‚»æ¥çŸ©é˜µä¿¡æ¯ ===")

        try:
            # 1. ä¿å­˜åŸå§‹å›¾æ„å»ºçš„é‚»æ¥çŸ©é˜µ
            graph_builder = self.feature_extractor.graph_feature_extractor.graph_builder
            if hasattr(graph_builder, 'adjacency_info') and graph_builder.adjacency_info:
                graph_builder.save_adjacency_matrices("step1_adjacency")
            else:
                print("è­¦å‘Š: å›¾æ„å»ºå™¨ä¸­æ²¡æœ‰é‚»æ¥çŸ©é˜µä¿¡æ¯")

            # 2. ä¿å­˜RGCNä¸­é—´è¡¨ç¤º
            rgcn_extractor = self.feature_extractor.graph_feature_extractor
            if hasattr(rgcn_extractor, 'intermediate_representations') and rgcn_extractor.intermediate_representations:
                rgcn_extractor.save_rgcn_representations("step1_rgcn")
            else:
                print("è­¦å‘Š: RGCNæå–å™¨ä¸­æ²¡æœ‰ä¸­é—´è¡¨ç¤ºä¿¡æ¯")

        except Exception as e:
            print(f"ä¿å­˜é‚»æ¥çŸ©é˜µä¿¡æ¯æ—¶å‡ºé”™: {e}")

    def load_and_extract(self, csv_file: str) -> Dict[str, torch.Tensor]:
        """
        ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®å¹¶æå–ç‰¹å¾

        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„

        Returns:
            ç‰¹å¾æå–ç»“æœ
        """
        # åŠ è½½èŠ‚ç‚¹æ•°æ®
        nodes = load_nodes_from_csv(csv_file)
        print(f"æˆåŠŸä» {csv_file} åŠ è½½ {len(nodes)} ä¸ªèŠ‚ç‚¹")

        # æå–ç‰¹å¾
        results = self.extract_features(nodes)

        print(f"\n=== æœ€ç»ˆç‰¹å¾æå–ç»“æœ ===")
        print(f"F_classic shape: {results['f_classic'].shape}")
        print(f"F_graph shape: {results['f_graph'].shape}")

        if 'f_fused' in results:
            print(f"F_fused shape: {results['f_fused'].shape}")
            print(f"å¯¹æ¯”å­¦ä¹ æŸå¤±: {results['contrastive_loss']:.4f}")

        return results

    def save_features(self, results: Dict[str, torch.Tensor], save_path: str = "step1_comprehensive_features.pt"):
        """
        ä¿å­˜ç‰¹å¾æå–ç»“æœ

        Args:
            results: ç‰¹å¾æå–ç»“æœ
            save_path: ä¿å­˜è·¯å¾„
        """
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®ï¼ˆæ’é™¤nodeså¯¹è±¡ï¼‰
        save_data = {}
        for key, value in results.items():
            if key != 'nodes' and isinstance(value, torch.Tensor):
                save_data[key] = value
            elif key == 'contrastive_loss':
                save_data[key] = value

        # æ·»åŠ å…ƒæ•°æ®
        save_data['metadata'] = {
            'num_nodes': results['f_classic'].shape[0],
            'classic_dim': results['f_classic'].shape[1],
            'graph_dim': results['f_graph'].shape[1],
            'use_fusion': 'f_fused' in results,
            'feature_version': 'comprehensive_v1.0'
        }

        if 'f_fused' in results:
            save_data['metadata']['fused_dim'] = results['f_fused'].shape[1]

        torch.save(save_data, save_path)
        print(f"ç‰¹å¾æ•°æ®å·²ä¿å­˜åˆ°: {save_path}")
        return save_path

    def save_features_with_adjacency(self, results: Dict[str, torch.Tensor], base_name: str = "step1_features"):
        """
        ä¿å­˜ç‰¹å¾å’Œé‚»æ¥çŸ©é˜µä¿¡æ¯

        Args:
            results: ç‰¹å¾æå–ç»“æœ
            base_name: åŸºç¡€æ–‡ä»¶å
        """
        # 1. ä¿å­˜å¸¸è§„ç‰¹å¾
        feature_path = self.save_features(results, f"{base_name}.pt")

        # 2. ä¿å­˜å¯è¯»æ ¼å¼ç‰¹å¾
        self.save_readable_features(results, base_name)

        # 3. ä¿å­˜é‚»æ¥çŸ©é˜µä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.save_adjacency:
            self._save_comprehensive_adjacency_info(base_name)

        return feature_path

    def _save_comprehensive_adjacency_info(self, base_name: str):
        """
        ä¿å­˜ç»¼åˆçš„é‚»æ¥çŸ©é˜µä¿¡æ¯

        Args:
            base_name: åŸºç¡€æ–‡ä»¶å
        """
        print(f"\n=== ä¿å­˜ç»¼åˆé‚»æ¥çŸ©é˜µä¿¡æ¯ ===")

        try:
            # è·å–å›¾æ„å»ºå™¨å’ŒRGCNæå–å™¨
            graph_builder = self.feature_extractor.graph_feature_extractor.graph_builder
            rgcn_extractor = self.feature_extractor.graph_feature_extractor

            # æ•´åˆæ‰€æœ‰é‚»æ¥çŸ©é˜µä¿¡æ¯
            comprehensive_info = {
                'generation_info': {
                    'timestamp': str(pd.Timestamp.now()),
                    'pipeline_config': {
                        'use_fusion': self.use_fusion,
                        'save_adjacency': self.save_adjacency,
                        'classic_dim': self.dims.CLASSIC_DIM,
                        'graph_dim': self.dims.GRAPH_OUTPUT_DIM,
                        'fused_dim': self.dims.FUSED_DIM if self.use_fusion else None
                    }
                }
            }

            # æ·»åŠ åŸå§‹å›¾ä¿¡æ¯
            if hasattr(graph_builder, 'adjacency_info') and graph_builder.adjacency_info:
                comprehensive_info['original_graph'] = graph_builder.adjacency_info

            # æ·»åŠ RGCNå¤„ç†ä¿¡æ¯
            if hasattr(rgcn_extractor, 'intermediate_representations') and rgcn_extractor.intermediate_representations:
                comprehensive_info['rgcn_processing'] = {
                    'layer_statistics': rgcn_extractor.intermediate_representations['layer_statistics'],
                    'tensor_shapes': {
                        'input_shape': list(rgcn_extractor.intermediate_representations['rgcn_input'].shape),
                        'hidden_shape': list(rgcn_extractor.intermediate_representations['rgcn_hidden'].shape),
                        'output_shape': list(rgcn_extractor.intermediate_representations['rgcn_output'].shape)
                    }
                }

            # ä¿å­˜ç»¼åˆä¿¡æ¯
            with open(f"{base_name}_adjacency_comprehensive.json", 'w', encoding='utf-8') as f:
                json.dump(comprehensive_info, f, indent=2, ensure_ascii=False, default=str)

            print(f"  âœ“ ç»¼åˆé‚»æ¥çŸ©é˜µä¿¡æ¯: {base_name}_adjacency_comprehensive.json")

            # ä¿å­˜PyTorchæ ¼å¼çš„å®Œæ•´æ•°æ®
            if (hasattr(graph_builder, 'adjacency_info') and graph_builder.adjacency_info and
                    hasattr(rgcn_extractor, 'intermediate_representations') and rgcn_extractor.intermediate_representations):

                complete_adjacency_data = {
                    'original_adjacency_matrix': torch.from_numpy(graph_builder.adjacency_info['adjacency_matrix_dense']),
                    'original_relation_matrix': torch.from_numpy(graph_builder.adjacency_info['relation_matrix']),
                    'original_edge_index': torch.from_numpy(graph_builder.adjacency_info['edge_index_coo']),
                    'original_edge_type': torch.from_numpy(graph_builder.adjacency_info['edge_type']),
                    'rgcn_input_features': rgcn_extractor.intermediate_representations['rgcn_input'],
                    'rgcn_hidden_features': rgcn_extractor.intermediate_representations['rgcn_hidden'],
                    'rgcn_output_features': rgcn_extractor.intermediate_representations['rgcn_output'],
                    'metadata': comprehensive_info['generation_info']
                }

                torch.save(complete_adjacency_data, f"{base_name}_adjacency_complete.pt")
                print(f"  âœ“ å®Œæ•´é‚»æ¥çŸ©é˜µæ•°æ®: {base_name}_adjacency_complete.pt")

        except Exception as e:
            print(f"ä¿å­˜ç»¼åˆé‚»æ¥çŸ©é˜µä¿¡æ¯æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    def save_readable_features(self, results: Dict[str, torch.Tensor], base_name: str = "features"):
        """
        ä¿å­˜å¯è¯»æ ¼å¼çš„ç‰¹å¾æ•°æ®

        Args:
            results: ç‰¹å¾æå–ç»“æœ
            base_name: åŸºç¡€æ–‡ä»¶å
        """
        print(f"\n=== ä¿å­˜å¯è¯»æ ¼å¼ç‰¹å¾ ===")

        # 1. å•ç‹¬ä¿å­˜æ¯ç§ç‰¹å¾ç±»å‹
        self._save_individual_features(results, base_name)

        # 2. ä¿å­˜ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
        self._save_feature_statistics(results, f"{base_name}_statistics.json")


        print(f"[SUCCESS] å¯è¯»æ ¼å¼ç‰¹å¾å·²ä¿å­˜å®Œæˆ")


    def _save_individual_features(self, results: Dict[str, torch.Tensor], base_name: str):
        """å•ç‹¬ä¿å­˜æ¯ç§ç‰¹å¾ç±»å‹"""
        print(f"å•ç‹¬ä¿å­˜å„ç‰¹å¾ç±»å‹...")

        # ä¿å­˜ F_classic ç‰¹å¾
        self._save_single_feature_type(
            results['f_classic'],
            f"{base_name}_f_classic.csv",
            "f_classic"
        )

        # ä¿å­˜ F_graph ç‰¹å¾
        self._save_single_feature_type(
            results['f_graph'],
            f"{base_name}_f_graph.csv",
            "f_graph"
        )

        # ä¿å­˜ F_fused ç‰¹å¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'f_fused' in results:
            self._save_single_feature_type(
                results['f_fused'],
                f"{base_name}_f_fused.csv",
                "f_fused"
            )

        # ä¿å­˜å„ç‰¹å¾ç±»å‹çš„è¯¦ç»†ç»Ÿè®¡
        self._save_individual_statistics(results, base_name)

    def _save_single_feature_type(self, tensor: torch.Tensor, csv_path: str, feature_type: str):
        """ä¿å­˜å•ä¸€ç‰¹å¾ç±»å‹åˆ°CSV"""
        print(f"  ä¿å­˜ {feature_type}: {csv_path}")

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        feature_array = tensor.detach().cpu().numpy()
        num_nodes, num_features = feature_array.shape

        # åˆ›å»ºDataFrame
        data = {}
        data['node_id'] = list(range(num_nodes))

        # æ·»åŠ ç‰¹å¾åˆ—
        for i in range(num_features):
            data[f'{feature_type}_{i:03d}'] = feature_array[:, i]

        df = pd.DataFrame(data)

        # ä¿å­˜ä¸ºCSV
        df.to_csv(csv_path, index=False, float_format='%.6f')

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"    âœ“ å½¢çŠ¶: {feature_array.shape}")
        print(f"    âœ“ æ•°å€¼èŒƒå›´: [{np.min(feature_array):.3f}, {np.max(feature_array):.3f}]")
        print(f"    âœ“ å‡å€¼: {np.mean(feature_array):.3f}, æ ‡å‡†å·®: {np.std(feature_array):.3f}")

    def _save_individual_statistics(self, results: Dict[str, torch.Tensor], base_name: str):
        """ä¿å­˜å„ç‰¹å¾ç±»å‹çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        stats_path = f"{base_name}_individual_statistics.json"
        print(f"  ä¿å­˜è¯¦ç»†ç»Ÿè®¡: {stats_path}")

        detailed_stats = {
            'generation_time': str(pd.Timestamp.now()),
            'feature_analysis': {}
        }

        # åˆ†ææ¯ç§ç‰¹å¾ç±»å‹
        for feature_name, tensor in results.items():
            if isinstance(tensor, torch.Tensor):
                feature_array = tensor.detach().cpu().numpy()

                # è®¡ç®—è¯¦ç»†ç»Ÿè®¡
                stats = {
                    'shape': list(tensor.shape),
                    'dtype': str(tensor.dtype),
                    'overall_stats': self._compute_detailed_stats(feature_array),
                    'dimension_wise_stats': self._compute_dimension_wise_stats(feature_array),
                    'scale_analysis': self._analyze_feature_scale(feature_array)
                }

                detailed_stats['feature_analysis'][feature_name] = stats

        # ä¿å­˜è¯¦ç»†ç»Ÿè®¡
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_stats, f, indent=2, ensure_ascii=False)

        print(f"    âœ“ è¯¦ç»†ç»Ÿè®¡å·²ä¿å­˜")


    def _compute_detailed_stats(self, feature_array: np.ndarray) -> Dict[str, Any]:
        """è®¡ç®—è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'mean': float(np.mean(feature_array)),
            'std': float(np.std(feature_array)),
            'min': float(np.min(feature_array)),
            'max': float(np.max(feature_array)),
            'median': float(np.median(feature_array)),
            'q25': float(np.percentile(feature_array, 25)),
            'q75': float(np.percentile(feature_array, 75)),
            'q05': float(np.percentile(feature_array, 5)),
            'q95': float(np.percentile(feature_array, 95)),
            'zero_ratio': float((feature_array == 0).sum() / feature_array.size),
            'non_zero_ratio': float((feature_array != 0).sum() / feature_array.size),
            'nan_count': int(np.isnan(feature_array).sum()),
            'inf_count': int(np.isinf(feature_array).sum()),
            'outlier_ratio_iqr': self._compute_outlier_ratio_iqr(feature_array),
            'outlier_ratio_zscore': self._compute_outlier_ratio_zscore(feature_array)
        }

    def _compute_dimension_wise_stats(self, feature_array: np.ndarray) -> List[Dict[str, float]]:
        """è®¡ç®—æ¯ä¸ªç»´åº¦çš„ç»Ÿè®¡ä¿¡æ¯"""
        if len(feature_array.shape) != 2:
            return []

        dimension_stats = []
        for i in range(feature_array.shape[1]):
            dim_data = feature_array[:, i]
            dim_stats = {
                'dimension': i,
                'mean': float(np.mean(dim_data)),
                'std': float(np.std(dim_data)),
                'min': float(np.min(dim_data)),
                'max': float(np.max(dim_data)),
                'range': float(np.max(dim_data) - np.min(dim_data)),
                'zero_ratio': float((dim_data == 0).sum() / len(dim_data))
            }
            dimension_stats.append(dim_stats)

        return dimension_stats

    def _analyze_feature_scale(self, feature_array: np.ndarray) -> Dict[str, Any]:
        """åˆ†æç‰¹å¾å°ºåº¦é—®é¢˜"""
        if len(feature_array.shape) != 2:
            return {}

        # è®¡ç®—æ¯ä¸ªç»´åº¦çš„å°ºåº¦
        dimension_scales = []
        for i in range(feature_array.shape[1]):
            dim_data = feature_array[:, i]
            scale = np.std(dim_data)
            dimension_scales.append(scale)

        dimension_scales = np.array(dimension_scales)

        analysis = {
            'scale_range': {
                'min_scale': float(np.min(dimension_scales)),
                'max_scale': float(np.max(dimension_scales)),
                'scale_ratio': float(np.max(dimension_scales) / (np.min(dimension_scales) + 1e-8))
            },
            'scale_distribution': {
                'scale_mean': float(np.mean(dimension_scales)),
                'scale_std': float(np.std(dimension_scales)),
                'scale_cv': float(np.std(dimension_scales) / (np.mean(dimension_scales) + 1e-8))
            },
            'recommendations': self._get_scaling_recommendations(dimension_scales)
        }

        return analysis

    def _compute_outlier_ratio_iqr(self, data: np.ndarray) -> float:
        """ä½¿ç”¨IQRæ–¹æ³•è®¡ç®—å¼‚å¸¸å€¼æ¯”ä¾‹"""
        q25 = np.percentile(data, 25)
        q75 = np.percentile(data, 75)
        iqr = q75 - q25

        if iqr == 0:
            return 0.0

        lower_bound = q25 - 1.5 * iqr
        upper_bound = q75 + 1.5 * iqr

        outliers = (data < lower_bound) | (data > upper_bound)
        return float(outliers.sum() / len(data))

    def _compute_outlier_ratio_zscore(self, data: np.ndarray, threshold: float = 3.0) -> float:
        """ä½¿ç”¨Z-scoreæ–¹æ³•è®¡ç®—å¼‚å¸¸å€¼æ¯”ä¾‹"""
        if np.std(data) == 0:
            return 0.0

        z_scores = np.abs((data - np.mean(data)) / np.std(data))
        outliers = z_scores > threshold
        return float(outliers.sum() / len(data))

    def _get_scaling_recommendations(self, dimension_scales: np.ndarray) -> List[str]:
        """åŸºäºå°ºåº¦åˆ†æç»™å‡ºæ ‡å‡†åŒ–å»ºè®®"""
        recommendations = []

        scale_ratio = np.max(dimension_scales) / (np.min(dimension_scales) + 1e-8)

        if scale_ratio > 1000:
            recommendations.append("å¼ºçƒˆå»ºè®®è¿›è¡Œæ ‡å‡†åŒ– - ç‰¹å¾å°ºåº¦å·®å¼‚æå¤§ (>1000å€)")
        elif scale_ratio > 100:
            recommendations.append("å»ºè®®è¿›è¡Œæ ‡å‡†åŒ– - ç‰¹å¾å°ºåº¦å·®å¼‚è¾ƒå¤§ (>100å€)")
        elif scale_ratio > 10:
            recommendations.append("è€ƒè™‘è¿›è¡Œæ ‡å‡†åŒ– - ç‰¹å¾å°ºåº¦æœ‰å·®å¼‚ (>10å€)")
        else:
            recommendations.append("ç‰¹å¾å°ºåº¦ç›¸å¯¹åˆç†")

        # æ£€æŸ¥æ˜¯å¦æœ‰é›¶æ–¹å·®ç‰¹å¾
        zero_var_count = (dimension_scales < 1e-8).sum()
        if zero_var_count > 0:
            recommendations.append(f"å‘ç° {zero_var_count} ä¸ªé›¶æ–¹å·®ç‰¹å¾ï¼Œå»ºè®®ç§»é™¤")

        # æ£€æŸ¥å°ºåº¦åˆ†å¸ƒ
        cv = np.std(dimension_scales) / (np.mean(dimension_scales) + 1e-8)
        if cv > 1.0:
            recommendations.append("ç‰¹å¾å°ºåº¦åˆ†å¸ƒä¸å‡åŒ€ï¼Œå»ºè®®ä½¿ç”¨RobustScaler")

        return recommendations

    def analyze_and_recommend_scaling(self, results: Dict[str, torch.Tensor]):
        """åˆ†æç‰¹å¾å¹¶ç»™å‡ºæ ‡å‡†åŒ–å»ºè®®"""
        print(f"\n=== ç‰¹å¾å°ºåº¦åˆ†æå’Œå»ºè®® ===")

        for feature_name, tensor in results.items():
            if isinstance(tensor, torch.Tensor):
                feature_array = tensor.detach().cpu().numpy()
                analysis = self._analyze_feature_scale(feature_array)

                print(f"\n{feature_name} ç‰¹å¾åˆ†æ:")
                print(f"  å½¢çŠ¶: {feature_array.shape}")
                print(f"  å°ºåº¦èŒƒå›´: {analysis['scale_range']['min_scale']:.3f} - {analysis['scale_range']['max_scale']:.3f}")
                print(f"  å°ºåº¦æ¯”ä¾‹: {analysis['scale_range']['scale_ratio']:.1f}")
                print(f"  å»ºè®®:")
                for rec in analysis['recommendations']:
                    print(f"    - {rec}")

    def _save_feature_statistics(self, results: Dict[str, torch.Tensor], stats_path: str):
        """ä¿å­˜ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯"""
        print(f"ä¿å­˜ç»Ÿè®¡ä¿¡æ¯: {stats_path}")

        statistics = {
            'generation_time': str(pd.Timestamp.now()),
            'feature_types': {
                'f_classic': self._compute_tensor_stats(results['f_classic']),
                'f_graph': self._compute_tensor_stats(results['f_graph'])
            }
        }

        if 'f_fused' in results:
            statistics['feature_types']['f_fused'] = self._compute_tensor_stats(results['f_fused'])

        # æ·»åŠ æ•´ä½“ç»Ÿè®¡
        statistics['overall'] = {
            'total_nodes': int(results['f_classic'].shape[0]),
            'total_features': int(results['f_classic'].shape[1] + results['f_graph'].shape[1]),
            'memory_usage_mb': self._estimate_memory_usage(results)
        }

        if 'f_fused' in results:
            statistics['overall']['total_features'] += int(results['f_fused'].shape[1])

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, indent=2, ensure_ascii=False)

        print(f"  âœ“ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜")

    def _compute_tensor_stats(self, tensor: torch.Tensor) -> Dict[str, Any]:
        """è®¡ç®—å¼ é‡çš„ç»Ÿè®¡ä¿¡æ¯"""
        tensor_np = tensor.detach().cpu().numpy()

        return {
            'shape': list(tensor.shape),
            'dtype': str(tensor.dtype),
            'mean': float(np.mean(tensor_np)),
            'std': float(np.std(tensor_np)),
            'min': float(np.min(tensor_np)),
            'max': float(np.max(tensor_np)),
            'median': float(np.median(tensor_np)),
            'q25': float(np.percentile(tensor_np, 25)),
            'q75': float(np.percentile(tensor_np, 75)),
            'zero_ratio': float((tensor_np == 0).sum() / tensor_np.size),
            'non_zero_ratio': float((tensor_np != 0).sum() / tensor_np.size),
            'nan_count': int(np.isnan(tensor_np).sum()),
            'inf_count': int(np.isinf(tensor_np).sum())
        }

    def _estimate_memory_usage(self, results: Dict[str, torch.Tensor]) -> float:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        total_elements = 0
        for key, tensor in results.items():
            if isinstance(tensor, torch.Tensor):
                total_elements += tensor.numel()

        # å‡è®¾æ¯ä¸ªå…ƒç´ 4å­—èŠ‚ï¼ˆfloat32ï¼‰
        return (total_elements * 4) / (1024 * 1024)

    def enable_adaptive_mode(self):
        """å¯ç”¨è‡ªé€‚åº”æ¨¡å¼"""
        self.adaptive_mode = True
        self.adaptive_extractor = AdaptiveFeatureExtractor()
        print("[SUCCESS] Pipelineè‡ªé€‚åº”æ¨¡å¼å·²å¯ç”¨")

    def extract_features_with_feedback(self, nodes: List[Node],
                                       step4_guidance: Optional[Dict[str, Any]] = None,
                                       epoch: int = 0) -> Dict[str, torch.Tensor]:
        """
        å¸¦åé¦ˆçš„ç‰¹å¾æå– (æ–°å¢æ–¹æ³•)

        Args:
            nodes: èŠ‚ç‚¹åˆ—è¡¨
            step4_guidance: ç¬¬å››æ­¥åé¦ˆæŒ‡å¯¼
            epoch: å½“å‰è®­ç»ƒè½®æ¬¡

        Returns:
            ç‰¹å¾æå–ç»“æœå­—å…¸
        """
        if self.adaptive_mode and self.adaptive_extractor is not None:
            print(f"[CONFIG] ä½¿ç”¨è‡ªé€‚åº”ç‰¹å¾æå– (Epoch {epoch})")

            # ä½¿ç”¨è‡ªé€‚åº”æå–å™¨
            f_classic, f_graph, extraction_info = self.adaptive_extractor(
                nodes, step4_guidance, epoch
            )

            results = {
                'f_classic': f_classic,
                'f_graph': f_graph,
                'nodes': nodes,
                'extraction_info': extraction_info,
                'adaptive_mode': True
            }

        else:
            print(f"[CONFIG] ä½¿ç”¨æ ‡å‡†ç‰¹å¾æå– (Epoch {epoch})")

            # ä½¿ç”¨åŸå§‹æå–å™¨
            f_classic, f_graph = self.feature_extractor(nodes)

            results = {
                'f_classic': f_classic,
                'f_graph': f_graph,
                'nodes': nodes,
                'adaptive_mode': False
            }

        # ç‰¹å¾èåˆ (å¦‚æœå¯ç”¨)
        if self.use_fusion:
            print(" æ‰§è¡Œç‰¹å¾èåˆ...")
            f_fused, contrastive_loss = self.fusion_pipeline(results['f_classic'], results['f_graph'])
            results['f_fused'] = f_fused
            results['contrastive_loss'] = contrastive_loss

        # ä¿å­˜é‚»æ¥çŸ©é˜µä¿¡æ¯
        if self.save_adjacency:
            self._save_adjacency_information()

        return results

    def get_adaptive_status(self) -> Dict[str, Any]:
        """è·å–è‡ªé€‚åº”çŠ¶æ€"""
        if self.adaptive_mode and self.adaptive_extractor is not None:
            return self.adaptive_extractor.get_adaptation_report()
        else:
            return {'adaptive_mode': False, 'message': 'Adaptive mode not enabled'}

    def save_adaptive_history(self, filepath: str = "adaptive_history.json"):
        """ä¿å­˜è‡ªé€‚åº”å†å²"""
        if self.adaptive_mode and self.adaptive_extractor is not None:
            import json

            history_data = {
                'pipeline_config': {
                    'use_fusion': self.use_fusion,
                    'save_adjacency': self.save_adjacency,
                    'adaptive_mode': self.adaptive_mode
                },
                'adaptive_status': self.get_adaptive_status(),
                'timestamp': str(datetime.now()) if 'datetime' in globals() else 'unknown'
            }

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, indent=2, ensure_ascii=False, default=str)

            print(f"ğŸ“ è‡ªé€‚åº”å†å²å·²ä¿å­˜: {filepath}")
        else:
            print("[WARNING] è‡ªé€‚åº”æ¨¡å¼æœªå¯ç”¨ï¼Œæ— æ³•ä¿å­˜å†å²")


def main():
    """å…¨é¢ç‰¹å¾æå–æµç¨‹"""
    print("=== å…¨é¢ç‰¹å¾æå–æµæ°´çº¿æ¼”ç¤º ===\n")

    # åˆå§‹åŒ–æµæ°´çº¿ï¼ˆå¯ç”¨é‚»æ¥çŸ©é˜µä¿å­˜ï¼‰
    pipeline = Pipeline(use_fusion=True, save_adjacency=True)

    # é€‰æ‹©æ•°æ®æ–‡ä»¶
    csv_files = ["large_samples.csv"]

    for csv_file in csv_files:
        try:
            print(f"\n{'='*50}")
            print(f"å¤„ç†æ–‡ä»¶: {csv_file}")
            print(f"{'='*50}")

            # æå–ç‰¹å¾
            results = pipeline.load_and_extract(csv_file)

            # ä½¿ç”¨æ–°çš„ä¿å­˜æ–¹æ³•ï¼ˆåŒ…å«é‚»æ¥çŸ©é˜µï¼‰
            base_name = f"step1_{csv_file.replace('.csv', '')}"
            pipeline.save_features_with_adjacency(results, base_name)

            # åˆ†æç‰¹å¾å°ºåº¦å¹¶ç»™å‡ºå»ºè®®
            pipeline.analyze_and_recommend_scaling(results)

            # ç®€å•éªŒè¯
            print(f"\nç‰¹å¾è´¨é‡æ£€æŸ¥:")
            print(f"- F_classic éé›¶å…ƒç´ æ¯”ä¾‹: {(results['f_classic'] != 0).float().mean():.3f}")
            print(f"- F_graph éé›¶å…ƒç´ æ¯”ä¾‹: {(results['f_graph'] != 0).float().mean():.3f}")

            if 'f_fused' in results:
                print(f"- F_fused éé›¶å…ƒç´ æ¯”ä¾‹: {(results['f_fused'] != 0).float().mean():.3f}")

            print(f"[SUCCESS] {csv_file} å¤„ç†å®Œæˆ\n")

        except Exception as e:
            print(f"[ERROR] å¤„ç† {csv_file} æ—¶å‡ºé”™: {e}\n")
            import traceback
            traceback.print_exc()
            continue

    print("=== å…¨é¢ç‰¹å¾æå–æµæ°´çº¿æ¼”ç¤ºå®Œæˆ ===")

if __name__ == "__main__":
    main()